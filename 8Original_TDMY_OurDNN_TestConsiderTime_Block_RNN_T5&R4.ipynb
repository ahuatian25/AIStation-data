{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验R3:引入LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras import layers,metrics\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU, ELU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.utils import shuffle as reset\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "# import \n",
    "from matplotlib.pylab import plt\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler #https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.RandomOverSampler.html?highlight=randomoversampler\n",
    "from frplayer import FilterResponseNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_DataFrame(data, test_size=0.2, considerTime=True, random_state=None):\n",
    "    # ConsiderTime-------trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "    if considerTime:\n",
    "        data=data.sort_values(by=\"Dates\", ascending=True)\n",
    "    else:\n",
    "        data=reset(data, random_state=random_state)\n",
    "    train=data[int(len(data)*test_size):].reset_index(drop=True)\n",
    "    test=data[:int(len(data)*test_size)].reset_index(drop=True)\n",
    "    return train, test\n",
    "\n",
    "def comparePlusMultResult(scoreDNN,scoreRNN,Y):\n",
    "    scorePrePlus=np.add(scoreDNN,scoreRNN)\n",
    "    scorePreMult=np.multiply(scoreDNN,scoreRNN)\n",
    "    \n",
    "    M=np.nanmax(scorePrePlus)\n",
    "    A=np.where(scorePrePlus == M, 1, scorePrePlus)\n",
    "    Plus_One=np.where(A < 1.0, 0, A)\n",
    "    \n",
    "    M=np.nanmax(scorePreMult)\n",
    "    A=np.where(scorePreMult == M, 1, scorePreMult)\n",
    "    Mult_One=np.where(A < 1.0, 0, A)    \n",
    "    \n",
    "    Plus_Result=0.0\n",
    "    Mult_Result=0.0\n",
    "    if np.sum(np.abs(np.array(Plus_One)-np.array(Y)))==0.0:\n",
    "        Plus_Result=1.0\n",
    "    if np.sum(np.abs(np.array(Mult_One)-np.array(Y)))==0.0:\n",
    "        Plus_Result=1.0\n",
    "    return Plus_Result, Mult_Result\n",
    "\n",
    "def compareResult(scoreNN,Y):\n",
    "    M=np.nanmax(scoreNN)\n",
    "    A=np.where(scoreNN == M, 1, scoreNN)\n",
    "    B=np.where(A < 1.0, 0, A)    \n",
    "    Result=0.0\n",
    "    if np.sum(np.abs(np.array(B)-np.array(Y)))==0.0:\n",
    "        Result=1.0\n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj    \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "def Dates2TDMY(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj  \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    #T_D_M_Y=str(time)+str(day)+str(month)+str(year)\n",
    "    T_D_M_Y=str(time)+str(day)+str(month)\n",
    "    return T_D_M_Y\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field2Vec(trainDF,testDF,fieldStr):\n",
    "    fields=sorted(trainDF[fieldStr].unique())\n",
    "    categories=sorted(trainDF[\"Category\"].unique())\n",
    "    C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "    F_C_counts=trainDF.groupby([fieldStr,\"Category\"]).size()\n",
    "    F_counts=trainDF.groupby([fieldStr]).size()\n",
    "    logodds={}\n",
    "    logoddsPF={}\n",
    "    MIN_CAT_COUNTS=2\n",
    "    default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "    for f in fields:\n",
    "        PA=F_counts[f]/float(len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "        logodds[f]=deepcopy(default_logodds)\n",
    "        for cat in F_C_counts[f].keys():\n",
    "            if (F_C_counts[f][cat]>MIN_CAT_COUNTS) and F_C_counts[f][cat]<F_counts[f]:\n",
    "                PA=F_C_counts[f][cat]/float(F_counts[f])\n",
    "                logodds[f][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "        logodds[f]=pd.Series(logodds[f])\n",
    "        logodds[f].index=range(len(categories))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #fieldsTest=sorted(testDF[fieldStr].unique())\n",
    "    #N_count=0\n",
    "    #for f in fieldsTest:\n",
    "        #if f not in fields:\n",
    "            #logoddsPF[f]=-50.0  #np.log(0.)-np.log(1.)=-inf,便于计算，改为-99999.0\n",
    "            #logodds[f]=deepcopy(default_logodds)\n",
    "            #pa=1.0/float(len(categories))\n",
    "            #logodds[f][range(len(categories))]=np.log(pa)-np.log(1.0-pa)\n",
    "            #logodds[f]=pd.Series(logodds[f])\n",
    "            #logodds[f].index=range(len(categories))\n",
    "            #N_count=N_count+1\n",
    "    #print(fieldStr+' N_count: '+str(N_count))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #引进代码原作者的新思想\n",
    "    if testDF.shape[0]>0: #如果testDF里有样本,......\n",
    "        print('There are some new:'+fieldStr)\n",
    "        new_fields=sorted(testDF[fieldStr].unique())\n",
    "        new_F_counts=testDF.groupby(fieldStr).size()\n",
    "        only_new=set(new_fields+fields)-set(fields)\n",
    "        only_old=set(new_fields+fields)-set(new_fields)\n",
    "        in_both=set(new_fields).intersection(fields)\n",
    "        print('# only_new_fieldds:'+str(len(only_new)))\n",
    "        for f in only_new:\n",
    "            PA=new_F_counts[f]/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "            logodds[f]=deepcopy(default_logodds)\n",
    "            logodds[f].index=range(len(categories))\n",
    "        for f in in_both:\n",
    "            PA=(F_counts[f]+new_F_counts[f])/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)    \n",
    "    return logodds,logoddsPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(df,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y=False):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print(\"Creating address features\")###Creating address features###\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds_A[x])\n",
    "    address_features.columns=[\"logodds_A\"+str(x) for x in range(len(address_features.columns))]\n",
    "    if needT_D_M_Y:\n",
    "        print(\"Creating time T_D_M_Y features\")###Creating time T_D_M_Y features###\n",
    "        T_D_M_Y_features=cleanData[\"T_D_M_Y\"].apply(lambda xx: logodds_T[xx])\n",
    "        T_D_M_Y_features.columns=[\"logodds_T\"+str(xx) for xx in range(len(T_D_M_Y_features.columns))]\n",
    "\n",
    "    print(\"Parsing dates\")            ###Creating address features###\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    #     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    #     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print(\"Creating one-hot variables\")\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPF_A\"]=cleanData[\"Address\"].apply(lambda x: logoddsPF_A[x])\n",
    "    if needT_D_M_Y:\n",
    "        cleanData[\"logoddsPF_T\"]=cleanData[\"T_D_M_Y\"].apply(lambda x: logoddsPF_T[x])\n",
    "    print(\"droping processed columns\")\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)    \n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    if needT_D_M_Y:\n",
    "        cleanData=cleanData.drop(\"T_D_M_Y\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print(\"joining one-hot features\")\n",
    "    if needT_D_M_Y:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:]).join(T_D_M_Y_features.iloc[:,:])\n",
    "    else:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:])\n",
    "    print(\"creating new features\")\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(keep='last')).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, Y, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(X) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)#数值在[low, high)区间。\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, X.shape[-1]))\n",
    "        targets = np.zeros((len(rows),Y.shape[1]))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = X[indices]\n",
    "            targets[j] = Y[rows[j]+delay]\n",
    "#         print('# row of Val: '+str(targets.shape[0]))###Tian\n",
    "        yield samples, targets\n",
    "    #Now here is the data generator that we will use. It yields a tuple (samples, targets) where samples is one batch of input data and targets is the corresponding array of target temperatures. It takes the following arguments:\n",
    "        # •data: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "        # •lookback: How many timesteps back should our input data go.\n",
    "        # •delay: How many timesteps in the future should our target be.\n",
    "        # •min_index and max_index: Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another one for testing.\n",
    "        # •shuffle: Whether to shuffle our samples or draw them in chronological order.\n",
    "        # •batch_size: The number of samples per batch.\n",
    "        # •step: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of OrginalAllDF: (878049, 9)\n",
      "The shape of AllDF after del wrong X and Y values: (877982, 9)\n",
      "The shape of AllDF after drop_duplicates: (812529, 9)\n",
      "(689038, 2)\n",
      "Address_counts_allDF_trainDF_testDF: 23191_23191_0\n",
      "The # of AllDF, AllTrain, AllTest, is: 812529,812529,0\n",
      "-----------LOGOODS: Address-------------\n",
      "-----------LOGOODS: T_D_M_Y-------------\n",
      "-----------LOGOODS: parse_data of Alltrain  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPF_A', 'logoddsPF_T', 'PD_BAYVIEW', 'PD_CENTRAL', 'PD_INGLESIDE', 'PD_MISSION', 'PD_NORTHERN', 'PD_PARK', 'PD_RICHMOND', 'PD_SOUTHERN', 'PD_TARAVAL', 'PD_TENDERLOIN', 'DAY_Friday', 'DAY_Monday', 'DAY_Saturday', 'DAY_Sunday', 'DAY_Thursday', 'DAY_Tuesday', 'DAY_Wednesday', 'logodds_A0', 'logodds_A1', 'logodds_A2', 'logodds_A3', 'logodds_A4', 'logodds_A5', 'logodds_A6', 'logodds_A7', 'logodds_A8', 'logodds_A9', 'logodds_A10', 'logodds_A11', 'logodds_A12', 'logodds_A13', 'logodds_A14', 'logodds_A15', 'logodds_A16', 'logodds_A17', 'logodds_A18', 'logodds_A19', 'logodds_A20', 'logodds_A21', 'logodds_A22', 'logodds_A23', 'logodds_A24', 'logodds_A25', 'logodds_A26', 'logodds_A27', 'logodds_A28', 'logodds_A29', 'logodds_A30', 'logodds_A31', 'logodds_A32', 'logodds_A33', 'logodds_A34', 'logodds_A35', 'logodds_A36', 'logodds_A37', 'logodds_A38', 'logodds_T0', 'logodds_T1', 'logodds_T2', 'logodds_T3', 'logodds_T4', 'logodds_T5', 'logodds_T6', 'logodds_T7', 'logodds_T8', 'logodds_T9', 'logodds_T10', 'logodds_T11', 'logodds_T12', 'logodds_T13', 'logodds_T14', 'logodds_T15', 'logodds_T16', 'logodds_T17', 'logodds_T18', 'logodds_T19', 'logodds_T20', 'logodds_T21', 'logodds_T22', 'logodds_T23', 'logodds_T24', 'logodds_T25', 'logodds_T26', 'logodds_T27', 'logodds_T28', 'logodds_T29', 'logodds_T30', 'logodds_T31', 'logodds_T32', 'logodds_T33', 'logodds_T34', 'logodds_T35', 'logodds_T36', 'logodds_T37', 'logodds_T38', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n",
      "110\n",
      "------------Attention: we do not RandomOverSampler---------------\n",
      "------------ConsiderTime:  Sorting--------------\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "ConsiderTime=True#False# True##trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "Rate_ALL=0.0 #0.0即不保留测试机\n",
    "needOverSampler=False\n",
    "needT_D_M_Y=True #False  使用_T_D_M_Y和周几\n",
    "allDF=pd.read_csv(\"./train_addrCorrect.csv\")\n",
    "print('The shape of OrginalAllDF: '+str(allDF.shape))\n",
    "\n",
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(allDF[[\"X\",\"Y\"]])\n",
    "allDF[[\"X\",\"Y\"]]=xy_scaler.transform(allDF[[\"X\",\"Y\"]])\n",
    "allDF=allDF[abs(allDF[\"Y\"])<100]\n",
    "allDF.index=range(len(allDF))\n",
    "print('The shape of AllDF after del wrong X and Y values: '+str(allDF.shape))\n",
    "\n",
    "def listCat(x):\n",
    "    return list(x)\n",
    "allDF.drop_duplicates(inplace=True,subset=['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Category'])\n",
    "Train_duplicated=pd.pivot_table(allDF,index=['Dates','DayOfWeek','PdDistrict', 'Address', 'X', 'Y'], values='Category',aggfunc=[len,listCat])\n",
    "print('The shape of AllDF after drop_duplicates: '+str(allDF.shape))\n",
    "print(Train_duplicated.shape)\n",
    "\n",
    "trainDF,testDF=train_test_split_DataFrame(allDF, test_size=Rate_ALL, considerTime=ConsiderTime, random_state=None)\n",
    "print('Address_counts_allDF_trainDF_testDF: ' + str(len(allDF[\"Address\"].unique())) + '_'+ str(len(trainDF[\"Address\"].unique())) + '_' + str(len(testDF[\"Address\"].unique())))\n",
    "\n",
    "N_AllSample=allDF.shape[0]\n",
    "N_AllTrain=trainDF.shape[0]\n",
    "N_AllTest=testDF.shape[0]\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "print('The # of AllDF, AllTrain, AllTest, is: '+str(N_AllSample)+','+str(N_AllTrain)+','+str(N_AllTest))\n",
    "#################Now proceed as before#################\n",
    "print('-----------LOGOODS: Address-------------')\n",
    "logodds_A,logoddsPF_A=field2Vec(trainDF,testDF,\"Address\")\n",
    "if needT_D_M_Y:\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"Dates\"].apply(Dates2TDMY)\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"T_D_M_Y\"]+trainDF[\"DayOfWeek\"]\n",
    "    if Rate_ALL>0:\n",
    "        testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"Dates\"].apply(Dates2TDMY)\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"T_D_M_Y\"]+testDF[\"DayOfWeek\"]\n",
    "    print('-----------LOGOODS: T_D_M_Y-------------')\n",
    "    logodds_T,logoddsPF_T=field2Vec(trainDF,testDF,\"T_D_M_Y\")    \n",
    "else:\n",
    "    logodds_T=None\n",
    "    logoddsPF_T=None\n",
    "    \n",
    "print('-----------LOGOODS: parse_data of Alltrain  -------------')\n",
    "features, labels=parse_data(trainDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y) \n",
    "if Rate_ALL>0:\n",
    "    print('-----------LOGOODS: parse_data of Alltest  -------------')\n",
    "    features_test, labels_test=parse_data(testDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y)###########和训练集使用同样的时间和地点Logoodds值#####\n",
    "    x_test=features_test.values\n",
    "    y_test=labels_test.values\n",
    "    y_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_test)), num_classes=N_CLASS)\n",
    "\n",
    "print(features.columns.tolist())\n",
    "print(len(features.columns))\n",
    "\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)\n",
    "if Rate_ALL>0:\n",
    "    features_test[collist]=scaler.transform(features_test)###########和训练集使用同样的scaler值#####\n",
    "######################################################\n",
    "#############################先进行过采样，然后再根据时间来排序##################################\n",
    "if needOverSampler:\n",
    "    print('------------RandomOverSampler--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArrayOverSampler, labelsArrayOverSampler = ros.fit_resample(features.values,labels.values)#####过采样#####\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('Shape of OverSampler of AllTrain: '+str(featuresArrayOverSampler.shape))\n",
    "else:\n",
    "    featuresArrayOverSampler=features.values\n",
    "    labelsArrayOverSampler=labels.values\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('------------Attention: we do not RandomOverSampler---------------')\n",
    "if ConsiderTime:\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    print('------------ConsiderTime:  Sorting--------------')\n",
    "    time_temp=featuresArrayOverSampler[:,2]+np.dot(featuresArrayOverSampler[:,3],100)+np.dot(featuresArrayOverSampler[:,4],10000)+np.dot(featuresArrayOverSampler[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresArrayOverSampler,labelsArrayOverSampler))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    labelsArrayOverSampler=features_label_time[:,-2]\n",
    "    featuresArrayOverSampler=features_label_time[:,0:featuresArrayOverSampler.shape[1]]\n",
    "    del features_label_time\n",
    "    #############################先进行过采样，然后再根据时间来排序----结束############################\n",
    "if Rate_ALL>0:\n",
    "    print('------------RandomOverSampler for AllTest--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArray_test, labelsArray_test = ros.fit_resample(features_test.values,labels_test.values)#####过采样#####\n",
    "    N_AllTest_OverSampler=int(featuresArray_test.shape[0])\n",
    "    labelsArray_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArray_test)), num_classes=N_CLASS)\n",
    "    print('Shape of OverSampler of AllTest: '+str(featuresArray_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_Train_OverSampler= 162506\n",
      "BlockSize is: 1300\n",
      "-----------------Building DNN model---------------------\n",
      "------------Building LSTM model--------------\n"
     ]
    }
   ],
   "source": [
    "DnnTrainFromZero=True\n",
    "RnnTrainFromZero=False\n",
    "ShuffleInTraining=True\n",
    "N_EPOCHS_0_DNN=7\n",
    "N_EPOCHS_DNN=3\n",
    "N_EPOCHS_0_RNN=2\n",
    "N_EPOCHS_RNN=1\n",
    "N_HN_1=128\n",
    "N_HN=128\n",
    "N_LAYERS=1\n",
    "N_BATCH=64\n",
    "Rate_Val=0.8#用20%作为原始训练集，分别训练DNN和RNN\n",
    "N_Split=500\n",
    "delay=-1\n",
    "N_Val_OverSampler=int(np.around(N_AllTrain_OverSampler*Rate_Val))\n",
    "N_Train_OverSampler=int(N_AllTrain_OverSampler-N_Val_OverSampler)\n",
    "print('N_Train_OverSampler= '+str(N_Train_OverSampler))\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresArrayOverSampler.shape[1]\n",
    "output_dim=N_CLASS\n",
    "BlockSize=int(np.floor(N_Val_OverSampler/N_Split))\n",
    "print('BlockSize is: '+str(BlockSize)) \n",
    "lookback=int(BlockSize)\n",
    "\n",
    "print('-----------------Building DNN model---------------------')\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HN_1,input_dim=input_dim))\n",
    "model.add(BatchNormalization())\n",
    "model.add(PReLU())\n",
    "for i in range(N_LAYERS):\n",
    "    model.add(Dense(N_HN))\n",
    "    model.add(BatchNormalization())   \n",
    "    model.add(PReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(output_dim))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "\n",
    "print('------------Building LSTM model--------------')\n",
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(LSTM(N_HN_1,dropout=0.5, recurrent_dropout=0.5,return_sequences=True,input_shape=(None,input_dim)))\n",
    "RNNmodel.add(LSTM(N_HN,dropout=0.5, recurrent_dropout=0.5,return_sequences=True,))\n",
    "RNNmodel.add(LSTM(N_HN,dropout=0.5, recurrent_dropout=0.5))\n",
    "RNNmodel.add(Dense(output_dim))\n",
    "RNNmodel.add(Activation('softmax'))\n",
    "RNNmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy', metrics.top_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Prepare dataset for DNN---------------------------------\n",
      "--------Spllit train val according to time!---------\n",
      "(162506, 110)\n",
      "(1, 110)\n",
      "--------------------------Generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------Prepare dataset for DNN---------------------------------')\n",
    "labelsArrayOverSampler_1hot=keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArrayOverSampler)), num_classes=N_CLASS)\n",
    "if ConsiderTime:\n",
    "    print('--------Spllit train val according to time!---------')\n",
    "    x_train=featuresArrayOverSampler[0:N_Train_OverSampler,:]\n",
    "    y_train=labelsArrayOverSampler_1hot[0:N_Train_OverSampler,:]\n",
    "else:\n",
    "    x_train,x_val,y_train,y_val = train_test_split(featuresArrayOverSampler,labelsArrayOverSampler_1hot,test_size=N_Val_OverSampler,train_size=N_Train_OverSampler, shuffle=True)\n",
    "print(str(x_train.shape))\n",
    "x_val_i=featuresArrayOverSampler[N_Train_OverSampler:N_Train_OverSampler+1,:]\n",
    "y_val_i=labelsArrayOverSampler_1hot[N_Train_OverSampler:N_Train_OverSampler+1,:]\n",
    "print(str(x_val_i.shape))\n",
    "\n",
    "print('--------------------------Generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------')\n",
    "train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=0, max_index=N_Train_OverSampler, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler-lookback, max_index=N_Train_OverSampler+1, shuffle=False, batch_size=N_BATCH, step=1)\n",
    "#数值在[min_index, max_index)区间。当delay=1时，就是用[min_index, max_index)区间的样本预测，第max_index个样本。当delay=2时，就是预测第max_index+1个\n",
    "train_steps= (N_Train_OverSampler-lookback) // N_BATCH\n",
    "val_steps =  1 #(N_Val-lookback) // N_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------DNN Training Go! Go! Go!!!!-----------\n",
      "Train on 162506 samples, validate on 1 samples\n",
      "Epoch 1/7\n",
      "162506/162506 [==============================] - 37s 228us/step - loss: 2.3328 - accuracy: 0.3046 - top_k_categorical_accuracy: 0.7175 - val_loss: 1.9426 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/7\n",
      "162506/162506 [==============================] - 38s 234us/step - loss: 2.1869 - accuracy: 0.3249 - top_k_categorical_accuracy: 0.7517 - val_loss: 1.8951 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/7\n",
      "162506/162506 [==============================] - 43s 262us/step - loss: 2.1698 - accuracy: 0.3289 - top_k_categorical_accuracy: 0.7548 - val_loss: 1.5331 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/7\n",
      "162506/162506 [==============================] - 39s 242us/step - loss: 2.1579 - accuracy: 0.3310 - top_k_categorical_accuracy: 0.7582 - val_loss: 1.5119 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/7\n",
      "162506/162506 [==============================] - 35s 216us/step - loss: 2.1473 - accuracy: 0.3328 - top_k_categorical_accuracy: 0.7607 - val_loss: 2.0033 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/7\n",
      "162506/162506 [==============================] - 36s 220us/step - loss: 2.1392 - accuracy: 0.3352 - top_k_categorical_accuracy: 0.7626 - val_loss: 1.5276 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/7\n",
      "162506/162506 [==============================] - 39s 240us/step - loss: 2.1305 - accuracy: 0.3368 - top_k_categorical_accuracy: 0.7644 - val_loss: 1.7780 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "------------DNN train finished--------------------\n",
      "------------LSTM Model has been loaded!!!-----------------\n"
     ]
    }
   ],
   "source": [
    "if DnnTrainFromZero:\n",
    "    print('------------DNN Training Go! Go! Go!!!!-----------')\n",
    "    fitting=model.fit(x_train, y_train, epochs=N_EPOCHS_0_DNN, batch_size=N_BATCH,verbose=1,validation_data=(x_val_i,y_val_i),shuffle=True)\n",
    "    #score01=model.predict(x_val_i, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    #score0=model.evaluate(x=x_val_i, y=y_val_i, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    RNNmodel.save('jjs_model_DnnV1.h5')\n",
    "    print('------------DNN train finished--------------------')\n",
    "else:\n",
    "    RNNmodel=load_model('jjs_model_DnnV1.h5')\n",
    "    print('------------Dnn Model has been loaded!!!-----------------')\n",
    "    \n",
    "    \n",
    "if RnnTrainFromZero:\n",
    "    print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=N_EPOCHS_0,verbose=1,validation_data=val_generator,validation_steps=val_steps)\n",
    "    print('------------LSTM train finished--------------------')\n",
    "    RNNmodel.save('jjs_model_0204LSTMV1.h5')\n",
    "else:\n",
    "    RNNmodel=load_model('jjs_model_0204LSTMV1.h5')\n",
    "    print('------------LSTM Model has been loaded!!!-----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TR2:steps_per_epoch=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Start the loop training!!---------------------\n",
      "i_s:0------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:1------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:2------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:3------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:4------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:5------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:6------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:7------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:8------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:9------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:10------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:11------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:12------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:13------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:14------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:15------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:16------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:17------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:18------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:19------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:20------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:21------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:22------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:23------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:24------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:25------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:26------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:27------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:28------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:29------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:30------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:31------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:32------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:33------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:34------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:35------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:36------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:37------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:38------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:39------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:40------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:41------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:42------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:43------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:44------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:45------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:46------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:47------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:48------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:49------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:50------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:51------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:52------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:53------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:54------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:55------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:56------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:57------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:58------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:59------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:60------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:61------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:62------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:63------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:64------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:65------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:66------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:67------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:68------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:69------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:70------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:71------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:72------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:73------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:74------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:75------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:76------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:77------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:78------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:79------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:80------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:81------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:82------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:83------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:84------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:85------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:86------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:87------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:88------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:89------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:90------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:91------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:92------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:93------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:94------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:95------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:96------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:97------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:98------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:99------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:100------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:101------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:102------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:103------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:104------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:105------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:106------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:107------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:108------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:109------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:110------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:111------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:112------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:113------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:114------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:115------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:116------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:117------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:118------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:119------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:120------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:121------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:122------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:123------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:124------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:125------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:126------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:127------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:128------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:129------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:130------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:131------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:132------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:133------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:134------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:135------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:136------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:137------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:138------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:139------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:140------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:141------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:142------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:143------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:144------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:145------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:146------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:147------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:148------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:149------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:150------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:151------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:152------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:153------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:154------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:155------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:156------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:157------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:158------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:159------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:160------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:161------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:162------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:163------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:164------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:165------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:166------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:167------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:168------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:169------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:170------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:171------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:172------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:173------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:174------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:175------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:176------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:177------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:178------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:179------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:180------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:181------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:182------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:183------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:184------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:185------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:186------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:187------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:188------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:189------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:190------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:191------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:192------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:193------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:194------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:195------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:196------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:197------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:198------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:199------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:200------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:201------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:202------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:203------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:204------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:205------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:206------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:207------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:208------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:209------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:210------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:211------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:212------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:213------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:214------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:215------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:216------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:217------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:218------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:219------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:220------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:221------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:222------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:223------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:224------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:225------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:226------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:227------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:228------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:229------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:230------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:231------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:232------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:233------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:234------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:235------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:236------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:237------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:238------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:239------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:240------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:241------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:242------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:243------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:244------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:245------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:246------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:247------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:248------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:249------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:250------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:251------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:252------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:253------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:254------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:255------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:256------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:257------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:258------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:259------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:260------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:261------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:262------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:263------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:264------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:265------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:266------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:267------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:268------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:269------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:270------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:271------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:272------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:273------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:274------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:275------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:276------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:277------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:278------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:279------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:280------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:281------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:282------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:283------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:284------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:285------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n"
     ]
    }
   ],
   "source": [
    "print('-----------------Start the loop training!!---------------------')\n",
    "ACC=np.zeros([N_Split,4])\n",
    "for i_s in range(N_Split):    \n",
    "    x_train=featuresArrayOverSampler[N_Train_OverSampler+i_s*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize,:]\n",
    "    y_train=labelsArrayOverSampler_1hot[N_Train_OverSampler+i_s*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize,:]\n",
    "    x_val_i=featuresArrayOverSampler[N_Train_OverSampler+(i_s+1)*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize+1,:]\n",
    "    y_val_i=labelsArrayOverSampler_1hot[N_Train_OverSampler+(i_s+1)*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize+1,:]\n",
    "    fittingDNN=model.fit(x_train, y_train, epochs=N_EPOCHS_DNN, batch_size=N_BATCH,verbose=0,validation_data=(x_val_i,y_val_i),shuffle=True)\n",
    "    \n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    fittingRNN=RNNmodel.fit_generator(train_generator,steps_per_epoch=70,epochs=1,verbose=0,validation_data=val_generator,validation_steps=1)\n",
    "    \n",
    "    scoreDNN=model.predict(x_val_i, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    scoreRNN=RNNmodel.predict(val_generator, batch_size=None, verbose=0, steps=1, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    pre_Dnn=compareResult(scoreDNN,y_val_i)\n",
    "    pre_Rnn=compareResult(scoreRNN,y_val_i)\n",
    "    pre_Plus,pre_Mult=comparePlusMultResult(scoreDNN,scoreRNN,y_val_i)        \n",
    "    print('i_s:'+str(i_s)+'------DNN & RNN & pre_Plus & pre_Mult = '+str(pre_Dnn)+'---'+str(pre_Rnn)+'---'+str(pre_Plus)+'---'+str(pre_Mult))\n",
    "    ACC[i_s,0]=pre_Dnn\n",
    "    ACC[i_s,1]=pre_Rnn\n",
    "    ACC[i_s,2]=pre_Plus\n",
    "    ACC[i_s,3]=pre_Mult    \n",
    "RNNmodel.save('jjs_model_0207D_R_V2.h5')        \n",
    "print(ACC)\n",
    "print(np.mean(ACC,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TR1:steps_per_epoch=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Start the loop training!!---------------------\n",
      "i_s:0------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:1------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:2------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:3------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:4------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:5------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:6------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:7------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:8------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:9------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:10------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:11------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:12------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:13------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:14------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:15------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:16------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:17------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:18------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:19------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:20------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:21------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:22------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:23------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:24------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:25------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:26------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:27------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:28------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:29------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:30------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:31------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:32------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:33------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:34------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:35------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:36------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:37------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:38------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:39------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:40------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:41------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:42------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:43------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:44------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:45------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:46------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:47------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:48------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:49------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:50------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:51------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:52------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:53------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:54------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:55------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:56------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:57------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:58------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:59------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:60------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:61------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:62------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:63------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:64------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:65------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:66------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:67------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:68------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:69------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:70------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:71------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:72------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:73------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:74------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:75------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:76------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:77------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:78------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:79------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:80------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:81------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:82------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:83------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:84------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:85------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:86------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:87------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:88------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:89------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:90------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:91------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:92------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:93------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:94------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:95------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:96------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:97------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:98------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:99------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:100------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:101------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:102------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:103------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:104------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:105------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:106------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:107------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:108------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:109------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:110------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:111------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:112------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:113------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:114------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:115------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:116------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:117------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:118------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:119------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:120------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:121------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:122------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:123------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:124------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:125------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:126------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:127------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:128------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:129------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:130------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:131------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:132------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:133------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:134------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:135------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:136------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:137------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:138------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:139------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:140------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:141------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:142------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:143------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:144------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:145------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:146------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:147------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:148------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:149------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:150------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:151------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:152------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:153------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:154------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:155------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:156------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:157------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:158------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:159------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:160------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:161------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:162------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:163------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:164------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:165------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:166------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:167------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:168------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:169------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:170------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:171------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:172------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:173------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:174------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:175------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:176------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:177------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:178------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:179------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:180------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:181------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:182------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:183------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:184------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:185------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:186------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:187------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:188------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:189------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:190------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:191------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:192------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:193------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:194------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:195------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:196------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:197------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:198------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:199------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:200------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:201------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:202------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:203------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:204------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:205------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:206------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:207------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:208------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:209------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:210------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:211------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:212------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:213------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:214------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:215------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:216------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:217------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:218------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:219------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:220------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:221------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:222------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:223------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:224------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:225------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:226------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:227------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:228------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:229------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:230------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:231------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:232------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:233------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:234------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:235------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:236------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:237------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:238------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:239------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:240------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:241------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:242------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:243------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:244------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:245------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:246------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:247------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:248------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:249------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:250------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:251------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:252------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:253------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:254------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:255------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:256------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:257------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:258------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:259------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:260------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:261------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:262------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:263------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:264------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:265------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:266------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:267------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:268------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:269------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:270------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:271------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:272------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:273------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:274------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:275------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:276------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:277------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:278------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:279------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:280------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:281------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:282------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:283------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:284------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:285------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:286------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:287------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:288------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:289------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:290------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:291------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:292------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:293------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:294------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:295------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:296------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:297------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:298------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:299------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:300------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:301------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:302------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:303------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:304------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:305------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:306------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:307------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:308------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:309------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:310------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:311------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:312------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:313------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:314------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:315------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:316------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:317------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:318------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:319------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:320------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:321------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:322------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:323------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:324------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:325------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:326------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:327------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:328------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:329------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:330------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:331------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:332------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:333------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:334------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:335------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:336------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:337------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:338------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:339------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:340------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:341------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:342------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:343------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:344------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:345------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:346------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:347------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:348------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:349------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:350------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:351------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:352------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:353------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:354------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:355------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:356------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:357------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:358------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:359------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:360------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:361------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:362------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:363------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:364------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:365------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:366------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:367------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:368------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:369------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:370------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:371------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:372------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:373------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:374------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:375------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:376------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:377------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:378------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:379------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:380------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:381------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:382------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:383------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:384------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:385------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:386------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:387------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:388------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:389------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:390------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:391------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:392------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:393------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:394------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:395------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:396------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:397------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:398------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:399------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:400------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:401------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:402------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:403------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:404------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:405------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:406------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:407------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:408------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:409------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:410------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:411------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:412------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:413------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:414------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:415------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:416------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:417------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:418------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:419------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:420------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:421------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:422------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:423------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:424------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:425------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:426------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:427------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:428------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:429------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:430------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:431------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:432------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:433------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:434------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:435------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:436------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---1.0---0.0\n",
      "i_s:437------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:438------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:439------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:440------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:441------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:442------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:443------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:444------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:445------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:446------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:447------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:448------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:449------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:450------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:451------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:452------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:453------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:454------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:455------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:456------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:457------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:458------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:459------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:460------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:461------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:462------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:463------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---0.0---0.0\n",
      "i_s:464------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:465------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:466------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:467------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:468------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:469------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:470------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:471------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:472------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:473------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:474------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:475------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:476------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:477------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:478------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:479------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:480------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:481------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:482------DNN & RNN & pre_Plus & pre_Mult = 0.0---1.0---1.0---0.0\n",
      "i_s:483------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:484------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:485------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:486------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:487------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:488------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:489------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:490------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:491------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "i_s:492------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---0.0---0.0\n",
      "i_s:493------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:494------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:495------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:496------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:497------DNN & RNN & pre_Plus & pre_Mult = 0.0---0.0---0.0---0.0\n",
      "i_s:498------DNN & RNN & pre_Plus & pre_Mult = 1.0---0.0---1.0---0.0\n",
      "i_s:499------DNN & RNN & pre_Plus & pre_Mult = 1.0---1.0---1.0---0.0\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 1. 1. 0.]]\n",
      "[0.34  0.188 0.312 0.   ]\n"
     ]
    }
   ],
   "source": [
    "print('-----------------Start the loop training!!---------------------')\n",
    "ACC=np.zeros([N_Split,4])\n",
    "for i_s in range(N_Split):    \n",
    "    x_train=featuresArrayOverSampler[N_Train_OverSampler+i_s*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize,:]\n",
    "    y_train=labelsArrayOverSampler_1hot[N_Train_OverSampler+i_s*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize,:]\n",
    "    x_val_i=featuresArrayOverSampler[N_Train_OverSampler+(i_s+1)*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize+1,:]\n",
    "    y_val_i=labelsArrayOverSampler_1hot[N_Train_OverSampler+(i_s+1)*BlockSize:N_Train_OverSampler+(i_s+1)*BlockSize+1,:]\n",
    "    fittingDNN=model.fit(x_train, y_train, epochs=N_EPOCHS_DNN, batch_size=N_BATCH,verbose=0,validation_data=(x_val_i,y_val_i),shuffle=True)\n",
    "    \n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    fittingRNN=RNNmodel.fit_generator(train_generator,steps_per_epoch=5,epochs=1,verbose=0,validation_data=val_generator,validation_steps=1)\n",
    "    \n",
    "    scoreDNN=model.predict(x_val_i, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    scoreRNN=RNNmodel.predict(val_generator, batch_size=None, verbose=0, steps=1, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    pre_Dnn=compareResult(scoreDNN,y_val_i)\n",
    "    pre_Rnn=compareResult(scoreRNN,y_val_i)\n",
    "    pre_Plus,pre_Mult=comparePlusMultResult(scoreDNN,scoreRNN,y_val_i)        \n",
    "    print('i_s:'+str(i_s)+'------DNN & RNN & pre_Plus & pre_Mult = '+str(pre_Dnn)+'---'+str(pre_Rnn)+'---'+str(pre_Plus)+'---'+str(pre_Mult))\n",
    "    ACC[i_s,0]=pre_Dnn\n",
    "    ACC[i_s,1]=pre_Rnn\n",
    "    ACC[i_s,2]=pre_Plus\n",
    "    ACC[i_s,3]=pre_Mult    \n",
    "RNNmodel.save('jjs_model_0207D_R_V1.h5')        \n",
    "print(ACC)\n",
    "print(np.mean(ACC,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generator at 0x7ff205d838e0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
    "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "begin from 0206 23:35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaaaa=np.mean(ACC,axis=0)\n",
    "aaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a=[[0,0,1,0]]\n",
    "b=[[1,0,0,0]]\n",
    "c=[[1,0,0,0]]\n",
    "rr=np.sum(np.abs(np.array(a)-np.array(b)))\n",
    "print(rr)\n",
    "ss=np.sum(np.abs(np.array(c)-np.array(b)))\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------Start the loop training!!---------------------')\n",
    "ACC=[0.0,0.0]\n",
    "val_ACC=[0.0,0.0]\n",
    "val_TopACC=[0.0,0.0]\n",
    "for i_s in range(N_Split):\n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    print('i_s='+str(i_s)+ ' in '+ str(N_Split) +';  max_index='+str(N_Train_OverSampler+(i_s+1)*BlockSize+1))\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    #history = RNNmodel.fit_generator(train_generator,steps_per_epoch=1,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=(N_Val_OverSampler - lookback) // N_BATCH)\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=70,epochs=1,verbose=1,validation_data=val_generator,validation_steps=1)\n",
    "    ACC.extend(history.history['accuracy'])\n",
    "    val_ACC.extend(history.history['val_accuracy'])\n",
    "    val_TopACC.extend(history.history['top_k_categorical_accuracy'])#\n",
    "    if i_s%100==0:\n",
    "        print(ACC)\n",
    "        print(val_ACC)\n",
    "        print(val_TopACC)\n",
    "RNNmodel.save('jjs_model_0204LSTMV3.h5')        \n",
    "print(val_ACC)\n",
    "NP_ACC=np.array(ACC)\n",
    "print(np.sum(NP_ACC)/500)\n",
    "NP_val_ACC=np.array(val_ACC)\n",
    "print(np.sum(NP_val_ACC)/500)\n",
    "NP_val_ACCTop5=np.array(val_TopACC)\n",
    "print(np.sum(NP_val_ACCTop5)/500)\n",
    "\n",
    "score01=RNNmodel.predict(x_batch, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
