{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验R3:引入LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras import layers,metrics\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU, ELU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.utils import shuffle as reset\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "# import \n",
    "from matplotlib.pylab import plt\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler #https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.RandomOverSampler.html?highlight=randomoversampler\n",
    "from frplayer import FilterResponseNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_DataFrame(data, test_size=0.2, considerTime=True, random_state=None):\n",
    "    # ConsiderTime-------trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "    if considerTime:\n",
    "        data=data.sort_values(by=\"Dates\", ascending=True)\n",
    "    else:\n",
    "        data=reset(data, random_state=random_state)\n",
    "    train=data[int(len(data)*test_size):].reset_index(drop=True)\n",
    "    test=data[:int(len(data)*test_size)].reset_index(drop=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj    \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "def Dates2TDMY(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj  \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    #T_D_M_Y=str(time)+str(day)+str(month)+str(year)\n",
    "    T_D_M_Y=str(time)+str(day)+str(month)\n",
    "    return T_D_M_Y\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field2Vec(trainDF,testDF,fieldStr):\n",
    "    fields=sorted(trainDF[fieldStr].unique())\n",
    "    categories=sorted(trainDF[\"Category\"].unique())\n",
    "    C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "    F_C_counts=trainDF.groupby([fieldStr,\"Category\"]).size()\n",
    "    F_counts=trainDF.groupby([fieldStr]).size()\n",
    "    logodds={}\n",
    "    logoddsPF={}\n",
    "    MIN_CAT_COUNTS=2\n",
    "    default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "    for f in fields:\n",
    "        PA=F_counts[f]/float(len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "        logodds[f]=deepcopy(default_logodds)\n",
    "        for cat in F_C_counts[f].keys():\n",
    "            if (F_C_counts[f][cat]>MIN_CAT_COUNTS) and F_C_counts[f][cat]<F_counts[f]:\n",
    "                PA=F_C_counts[f][cat]/float(F_counts[f])\n",
    "                logodds[f][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "        logodds[f]=pd.Series(logodds[f])\n",
    "        logodds[f].index=range(len(categories))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #fieldsTest=sorted(testDF[fieldStr].unique())\n",
    "    #N_count=0\n",
    "    #for f in fieldsTest:\n",
    "        #if f not in fields:\n",
    "            #logoddsPF[f]=-50.0  #np.log(0.)-np.log(1.)=-inf,便于计算，改为-99999.0\n",
    "            #logodds[f]=deepcopy(default_logodds)\n",
    "            #pa=1.0/float(len(categories))\n",
    "            #logodds[f][range(len(categories))]=np.log(pa)-np.log(1.0-pa)\n",
    "            #logodds[f]=pd.Series(logodds[f])\n",
    "            #logodds[f].index=range(len(categories))\n",
    "            #N_count=N_count+1\n",
    "    #print(fieldStr+' N_count: '+str(N_count))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #引进代码原作者的新思想\n",
    "    if testDF.shape[0]>0: #如果testDF里有样本,......\n",
    "        print('There are some new:'+fieldStr)\n",
    "        new_fields=sorted(testDF[fieldStr].unique())\n",
    "        new_F_counts=testDF.groupby(fieldStr).size()\n",
    "        only_new=set(new_fields+fields)-set(fields)\n",
    "        only_old=set(new_fields+fields)-set(new_fields)\n",
    "        in_both=set(new_fields).intersection(fields)\n",
    "        print('# only_new_fieldds:'+str(len(only_new)))\n",
    "        for f in only_new:\n",
    "            PA=new_F_counts[f]/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "            logodds[f]=deepcopy(default_logodds)\n",
    "            logodds[f].index=range(len(categories))\n",
    "        for f in in_both:\n",
    "            PA=(F_counts[f]+new_F_counts[f])/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)    \n",
    "    return logodds,logoddsPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(df,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y=False):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print(\"Creating address features\")###Creating address features###\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds_A[x])\n",
    "    address_features.columns=[\"logodds_A\"+str(x) for x in range(len(address_features.columns))]\n",
    "    if needT_D_M_Y:\n",
    "        print(\"Creating time T_D_M_Y features\")###Creating time T_D_M_Y features###\n",
    "        T_D_M_Y_features=cleanData[\"T_D_M_Y\"].apply(lambda xx: logodds_T[xx])\n",
    "        T_D_M_Y_features.columns=[\"logodds_T\"+str(xx) for xx in range(len(T_D_M_Y_features.columns))]\n",
    "\n",
    "    print(\"Parsing dates\")            ###Creating address features###\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    #     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    #     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print(\"Creating one-hot variables\")\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPF_A\"]=cleanData[\"Address\"].apply(lambda x: logoddsPF_A[x])\n",
    "    if needT_D_M_Y:\n",
    "        cleanData[\"logoddsPF_T\"]=cleanData[\"T_D_M_Y\"].apply(lambda x: logoddsPF_T[x])\n",
    "    print(\"droping processed columns\")\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)    \n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    if needT_D_M_Y:\n",
    "        cleanData=cleanData.drop(\"T_D_M_Y\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print(\"joining one-hot features\")\n",
    "    if needT_D_M_Y:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:]).join(T_D_M_Y_features.iloc[:,:])\n",
    "    else:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:])\n",
    "    print(\"creating new features\")\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(keep='last')).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, Y, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(X) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)#数值在[low, high)区间。\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, X.shape[-1]))\n",
    "        targets = np.zeros((len(rows),Y.shape[1]))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = X[indices]\n",
    "            targets[j] = Y[rows[j]+delay]\n",
    "#         print('# row of Val: '+str(targets.shape[0]))###Tian\n",
    "        yield samples, targets\n",
    "    #Now here is the data generator that we will use. It yields a tuple (samples, targets) where samples is one batch of input data and targets is the corresponding array of target temperatures. It takes the following arguments:\n",
    "        # •data: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "        # •lookback: How many timesteps back should our input data go.\n",
    "        # •delay: How many timesteps in the future should our target be.\n",
    "        # •min_index and max_index: Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another one for testing.\n",
    "        # •shuffle: Whether to shuffle our samples or draw them in chronological order.\n",
    "        # •batch_size: The number of samples per batch.\n",
    "        # •step: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of OrginalAllDF: (878049, 9)\n",
      "The shape of AllDF after del wrong X and Y values: (877982, 9)\n",
      "The shape of AllDF after drop_duplicates: (812529, 9)\n",
      "(689038, 2)\n",
      "Address_counts_allDF_trainDF_testDF: 23191_23191_0\n",
      "The # of AllDF, AllTrain, AllTest, is: 812529,812529,0\n",
      "-----------LOGOODS: Address-------------\n",
      "-----------LOGOODS: T_D_M_Y-------------\n",
      "-----------LOGOODS: parse_data of Alltrain  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPF_A', 'logoddsPF_T', 'PD_BAYVIEW', 'PD_CENTRAL', 'PD_INGLESIDE', 'PD_MISSION', 'PD_NORTHERN', 'PD_PARK', 'PD_RICHMOND', 'PD_SOUTHERN', 'PD_TARAVAL', 'PD_TENDERLOIN', 'DAY_Friday', 'DAY_Monday', 'DAY_Saturday', 'DAY_Sunday', 'DAY_Thursday', 'DAY_Tuesday', 'DAY_Wednesday', 'logodds_A0', 'logodds_A1', 'logodds_A2', 'logodds_A3', 'logodds_A4', 'logodds_A5', 'logodds_A6', 'logodds_A7', 'logodds_A8', 'logodds_A9', 'logodds_A10', 'logodds_A11', 'logodds_A12', 'logodds_A13', 'logodds_A14', 'logodds_A15', 'logodds_A16', 'logodds_A17', 'logodds_A18', 'logodds_A19', 'logodds_A20', 'logodds_A21', 'logodds_A22', 'logodds_A23', 'logodds_A24', 'logodds_A25', 'logodds_A26', 'logodds_A27', 'logodds_A28', 'logodds_A29', 'logodds_A30', 'logodds_A31', 'logodds_A32', 'logodds_A33', 'logodds_A34', 'logodds_A35', 'logodds_A36', 'logodds_A37', 'logodds_A38', 'logodds_T0', 'logodds_T1', 'logodds_T2', 'logodds_T3', 'logodds_T4', 'logodds_T5', 'logodds_T6', 'logodds_T7', 'logodds_T8', 'logodds_T9', 'logodds_T10', 'logodds_T11', 'logodds_T12', 'logodds_T13', 'logodds_T14', 'logodds_T15', 'logodds_T16', 'logodds_T17', 'logodds_T18', 'logodds_T19', 'logodds_T20', 'logodds_T21', 'logodds_T22', 'logodds_T23', 'logodds_T24', 'logodds_T25', 'logodds_T26', 'logodds_T27', 'logodds_T28', 'logodds_T29', 'logodds_T30', 'logodds_T31', 'logodds_T32', 'logodds_T33', 'logodds_T34', 'logodds_T35', 'logodds_T36', 'logodds_T37', 'logodds_T38', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n",
      "110\n",
      "------------Attention: we do not RandomOverSampler---------------\n",
      "------------ConsiderTime:  Sorting--------------\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "ConsiderTime=True#False# True##trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "Rate_ALL=0.0 #0.0即不保留测试机\n",
    "needOverSampler=False\n",
    "needT_D_M_Y=True #False  使用_T_D_M_Y和周几\n",
    "allDF=pd.read_csv(\"./train_addrCorrect.csv\")\n",
    "print('The shape of OrginalAllDF: '+str(allDF.shape))\n",
    "\n",
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(allDF[[\"X\",\"Y\"]])\n",
    "allDF[[\"X\",\"Y\"]]=xy_scaler.transform(allDF[[\"X\",\"Y\"]])\n",
    "allDF=allDF[abs(allDF[\"Y\"])<100]\n",
    "allDF.index=range(len(allDF))\n",
    "print('The shape of AllDF after del wrong X and Y values: '+str(allDF.shape))\n",
    "\n",
    "def listCat(x):\n",
    "    return list(x)\n",
    "allDF.drop_duplicates(inplace=True,subset=['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Category'])\n",
    "Train_duplicated=pd.pivot_table(allDF,index=['Dates','DayOfWeek','PdDistrict', 'Address', 'X', 'Y'], values='Category',aggfunc=[len,listCat])\n",
    "print('The shape of AllDF after drop_duplicates: '+str(allDF.shape))\n",
    "print(Train_duplicated.shape)\n",
    "\n",
    "trainDF,testDF=train_test_split_DataFrame(allDF, test_size=Rate_ALL, considerTime=ConsiderTime, random_state=None)\n",
    "print('Address_counts_allDF_trainDF_testDF: ' + str(len(allDF[\"Address\"].unique())) + '_'+ str(len(trainDF[\"Address\"].unique())) + '_' + str(len(testDF[\"Address\"].unique())))\n",
    "\n",
    "N_AllSample=allDF.shape[0]\n",
    "N_AllTrain=trainDF.shape[0]\n",
    "N_AllTest=testDF.shape[0]\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "print('The # of AllDF, AllTrain, AllTest, is: '+str(N_AllSample)+','+str(N_AllTrain)+','+str(N_AllTest))\n",
    "#################Now proceed as before#################\n",
    "print('-----------LOGOODS: Address-------------')\n",
    "logodds_A,logoddsPF_A=field2Vec(trainDF,testDF,\"Address\")\n",
    "if needT_D_M_Y:\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"Dates\"].apply(Dates2TDMY)\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"T_D_M_Y\"]+trainDF[\"DayOfWeek\"]\n",
    "    if Rate_ALL>0:\n",
    "        testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"Dates\"].apply(Dates2TDMY)\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"T_D_M_Y\"]+testDF[\"DayOfWeek\"]\n",
    "    print('-----------LOGOODS: T_D_M_Y-------------')\n",
    "    logodds_T,logoddsPF_T=field2Vec(trainDF,testDF,\"T_D_M_Y\")    \n",
    "else:\n",
    "    logodds_T=None\n",
    "    logoddsPF_T=None\n",
    "    \n",
    "print('-----------LOGOODS: parse_data of Alltrain  -------------')\n",
    "features, labels=parse_data(trainDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y) \n",
    "if Rate_ALL>0:\n",
    "    print('-----------LOGOODS: parse_data of Alltest  -------------')\n",
    "    features_test, labels_test=parse_data(testDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y)###########和训练集使用同样的时间和地点Logoodds值#####\n",
    "    x_test=features_test.values\n",
    "    y_test=labels_test.values\n",
    "    y_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_test)), num_classes=N_CLASS)\n",
    "\n",
    "print(features.columns.tolist())\n",
    "print(len(features.columns))\n",
    "\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)\n",
    "if Rate_ALL>0:\n",
    "    features_test[collist]=scaler.transform(features_test)###########和训练集使用同样的scaler值#####\n",
    "######################################################\n",
    "#############################先进行过采样，然后再根据时间来排序##################################\n",
    "if needOverSampler:\n",
    "    print('------------RandomOverSampler--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArrayOverSampler, labelsArrayOverSampler = ros.fit_resample(features.values,labels.values)#####过采样#####\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('Shape of OverSampler of AllTrain: '+str(featuresArrayOverSampler.shape))\n",
    "else:\n",
    "    featuresArrayOverSampler=features.values\n",
    "    labelsArrayOverSampler=labels.values\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('------------Attention: we do not RandomOverSampler---------------')\n",
    "if ConsiderTime:\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    print('------------ConsiderTime:  Sorting--------------')\n",
    "    time_temp=featuresArrayOverSampler[:,2]+np.dot(featuresArrayOverSampler[:,3],100)+np.dot(featuresArrayOverSampler[:,4],10000)+np.dot(featuresArrayOverSampler[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresArrayOverSampler,labelsArrayOverSampler))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    labelsArrayOverSampler=features_label_time[:,-2]\n",
    "    featuresArrayOverSampler=features_label_time[:,0:featuresArrayOverSampler.shape[1]]\n",
    "    del features_label_time\n",
    "    #############################先进行过采样，然后再根据时间来排序----结束############################\n",
    "if Rate_ALL>0:\n",
    "    print('------------RandomOverSampler for AllTest--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArray_test, labelsArray_test = ros.fit_resample(features_test.values,labels_test.values)#####过采样#####\n",
    "    N_AllTest_OverSampler=int(featuresArray_test.shape[0])\n",
    "    labelsArray_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArray_test)), num_classes=N_CLASS)\n",
    "    print('Shape of OverSampler of AllTest: '+str(featuresArray_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Building LSTM model--------------\n",
      "N_Train_OverSampler= 162506\n",
      "BlockSize is: 1300\n"
     ]
    }
   ],
   "source": [
    "####TEST DNN\n",
    "print('------------Building LSTM model--------------')\n",
    "ShuffleInTraining=True\n",
    "N_EPOCHS_0=2\n",
    "N_EPOCHS=1\n",
    "N_HN_1=128\n",
    "N_HN=64\n",
    "N_BATCH=64\n",
    "\n",
    "Rate_Val=0.8\n",
    "\n",
    "\n",
    "N_Val_OverSampler=int(np.around(N_AllTrain_OverSampler*Rate_Val))\n",
    "N_Train_OverSampler=int(N_AllTrain_OverSampler-N_Val_OverSampler)\n",
    "print('N_Train_OverSampler= '+str(N_Train_OverSampler))\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresArrayOverSampler.shape[1]\n",
    "output_dim=N_CLASS\n",
    "\n",
    "N_Split=500\n",
    "BlockSize=int(np.floor(N_Val_OverSampler/N_Split))\n",
    "print('BlockSize is: '+str(BlockSize)) \n",
    "lookback=int(BlockSize)\n",
    "delay=-1\n",
    "\n",
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(LSTM(N_HN_1,dropout=0.5, recurrent_dropout=0.5,return_sequences=True,input_shape=(None,input_dim)))\n",
    "RNNmodel.add(LSTM(N_HN,dropout=0.5, recurrent_dropout=0.5,return_sequences=True,))\n",
    "RNNmodel.add(LSTM(N_HN,dropout=0.5, recurrent_dropout=0.5))\n",
    "RNNmodel.add(Dense(output_dim))\n",
    "RNNmodel.add(Activation('softmax'))\n",
    "RNNmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "\n",
    "labelsArrayOverSampler_1hot=keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArrayOverSampler)), num_classes=N_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------')\n",
    "train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=0, max_index=N_Train_OverSampler, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler-lookback, max_index=N_Train_OverSampler+1, shuffle=False, batch_size=N_BATCH, step=1)\n",
    "#数值在[min_index, max_index)区间。当delay=1时，就是用[min_index, max_index)区间的样本预测，第max_index个样本。当delay=2时，就是预测第max_index+1个\n",
    "train_steps= (N_Train_OverSampler-lookback) // N_BATCH\n",
    "val_steps =  1 #(N_Val-lookback) // N_BATCH\n",
    "# test_steps =(N_AllTest - lookback) // N_BATCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------LSTM GO GO GO!!!!---------------------------------------------\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/2\n",
      "2518/2518 [==============================] - 8324s 3s/step - loss: 2.5899 - accuracy: 0.2228 - top_k_categorical_accuracy: 0.6306 - val_loss: 1.9255 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "2518/2518 [==============================] - 7346s 3s/step - loss: 2.4820 - accuracy: 0.2533 - top_k_categorical_accuracy: 0.6653 - val_loss: 2.6210 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "------------LSTM train finished--------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "# history = RNNmodel.fit_generator(train_generator,steps_per_epoch=10,epochs=N_EPOCHS_0,verbose=1)\n",
    "history = RNNmodel.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=N_EPOCHS_0,verbose=1,validation_data=val_generator,validation_steps=val_steps)\n",
    "print('------------LSTM train finished--------------------')\n",
    "RNNmodel.save('jjs_model_0204LSTMV1.h5')\n",
    "# RNNmodel.evaluate_generator(val_generator,steps=1, callbacks=None,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNmodel=load_model('jjs_model_0203LSTMV1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Start the loop training!!---------------------\n",
      "i_s=0 in 500;  max_index=163807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0733 - accuracy: 0.7531 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5512 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125]\n",
      "[0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0]\n",
      "i_s=1 in 500;  max_index=165107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.6894 - accuracy: 0.8969 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.0020 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=2 in 500;  max_index=166407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 22s 4s/step - loss: 3.6007 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3094 - val_loss: 4.4206 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=3 in 500;  max_index=167707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.6625 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.8250 - val_loss: 2.0500 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=4 in 500;  max_index=169007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 3.1091 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3125 - val_loss: 2.6154 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=5 in 500;  max_index=170307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.1339 - accuracy: 0.7844 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.1183 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=6 in 500;  max_index=171607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.8633 - accuracy: 0.0625 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.7797 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=7 in 500;  max_index=172907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.0375 - accuracy: 0.1219 - top_k_categorical_accuracy: 0.9156 - val_loss: 3.4527 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=8 in 500;  max_index=174207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 4.7767 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.1478 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=9 in 500;  max_index=175507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.8674 - accuracy: 0.8562 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4436 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=10 in 500;  max_index=176807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 2.7689 - accuracy: 0.0656 - top_k_categorical_accuracy: 0.5375 - val_loss: 4.1268 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=11 in 500;  max_index=178107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.1375 - accuracy: 0.7719 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.4810 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=12 in 500;  max_index=179407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.4227 - accuracy: 0.2719 - top_k_categorical_accuracy: 0.7906 - val_loss: 2.5631 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=13 in 500;  max_index=180707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.7573 - accuracy: 0.9219 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6154 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=14 in 500;  max_index=182007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.3708 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0188 - val_loss: 2.8965 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=15 in 500;  max_index=183307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 5.4617 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.9633 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=16 in 500;  max_index=184607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.4688 - accuracy: 0.7125 - top_k_categorical_accuracy: 0.9531 - val_loss: 2.6397 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=17 in 500;  max_index=185907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 3.7142 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0031 - val_loss: 3.8470 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=18 in 500;  max_index=187207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 20s 4s/step - loss: 2.2633 - accuracy: 0.0719 - top_k_categorical_accuracy: 0.9688 - val_loss: 2.9778 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=19 in 500;  max_index=188507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.1548 - accuracy: 0.7563 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.3955 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=20 in 500;  max_index=189807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.8989 - accuracy: 0.0063 - top_k_categorical_accuracy: 0.2656 - val_loss: 2.7293 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=21 in 500;  max_index=191107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 21s 4s/step - loss: 2.4120 - accuracy: 0.1063 - top_k_categorical_accuracy: 0.7656 - val_loss: 2.5877 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=22 in 500;  max_index=192407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 2.5401 - accuracy: 0.1906 - top_k_categorical_accuracy: 0.5188 - val_loss: 3.0679 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=23 in 500;  max_index=193707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.9944 - accuracy: 0.0312 - top_k_categorical_accuracy: 0.3969 - val_loss: 3.5376 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=24 in 500;  max_index=195007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 20s 4s/step - loss: 1.8692 - accuracy: 0.4313 - top_k_categorical_accuracy: 0.8656 - val_loss: 1.9460 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=25 in 500;  max_index=196307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.7697 - accuracy: 0.3688 - top_k_categorical_accuracy: 0.9625 - val_loss: 2.0132 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=26 in 500;  max_index=197607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.1588 - accuracy: 0.0312 - top_k_categorical_accuracy: 0.4406 - val_loss: 2.5256 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=27 in 500;  max_index=198907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.5686 - accuracy: 0.3187 - top_k_categorical_accuracy: 0.5688 - val_loss: 4.0942 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=28 in 500;  max_index=200207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.7422 - accuracy: 0.4219 - top_k_categorical_accuracy: 0.9844 - val_loss: 3.0909 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=29 in 500;  max_index=201507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.5647 - accuracy: 0.9344 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5751 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=30 in 500;  max_index=202807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 28s 6s/step - loss: 2.8632 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.5375 - val_loss: 2.6098 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=31 in 500;  max_index=204107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.9224 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.2562 - val_loss: 3.0916 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=32 in 500;  max_index=205407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.6425 - accuracy: 0.5938 - top_k_categorical_accuracy: 0.9438 - val_loss: 2.5272 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=33 in 500;  max_index=206707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.1009 - accuracy: 0.1594 - top_k_categorical_accuracy: 0.7719 - val_loss: 3.5833 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=34 in 500;  max_index=208007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.8611 - accuracy: 0.4750 - top_k_categorical_accuracy: 0.8906 - val_loss: 2.4641 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=35 in 500;  max_index=209307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.7781 - accuracy: 0.8938 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=36 in 500;  max_index=210607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 22s 4s/step - loss: 2.4318 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.7500 - val_loss: 2.7068 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=37 in 500;  max_index=211907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.3829 - accuracy: 0.6781 - top_k_categorical_accuracy: 0.9281 - val_loss: 3.3179 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=38 in 500;  max_index=213207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.9489 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.4186 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=39 in 500;  max_index=214507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 6.4353 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.0125 - val_loss: 5.5280 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=40 in 500;  max_index=215807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.8908 - accuracy: 0.4781 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.3867 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=41 in 500;  max_index=217107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.1693 - accuracy: 0.3469 - top_k_categorical_accuracy: 0.8344 - val_loss: 1.7823 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=42 in 500;  max_index=218407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.1122 - accuracy: 0.7312 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.2326 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=43 in 500;  max_index=219707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 4.5278 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0188 - val_loss: 3.6864 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=44 in 500;  max_index=221007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1959 - accuracy: 0.6281 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9245 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=45 in 500;  max_index=222307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.1533 - accuracy: 0.8938 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.4646 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=46 in 500;  max_index=223607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.8604 - accuracy: 0.2844 - top_k_categorical_accuracy: 0.9656 - val_loss: 2.2362 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=47 in 500;  max_index=224907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0965 - accuracy: 0.9031 - top_k_categorical_accuracy: 0.9937 - val_loss: 2.4242 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=48 in 500;  max_index=226207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 4.0073 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.4239 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=49 in 500;  max_index=227507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.2017 - accuracy: 0.1469 - top_k_categorical_accuracy: 0.9531 - val_loss: 2.8958 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125]\n",
      "i_s=50 in 500;  max_index=228807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.8373 - accuracy: 0.3562 - top_k_categorical_accuracy: 0.9875 - val_loss: 3.0023 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=51 in 500;  max_index=230107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.7900 - accuracy: 0.8938 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5411 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=52 in 500;  max_index=231407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 21s 4s/step - loss: 2.4104 - accuracy: 0.0250 - top_k_categorical_accuracy: 0.8844 - val_loss: 2.4679 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=53 in 500;  max_index=232707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 20s 4s/step - loss: 3.1302 - accuracy: 0.0219 - top_k_categorical_accuracy: 0.3688 - val_loss: 2.8113 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=54 in 500;  max_index=234007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9805 - accuracy: 0.6500 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.4883 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=55 in 500;  max_index=235307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.7733 - accuracy: 0.0063 - top_k_categorical_accuracy: 0.2219 - val_loss: 3.1183 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=56 in 500;  max_index=236607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.7209 - accuracy: 0.0250 - top_k_categorical_accuracy: 0.5906 - val_loss: 3.6822 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=57 in 500;  max_index=237907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 4.1592 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0688 - val_loss: 4.5379 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=58 in 500;  max_index=239207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.5015 - accuracy: 0.1562 - top_k_categorical_accuracy: 0.5656 - val_loss: 1.7058 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=59 in 500;  max_index=240507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.9808 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.1156 - val_loss: 3.8934 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=60 in 500;  max_index=241807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.3537 - accuracy: 0.4187 - top_k_categorical_accuracy: 0.7125 - val_loss: 3.0312 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=61 in 500;  max_index=243107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.6100 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4674 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=62 in 500;  max_index=244407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 5.3767 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.5866 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=63 in 500;  max_index=245707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.3367 - accuracy: 0.3844 - top_k_categorical_accuracy: 0.7937 - val_loss: 5.3350 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=64 in 500;  max_index=247007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.3990 - accuracy: 0.5562 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4334 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=65 in 500;  max_index=248307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.9627 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.1309 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=66 in 500;  max_index=249607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9741 - accuracy: 0.5437 - top_k_categorical_accuracy: 0.9406 - val_loss: 2.0497 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=67 in 500;  max_index=250907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.5815 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.8844 - val_loss: 2.9040 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=68 in 500;  max_index=252207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.8291 - accuracy: 0.9281 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3782 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=69 in 500;  max_index=253507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.7657 - accuracy: 0.9750 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5342 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=70 in 500;  max_index=254807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.3770 - accuracy: 0.0594 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6179 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=71 in 500;  max_index=256107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.6149 - accuracy: 0.2188 - top_k_categorical_accuracy: 0.6938 - val_loss: 2.8718 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=72 in 500;  max_index=257407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.6891 - accuracy: 0.1562 - top_k_categorical_accuracy: 0.7563 - val_loss: 2.8230 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=73 in 500;  max_index=258707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3210 - accuracy: 0.9781 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6305 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=74 in 500;  max_index=260007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.0323 - accuracy: 0.7031 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.2893 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=75 in 500;  max_index=261307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.6474 - accuracy: 0.4313 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.1064 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=76 in 500;  max_index=262607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.3596 - accuracy: 0.2406 - top_k_categorical_accuracy: 0.8750 - val_loss: 3.2884 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=77 in 500;  max_index=263907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.6820 - accuracy: 0.4656 - top_k_categorical_accuracy: 0.8875 - val_loss: 3.4083 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=78 in 500;  max_index=265207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.1463 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3281 - val_loss: 3.1557 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=79 in 500;  max_index=266507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.2632 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0219 - val_loss: 2.9399 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=80 in 500;  max_index=267807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.2139 - accuracy: 0.6969 - top_k_categorical_accuracy: 0.9781 - val_loss: 3.8084 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=81 in 500;  max_index=269107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.9723 - accuracy: 0.0219 - top_k_categorical_accuracy: 0.9469 - val_loss: 2.8902 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=82 in 500;  max_index=270407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.3662 - accuracy: 0.3906 - top_k_categorical_accuracy: 0.7531 - val_loss: 3.3271 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=83 in 500;  max_index=271707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.5490 - accuracy: 0.1719 - top_k_categorical_accuracy: 0.7094 - val_loss: 2.7641 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=84 in 500;  max_index=273007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.5248 - accuracy: 0.6344 - top_k_categorical_accuracy: 0.8813 - val_loss: 3.9039 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=85 in 500;  max_index=274307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3348 - accuracy: 0.6156 - top_k_categorical_accuracy: 0.9563 - val_loss: 2.3872 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=86 in 500;  max_index=275607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 2.2499 - accuracy: 0.3250 - top_k_categorical_accuracy: 0.8281 - val_loss: 2.6922 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=87 in 500;  max_index=276907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.7354 - accuracy: 0.3594 - top_k_categorical_accuracy: 0.9563 - val_loss: 2.9329 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=88 in 500;  max_index=278207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.6276 - accuracy: 0.8125 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5061 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=89 in 500;  max_index=279507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.6752 - accuracy: 0.3531 - top_k_categorical_accuracy: 0.9594 - val_loss: 2.4821 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=90 in 500;  max_index=280807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.4075 - accuracy: 0.7969 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4267 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=91 in 500;  max_index=282107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.3861 - accuracy: 0.1031 - top_k_categorical_accuracy: 0.6656 - val_loss: 2.4503 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=92 in 500;  max_index=283407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.3622 - accuracy: 0.6781 - top_k_categorical_accuracy: 0.9094 - val_loss: 2.5539 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=93 in 500;  max_index=284707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.9310 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.4062 - val_loss: 2.7390 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=94 in 500;  max_index=286007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.3314 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9033 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=95 in 500;  max_index=287307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 4.4426 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0250 - val_loss: 3.5848 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=96 in 500;  max_index=288607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.8371 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3562 - val_loss: 2.6764 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=97 in 500;  max_index=289907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3085 - accuracy: 0.6344 - top_k_categorical_accuracy: 0.9781 - val_loss: 2.1706 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=98 in 500;  max_index=291207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.3967 - accuracy: 0.9375 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5549 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0]\n",
      "i_s=99 in 500;  max_index=292507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3374 - accuracy: 0.5625 - top_k_categorical_accuracy: 0.9594 - val_loss: 2.3670 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=100 in 500;  max_index=293807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 2.0829 - accuracy: 0.1750 - top_k_categorical_accuracy: 0.9000 - val_loss: 2.2555 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=101 in 500;  max_index=295107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6123 - accuracy: 0.8344 - top_k_categorical_accuracy: 0.9906 - val_loss: 0.9071 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=102 in 500;  max_index=296407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.0944 - accuracy: 0.6438 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6216 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=103 in 500;  max_index=297707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 4.2328 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3656 - val_loss: 2.6731 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=104 in 500;  max_index=299007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.8690 - accuracy: 0.4781 - top_k_categorical_accuracy: 0.9062 - val_loss: 2.4639 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=105 in 500;  max_index=300307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.8187 - accuracy: 0.7656 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1017 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=106 in 500;  max_index=301607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5619 - accuracy: 0.8781 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4349 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=107 in 500;  max_index=302907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2211 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2895 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=108 in 500;  max_index=304207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3970 - accuracy: 0.9344 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=109 in 500;  max_index=305507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9372 - accuracy: 0.7906 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6855 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=110 in 500;  max_index=306807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 6.0043 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.8096 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=111 in 500;  max_index=308107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.1607 - accuracy: 0.2812 - top_k_categorical_accuracy: 0.9438 - val_loss: 2.6845 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=112 in 500;  max_index=309407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.5158 - accuracy: 0.8562 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6357 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=113 in 500;  max_index=310707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.4420 - accuracy: 0.5656 - top_k_categorical_accuracy: 0.9125 - val_loss: 0.9006 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=114 in 500;  max_index=312007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6796 - accuracy: 0.8719 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4324 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=115 in 500;  max_index=313307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 2.4006 - accuracy: 0.0094 - top_k_categorical_accuracy: 0.8938 - val_loss: 3.1872 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=116 in 500;  max_index=314607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.5257 - accuracy: 0.5781 - top_k_categorical_accuracy: 0.9781 - val_loss: 2.8187 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=117 in 500;  max_index=315907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.6715 - accuracy: 0.2875 - top_k_categorical_accuracy: 0.9094 - val_loss: 1.9250 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=118 in 500;  max_index=317207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 5.7135 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.8302 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=119 in 500;  max_index=318507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.5191 - accuracy: 0.4156 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.2333 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=120 in 500;  max_index=319807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 2.8731 - accuracy: 0.0281 - top_k_categorical_accuracy: 0.5125 - val_loss: 3.2436 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=121 in 500;  max_index=321107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 4.1219 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.7285 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=122 in 500;  max_index=322407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.8876 - accuracy: 0.3281 - top_k_categorical_accuracy: 0.8813 - val_loss: 2.5690 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=123 in 500;  max_index=323707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.3267 - accuracy: 0.0125 - top_k_categorical_accuracy: 0.7750 - val_loss: 1.6492 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=124 in 500;  max_index=325007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5558 - accuracy: 0.8625 - top_k_categorical_accuracy: 0.9937 - val_loss: 2.4463 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=125 in 500;  max_index=326307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4734 - accuracy: 0.9344 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.5451 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=126 in 500;  max_index=327607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.2774 - accuracy: 0.5875 - top_k_categorical_accuracy: 0.9625 - val_loss: 2.0011 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=127 in 500;  max_index=328907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.5114 - accuracy: 0.5063 - top_k_categorical_accuracy: 0.9656 - val_loss: 1.0313 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=128 in 500;  max_index=330207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.0931 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4478 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=129 in 500;  max_index=331507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2297 - accuracy: 0.5906 - top_k_categorical_accuracy: 0.9812 - val_loss: 2.4473 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=130 in 500;  max_index=332807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3261 - accuracy: 0.8969 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0510 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=131 in 500;  max_index=334107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5925 - accuracy: 0.8531 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9684 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=132 in 500;  max_index=335407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.5992 - accuracy: 0.8375 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8042 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=133 in 500;  max_index=336707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2676 - accuracy: 0.9094 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=134 in 500;  max_index=338007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.0698 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=135 in 500;  max_index=339307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.4825 - accuracy: 0.2625 - top_k_categorical_accuracy: 0.8562 - val_loss: 2.7604 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=136 in 500;  max_index=340607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.4726 - accuracy: 0.2281 - top_k_categorical_accuracy: 0.6875 - val_loss: 3.1689 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=137 in 500;  max_index=341907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.9795 - accuracy: 0.0094 - top_k_categorical_accuracy: 0.2281 - val_loss: 4.5217 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=138 in 500;  max_index=343207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4408 - accuracy: 0.9594 - top_k_categorical_accuracy: 0.9969 - val_loss: 3.2888 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=139 in 500;  max_index=344507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.3426 - accuracy: 0.1594 - top_k_categorical_accuracy: 0.9656 - val_loss: 1.7081 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=140 in 500;  max_index=345807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 6.0869 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.5689 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=141 in 500;  max_index=347107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3158 - accuracy: 0.9937 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7730 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=142 in 500;  max_index=348407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 8.0200 - accuracy: 0.0125 - top_k_categorical_accuracy: 0.0781 - val_loss: 9.2751 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=143 in 500;  max_index=349707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.2222 - accuracy: 0.0719 - top_k_categorical_accuracy: 0.5844 - val_loss: 2.9431 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=144 in 500;  max_index=351007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.3442 - accuracy: 0.6156 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.0646 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=145 in 500;  max_index=352307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.8142 - accuracy: 0.7156 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4689 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=146 in 500;  max_index=353607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.8290 - accuracy: 0.5594 - top_k_categorical_accuracy: 0.8719 - val_loss: 2.4039 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=147 in 500;  max_index=354907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0738 - accuracy: 0.6656 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.0543 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875]\n",
      "i_s=148 in 500;  max_index=356207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.6215 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.1844 - val_loss: 3.1592 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=149 in 500;  max_index=357507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.0750 - accuracy: 0.5813 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.6215 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=150 in 500;  max_index=358807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.9605 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0688 - val_loss: 4.7758 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=151 in 500;  max_index=360107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5498 - accuracy: 0.8719 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5768 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=152 in 500;  max_index=361407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.2126 - accuracy: 0.9688 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9765 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=153 in 500;  max_index=362707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.1235 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1301 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=154 in 500;  max_index=364007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.5709 - accuracy: 0.5844 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.8731 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=155 in 500;  max_index=365307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.9134 - accuracy: 0.4281 - top_k_categorical_accuracy: 0.9594 - val_loss: 2.9036 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=156 in 500;  max_index=366607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.3896 - accuracy: 0.6375 - top_k_categorical_accuracy: 0.9969 - val_loss: 3.0501 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=157 in 500;  max_index=367907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 5.0361 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0031 - val_loss: 3.9717 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=158 in 500;  max_index=369207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.8346 - accuracy: 0.0562 - top_k_categorical_accuracy: 0.7219 - val_loss: 4.0227 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=159 in 500;  max_index=370507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.6164 - accuracy: 0.5250 - top_k_categorical_accuracy: 0.8875 - val_loss: 2.2473 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=160 in 500;  max_index=371807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.9068 - accuracy: 0.7875 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.5564 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=161 in 500;  max_index=373107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.3148 - accuracy: 0.2781 - top_k_categorical_accuracy: 0.8156 - val_loss: 3.5804 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=162 in 500;  max_index=374407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3957 - accuracy: 0.5938 - top_k_categorical_accuracy: 0.9688 - val_loss: 1.2859 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=163 in 500;  max_index=375707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 6.5801 - accuracy: 0.0094 - top_k_categorical_accuracy: 0.0375 - val_loss: 7.0132 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=164 in 500;  max_index=377007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.5495 - accuracy: 0.6531 - top_k_categorical_accuracy: 0.8781 - val_loss: 2.8018 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=165 in 500;  max_index=378307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.7163 - accuracy: 0.5188 - top_k_categorical_accuracy: 0.8687 - val_loss: 3.1037 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=166 in 500;  max_index=379607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.0444 - accuracy: 0.4938 - top_k_categorical_accuracy: 0.9000 - val_loss: 3.7007 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=167 in 500;  max_index=380907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.3408 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.8969 - val_loss: 2.1764 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=168 in 500;  max_index=382207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.1128 - accuracy: 0.1250 - top_k_categorical_accuracy: 0.9656 - val_loss: 2.6478 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=169 in 500;  max_index=383507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.0564 - accuracy: 0.0562 - top_k_categorical_accuracy: 0.3938 - val_loss: 1.8280 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=170 in 500;  max_index=384807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.6443 - accuracy: 0.4969 - top_k_categorical_accuracy: 0.8844 - val_loss: 3.3228 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=171 in 500;  max_index=386107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.5526 - accuracy: 0.4031 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2040 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=172 in 500;  max_index=387407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.0356 - accuracy: 0.7031 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.5405 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=173 in 500;  max_index=388707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.1268 - accuracy: 0.6500 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0670 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=174 in 500;  max_index=390007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.2042 - accuracy: 0.3094 - top_k_categorical_accuracy: 0.7937 - val_loss: 2.2930 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=175 in 500;  max_index=391307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0802 - accuracy: 0.2219 - top_k_categorical_accuracy: 0.8875 - val_loss: 4.0178 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=176 in 500;  max_index=392607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0633 - accuracy: 0.6719 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.5370 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=177 in 500;  max_index=393907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5724 - accuracy: 0.3844 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.0729 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=178 in 500;  max_index=395207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 4.9169 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0094 - val_loss: 3.1572 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=179 in 500;  max_index=396507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0462 - accuracy: 0.7281 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.6851 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=180 in 500;  max_index=397807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.7259 - accuracy: 0.2688 - top_k_categorical_accuracy: 0.9688 - val_loss: 2.7496 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=181 in 500;  max_index=399107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.0546 - accuracy: 0.7219 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5888 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=182 in 500;  max_index=400407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.8496 - accuracy: 0.3250 - top_k_categorical_accuracy: 0.9781 - val_loss: 2.0917 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=183 in 500;  max_index=401707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.4921 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.4625 - val_loss: 3.6777 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=184 in 500;  max_index=403007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.2514 - accuracy: 0.1906 - top_k_categorical_accuracy: 0.8687 - val_loss: 3.3599 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=185 in 500;  max_index=404307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.5405 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.6723 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=186 in 500;  max_index=405607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3943 - accuracy: 0.9719 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7147 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=187 in 500;  max_index=406907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.6328 - accuracy: 0.8938 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2452 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=188 in 500;  max_index=408207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.5910 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.2969 - val_loss: 3.5158 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=189 in 500;  max_index=409507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.1853 - accuracy: 0.1406 - top_k_categorical_accuracy: 0.4875 - val_loss: 3.6655 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=190 in 500;  max_index=410807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 2.9620 - accuracy: 0.0156 - top_k_categorical_accuracy: 0.5156 - val_loss: 4.5693 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=191 in 500;  max_index=412107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6009 - accuracy: 0.9312 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7252 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=192 in 500;  max_index=413407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 20s 4s/step - loss: 3.0286 - accuracy: 0.0125 - top_k_categorical_accuracy: 0.3125 - val_loss: 2.5259 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=193 in 500;  max_index=414707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6140 - accuracy: 0.8781 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.2463 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=194 in 500;  max_index=416007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2975 - accuracy: 0.9750 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9908 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=195 in 500;  max_index=417307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 5.1720 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0562 - val_loss: 5.2247 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=196 in 500;  max_index=418607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 5.3154 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 5.2901 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625, 0.0, 0.58125, 0.0, 0.871875, 0.96875, 0.9875, 0.584375, 0.428125, 0.6375, 0.0, 0.05625, 0.525, 0.7875, 0.278125, 0.59375, 0.009375, 0.653125, 0.51875, 0.49375, 0.0, 0.125, 0.05625, 0.496875, 0.403125, 0.703125, 0.65, 0.309375, 0.221875, 0.671875, 0.384375, 0.0, 0.728125, 0.26875, 0.721875, 0.325, 0.0, 0.190625, 0.0, 0.971875, 0.89375, 0.0, 0.140625, 0.015625, 0.93125, 0.0125, 0.878125, 0.975, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875, 0.184375, 0.996875, 0.06875, 1.0, 1.0, 1.0, 0.996875, 0.959375, 0.996875, 0.003125, 0.721875, 0.8875, 0.984375, 0.815625, 0.96875, 0.0375, 0.878125, 0.86875, 0.9, 0.896875, 0.965625, 0.39375, 0.884375, 1.0, 0.990625, 1.0, 0.79375, 0.8875, 0.990625, 0.996875, 0.009375, 0.990625, 0.96875, 1.0, 0.978125, 0.4625, 0.86875, 0.0, 1.0, 1.0, 0.296875, 0.4875, 0.515625, 1.0, 0.3125, 0.984375, 1.0, 0.05625, 0.0]\n",
      "i_s=197 in 500;  max_index=419907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.2134 - accuracy: 0.4844 - top_k_categorical_accuracy: 0.8000 - val_loss: 4.2535 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=198 in 500;  max_index=421207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.9691 - accuracy: 0.9375 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.9919 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=199 in 500;  max_index=422507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.9832 - accuracy: 0.0250 - top_k_categorical_accuracy: 0.4781 - val_loss: 2.4627 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=200 in 500;  max_index=423807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.9819 - accuracy: 0.0188 - top_k_categorical_accuracy: 0.7156 - val_loss: 2.5397 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=201 in 500;  max_index=425107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2565 - accuracy: 0.7969 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9630 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=202 in 500;  max_index=426407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.7225 - accuracy: 0.0688 - top_k_categorical_accuracy: 0.5750 - val_loss: 1.7076 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=203 in 500;  max_index=427707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.1234 - accuracy: 0.5844 - top_k_categorical_accuracy: 0.9812 - val_loss: 2.2507 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=204 in 500;  max_index=429007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 7.1540 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0031 - val_loss: 7.4275 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=205 in 500;  max_index=430307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.3093 - accuracy: 0.7312 - top_k_categorical_accuracy: 0.9406 - val_loss: 2.1821 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=206 in 500;  max_index=431607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.1204 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.4344 - val_loss: 3.6494 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=207 in 500;  max_index=432907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.9947 - accuracy: 0.5813 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1234 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=208 in 500;  max_index=434207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 4.6700 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 6.3560 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=209 in 500;  max_index=435507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.5343 - accuracy: 0.9438 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8688 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=210 in 500;  max_index=436807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3903 - accuracy: 0.9906 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8596 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=211 in 500;  max_index=438107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.4891 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0375 - val_loss: 4.2937 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=212 in 500;  max_index=439407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.7722 - accuracy: 0.1719 - top_k_categorical_accuracy: 0.6844 - val_loss: 4.3336 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=213 in 500;  max_index=440707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.3050 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.6125 - val_loss: 3.1329 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=214 in 500;  max_index=442007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 4.1032 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0094 - val_loss: 3.6751 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=215 in 500;  max_index=443307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9818 - accuracy: 0.5063 - top_k_categorical_accuracy: 0.8313 - val_loss: 4.0142 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=216 in 500;  max_index=444607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.0703 - accuracy: 0.2875 - top_k_categorical_accuracy: 0.9812 - val_loss: 2.2129 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=217 in 500;  max_index=445907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.0779 - accuracy: 0.2313 - top_k_categorical_accuracy: 0.9688 - val_loss: 2.1231 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=218 in 500;  max_index=447207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.5961 - accuracy: 0.4031 - top_k_categorical_accuracy: 0.9781 - val_loss: 1.1608 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=219 in 500;  max_index=448507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4979 - accuracy: 0.8938 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3950 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=220 in 500;  max_index=449807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.3875 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.5344 - val_loss: 3.0194 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=221 in 500;  max_index=451107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.6964 - accuracy: 0.8250 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4026 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=222 in 500;  max_index=452407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.2878 - accuracy: 0.0375 - top_k_categorical_accuracy: 0.4469 - val_loss: 1.2477 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=223 in 500;  max_index=453707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.7312 - accuracy: 0.3719 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.5462 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=224 in 500;  max_index=455007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.6080 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3688 - val_loss: 3.3126 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=225 in 500;  max_index=456307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2121 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4202 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=226 in 500;  max_index=457607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.0731 - accuracy: 0.6844 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8514 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=227 in 500;  max_index=458907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.8223 - accuracy: 0.8156 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=228 in 500;  max_index=460207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.4108 - accuracy: 0.3875 - top_k_categorical_accuracy: 0.9812 - val_loss: 1.8693 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=229 in 500;  max_index=461507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.9276 - accuracy: 0.0125 - top_k_categorical_accuracy: 0.8062 - val_loss: 2.6416 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=230 in 500;  max_index=462807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.1931 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.4500 - val_loss: 4.0523 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=231 in 500;  max_index=464107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 4.0959 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.0969 - val_loss: 4.1930 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=232 in 500;  max_index=465407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6625 - accuracy: 0.9312 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5267 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=233 in 500;  max_index=466707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.6901 - accuracy: 0.5031 - top_k_categorical_accuracy: 0.9937 - val_loss: 2.5470 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=234 in 500;  max_index=468007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 2.4811 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.8406 - val_loss: 2.6852 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=235 in 500;  max_index=469307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.6828 - accuracy: 0.8406 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5298 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=236 in 500;  max_index=470607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5942 - accuracy: 0.4375 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7076 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=237 in 500;  max_index=471907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 5.7350 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.0612 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=238 in 500;  max_index=473207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.6094 - accuracy: 0.1281 - top_k_categorical_accuracy: 0.6781 - val_loss: 2.0018 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=239 in 500;  max_index=474507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0268 - accuracy: 0.1094 - top_k_categorical_accuracy: 0.9500 - val_loss: 1.9087 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=240 in 500;  max_index=475807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.4032 - accuracy: 0.4187 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7861 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=241 in 500;  max_index=477107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1363 - accuracy: 0.6719 - top_k_categorical_accuracy: 0.9781 - val_loss: 0.8116 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=242 in 500;  max_index=478407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0815 - accuracy: 0.6062 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3997 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=243 in 500;  max_index=479707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.0242 - accuracy: 0.3281 - top_k_categorical_accuracy: 0.8719 - val_loss: 3.1245 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=244 in 500;  max_index=481007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3403 - accuracy: 0.4594 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1031 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=245 in 500;  max_index=482307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.8703 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.1187 - val_loss: 3.9668 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625, 0.0, 0.58125, 0.0, 0.871875, 0.96875, 0.9875, 0.584375, 0.428125, 0.6375, 0.0, 0.05625, 0.525, 0.7875, 0.278125, 0.59375, 0.009375, 0.653125, 0.51875, 0.49375, 0.0, 0.125, 0.05625, 0.496875, 0.403125, 0.703125, 0.65, 0.309375, 0.221875, 0.671875, 0.384375, 0.0, 0.728125, 0.26875, 0.721875, 0.325, 0.0, 0.190625, 0.0, 0.971875, 0.89375, 0.0, 0.140625, 0.015625, 0.93125, 0.0125, 0.878125, 0.975, 0.0, 0.0, 0.484375, 0.9375, 0.025, 0.01875, 0.796875, 0.06875, 0.584375, 0.0, 0.73125, 0.0, 0.58125, 0.0, 0.94375, 0.990625, 0.0, 0.171875, 0.0, 0.0, 0.50625, 0.2875, 0.23125, 0.403125, 0.89375, 0.0, 0.825, 0.0375, 0.371875, 0.0, 0.984375, 0.684375, 0.815625, 0.3875, 0.0125, 0.0, 0.003125, 0.93125, 0.503125, 0.0, 0.840625, 0.4375, 0.0, 0.128125, 0.109375, 0.41875, 0.671875, 0.60625, 0.328125, 0.459375, 0.0]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875, 0.184375, 0.996875, 0.06875, 1.0, 1.0, 1.0, 0.996875, 0.959375, 0.996875, 0.003125, 0.721875, 0.8875, 0.984375, 0.815625, 0.96875, 0.0375, 0.878125, 0.86875, 0.9, 0.896875, 0.965625, 0.39375, 0.884375, 1.0, 0.990625, 1.0, 0.79375, 0.8875, 0.990625, 0.996875, 0.009375, 0.990625, 0.96875, 1.0, 0.978125, 0.4625, 0.86875, 0.0, 1.0, 1.0, 0.296875, 0.4875, 0.515625, 1.0, 0.3125, 0.984375, 1.0, 0.05625, 0.0, 0.8, 0.984375, 0.478125, 0.715625, 1.0, 0.575, 0.98125, 0.003125, 0.940625, 0.434375, 1.0, 0.0, 1.0, 1.0, 0.0375, 0.684375, 0.6125, 0.009375, 0.83125, 0.98125, 0.96875, 0.978125, 1.0, 0.534375, 0.996875, 0.446875, 0.9875, 0.36875, 1.0, 1.0, 1.0, 0.98125, 0.80625, 0.45, 0.096875, 1.0, 0.99375, 0.840625, 1.0, 1.0, 0.0, 0.678125, 0.95, 1.0, 0.978125, 1.0, 0.871875, 1.0, 0.11875]\n",
      "i_s=246 in 500;  max_index=483607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.8192 - accuracy: 0.0312 - top_k_categorical_accuracy: 0.6875 - val_loss: 4.4768 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=247 in 500;  max_index=484907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.7164 - accuracy: 0.2531 - top_k_categorical_accuracy: 0.9781 - val_loss: 2.4245 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=248 in 500;  max_index=486207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6966 - accuracy: 0.8656 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0199 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=249 in 500;  max_index=487507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.3026 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3250 - val_loss: 3.6669 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=250 in 500;  max_index=488807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.7084 - accuracy: 0.4500 - top_k_categorical_accuracy: 0.9187 - val_loss: 2.1891 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=251 in 500;  max_index=490107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2913 - accuracy: 0.5125 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5390 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=252 in 500;  max_index=491407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.8485 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.1187 - val_loss: 3.3467 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=253 in 500;  max_index=492707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.8668 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.4719 - val_loss: 3.1263 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=254 in 500;  max_index=494007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5572 - accuracy: 0.9312 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5525 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=255 in 500;  max_index=495307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2652 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=256 in 500;  max_index=496607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5655 - accuracy: 0.4781 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.1996 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=257 in 500;  max_index=497907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.8328 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.5969 - val_loss: 2.5122 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=258 in 500;  max_index=499207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6204 - accuracy: 0.9469 - top_k_categorical_accuracy: 0.9937 - val_loss: 0.6465 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=259 in 500;  max_index=500507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5783 - accuracy: 0.4375 - top_k_categorical_accuracy: 0.9688 - val_loss: 1.6481 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=260 in 500;  max_index=501807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.8772 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.4094 - val_loss: 2.9720 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=261 in 500;  max_index=503107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0096 - accuracy: 0.8062 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9966 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=262 in 500;  max_index=504407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0713 - accuracy: 0.6938 - top_k_categorical_accuracy: 0.9531 - val_loss: 2.4567 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=263 in 500;  max_index=505707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.1817 - accuracy: 0.5031 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9398 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=264 in 500;  max_index=507007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.9129 - accuracy: 0.0375 - top_k_categorical_accuracy: 0.9438 - val_loss: 2.8501 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=265 in 500;  max_index=508307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2639 - accuracy: 0.6938 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7542 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=266 in 500;  max_index=509607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 6.0564 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.3551 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=267 in 500;  max_index=510907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.0995 - accuracy: 0.8469 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2195 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=268 in 500;  max_index=512207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.3696 - accuracy: 0.4437 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0187 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=269 in 500;  max_index=513507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.0873 - accuracy: 0.0219 - top_k_categorical_accuracy: 0.7375 - val_loss: 3.4357 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=270 in 500;  max_index=514807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 4.5821 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.9268 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=271 in 500;  max_index=516107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9747 - accuracy: 0.8594 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5386 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=272 in 500;  max_index=517407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.8293 - accuracy: 0.4094 - top_k_categorical_accuracy: 0.9312 - val_loss: 2.0127 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=273 in 500;  max_index=518707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.7753 - accuracy: 0.2375 - top_k_categorical_accuracy: 0.9500 - val_loss: 3.6429 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=274 in 500;  max_index=520007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.4880 - accuracy: 0.4531 - top_k_categorical_accuracy: 0.9844 - val_loss: 1.6863 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=275 in 500;  max_index=521307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.9029 - accuracy: 0.7656 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3213 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=276 in 500;  max_index=522607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.4967 - accuracy: 0.4719 - top_k_categorical_accuracy: 0.9406 - val_loss: 2.4349 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=277 in 500;  max_index=523907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.8916 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.1344 - val_loss: 3.4439 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=278 in 500;  max_index=525207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.7794 - accuracy: 0.0719 - top_k_categorical_accuracy: 0.5375 - val_loss: 3.3650 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=279 in 500;  max_index=526507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.2701 - accuracy: 0.0469 - top_k_categorical_accuracy: 0.3906 - val_loss: 4.4570 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=280 in 500;  max_index=527807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.3604 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3209 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=281 in 500;  max_index=529107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4457 - accuracy: 0.9563 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3637 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=282 in 500;  max_index=530407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.7735 - accuracy: 0.3875 - top_k_categorical_accuracy: 0.9094 - val_loss: 2.4911 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=283 in 500;  max_index=531707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.1966 - accuracy: 0.9906 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7503 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=284 in 500;  max_index=533007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3510 - accuracy: 0.5375 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.3300 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=285 in 500;  max_index=534307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.9574 - accuracy: 0.0156 - top_k_categorical_accuracy: 0.2406 - val_loss: 3.7960 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=286 in 500;  max_index=535607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.4869 - accuracy: 0.0688 - top_k_categorical_accuracy: 0.7281 - val_loss: 3.2607 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=287 in 500;  max_index=536907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.9082 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0125 - val_loss: 3.6011 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=288 in 500;  max_index=538207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.1452 - accuracy: 0.0375 - top_k_categorical_accuracy: 0.4344 - val_loss: 3.7179 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=289 in 500;  max_index=539507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.9371 - accuracy: 0.0281 - top_k_categorical_accuracy: 0.4469 - val_loss: 3.4026 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=290 in 500;  max_index=540807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.8304 - accuracy: 0.4469 - top_k_categorical_accuracy: 0.8781 - val_loss: 3.2390 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=291 in 500;  max_index=542107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0723 - accuracy: 0.7281 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.9929 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=292 in 500;  max_index=543407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2630 - accuracy: 0.5906 - top_k_categorical_accuracy: 0.9656 - val_loss: 2.5963 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=293 in 500;  max_index=544707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.3185 - accuracy: 0.2812 - top_k_categorical_accuracy: 0.7750 - val_loss: 4.4168 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=294 in 500;  max_index=546007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5759 - accuracy: 0.5500 - top_k_categorical_accuracy: 0.9312 - val_loss: 2.3662 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625, 0.0, 0.58125, 0.0, 0.871875, 0.96875, 0.9875, 0.584375, 0.428125, 0.6375, 0.0, 0.05625, 0.525, 0.7875, 0.278125, 0.59375, 0.009375, 0.653125, 0.51875, 0.49375, 0.0, 0.125, 0.05625, 0.496875, 0.403125, 0.703125, 0.65, 0.309375, 0.221875, 0.671875, 0.384375, 0.0, 0.728125, 0.26875, 0.721875, 0.325, 0.0, 0.190625, 0.0, 0.971875, 0.89375, 0.0, 0.140625, 0.015625, 0.93125, 0.0125, 0.878125, 0.975, 0.0, 0.0, 0.484375, 0.9375, 0.025, 0.01875, 0.796875, 0.06875, 0.584375, 0.0, 0.73125, 0.0, 0.58125, 0.0, 0.94375, 0.990625, 0.0, 0.171875, 0.0, 0.0, 0.50625, 0.2875, 0.23125, 0.403125, 0.89375, 0.0, 0.825, 0.0375, 0.371875, 0.0, 0.984375, 0.684375, 0.815625, 0.3875, 0.0125, 0.0, 0.003125, 0.93125, 0.503125, 0.0, 0.840625, 0.4375, 0.0, 0.128125, 0.109375, 0.41875, 0.671875, 0.60625, 0.328125, 0.459375, 0.0, 0.03125, 0.253125, 0.865625, 0.0, 0.45, 0.5125, 0.0, 0.0, 0.93125, 0.996875, 0.478125, 0.0, 0.946875, 0.4375, 0.0, 0.80625, 0.69375, 0.503125, 0.0375, 0.69375, 0.0, 0.846875, 0.44375, 0.021875, 0.0, 0.859375, 0.409375, 0.2375, 0.453125, 0.765625, 0.471875, 0.0, 0.071875, 0.046875, 0.984375, 0.95625, 0.3875, 0.990625, 0.5375, 0.015625, 0.06875, 0.0, 0.0375, 0.028125, 0.446875, 0.728125, 0.590625, 0.28125, 0.55]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875, 0.184375, 0.996875, 0.06875, 1.0, 1.0, 1.0, 0.996875, 0.959375, 0.996875, 0.003125, 0.721875, 0.8875, 0.984375, 0.815625, 0.96875, 0.0375, 0.878125, 0.86875, 0.9, 0.896875, 0.965625, 0.39375, 0.884375, 1.0, 0.990625, 1.0, 0.79375, 0.8875, 0.990625, 0.996875, 0.009375, 0.990625, 0.96875, 1.0, 0.978125, 0.4625, 0.86875, 0.0, 1.0, 1.0, 0.296875, 0.4875, 0.515625, 1.0, 0.3125, 0.984375, 1.0, 0.05625, 0.0, 0.8, 0.984375, 0.478125, 0.715625, 1.0, 0.575, 0.98125, 0.003125, 0.940625, 0.434375, 1.0, 0.0, 1.0, 1.0, 0.0375, 0.684375, 0.6125, 0.009375, 0.83125, 0.98125, 0.96875, 0.978125, 1.0, 0.534375, 0.996875, 0.446875, 0.9875, 0.36875, 1.0, 1.0, 1.0, 0.98125, 0.80625, 0.45, 0.096875, 1.0, 0.99375, 0.840625, 1.0, 1.0, 0.0, 0.678125, 0.95, 1.0, 0.978125, 1.0, 0.871875, 1.0, 0.11875, 0.6875, 0.978125, 1.0, 0.325, 0.91875, 1.0, 0.11875, 0.471875, 1.0, 1.0, 0.9875, 0.596875, 0.99375, 0.96875, 0.409375, 1.0, 0.953125, 1.0, 0.94375, 1.0, 0.0, 1.0, 1.0, 0.7375, 0.0, 1.0, 0.93125, 0.95, 0.984375, 1.0, 0.940625, 0.134375, 0.5375, 0.390625, 1.0, 1.0, 0.909375, 1.0, 0.990625, 0.240625, 0.728125, 0.0125, 0.434375, 0.446875, 0.878125, 0.996875, 0.965625, 0.775, 0.93125]\n",
      "i_s=295 in 500;  max_index=547307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4770 - accuracy: 0.9094 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3538 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=296 in 500;  max_index=548607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3629 - accuracy: 0.5375 - top_k_categorical_accuracy: 0.9406 - val_loss: 2.5582 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=297 in 500;  max_index=549907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 3.4904 - accuracy: 0.0063 - top_k_categorical_accuracy: 0.4344 - val_loss: 3.8313 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=298 in 500;  max_index=551207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.7890 - accuracy: 0.0281 - top_k_categorical_accuracy: 0.6094 - val_loss: 3.3992 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=299 in 500;  max_index=552507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.2527 - accuracy: 0.1844 - top_k_categorical_accuracy: 0.8562 - val_loss: 2.0336 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=300 in 500;  max_index=553807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.7807 - accuracy: 0.8250 - top_k_categorical_accuracy: 0.9937 - val_loss: 1.8711 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=301 in 500;  max_index=555107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.6750 - accuracy: 0.5219 - top_k_categorical_accuracy: 0.9250 - val_loss: 1.5906 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=302 in 500;  max_index=556407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.4706 - accuracy: 0.5031 - top_k_categorical_accuracy: 0.9531 - val_loss: 3.1361 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=303 in 500;  max_index=557707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.7631 - accuracy: 0.8031 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.3008 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=304 in 500;  max_index=559007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.6687 - accuracy: 0.0312 - top_k_categorical_accuracy: 0.7531 - val_loss: 2.7326 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=305 in 500;  max_index=560307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5046 - accuracy: 0.9062 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.6029 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=306 in 500;  max_index=561607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 9.0821 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0250 - val_loss: 8.5434 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=307 in 500;  max_index=562907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.0182 - accuracy: 0.2281 - top_k_categorical_accuracy: 0.8813 - val_loss: 2.4260 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=308 in 500;  max_index=564207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5394 - accuracy: 0.4187 - top_k_categorical_accuracy: 0.9438 - val_loss: 0.9862 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=309 in 500;  max_index=565507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.5932 - accuracy: 0.0406 - top_k_categorical_accuracy: 0.8344 - val_loss: 2.6584 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=310 in 500;  max_index=566807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.2945 - accuracy: 0.5625 - top_k_categorical_accuracy: 0.9937 - val_loss: 2.4740 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=311 in 500;  max_index=568107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.8146 - accuracy: 0.8219 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4569 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=312 in 500;  max_index=569407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 5.5629 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0031 - val_loss: 3.8246 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=313 in 500;  max_index=570707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0276 - accuracy: 0.8438 - top_k_categorical_accuracy: 0.9969 - val_loss: 3.1099 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=314 in 500;  max_index=572007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.1825 - accuracy: 0.6594 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.9096 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=315 in 500;  max_index=573307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 5.1817 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0031 - val_loss: 4.2439 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=316 in 500;  max_index=574607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.7596 - accuracy: 0.3719 - top_k_categorical_accuracy: 0.9969 - val_loss: 3.0335 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=317 in 500;  max_index=575907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.2153 - accuracy: 0.6281 - top_k_categorical_accuracy: 0.9656 - val_loss: 1.7000 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=318 in 500;  max_index=577207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5935 - accuracy: 0.9000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7645 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=319 in 500;  max_index=578507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.6090 - accuracy: 0.0938 - top_k_categorical_accuracy: 0.7437 - val_loss: 2.4758 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=320 in 500;  max_index=579807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1131 - accuracy: 0.6625 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.2621 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=321 in 500;  max_index=581107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0908 - accuracy: 0.7031 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.1536 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=322 in 500;  max_index=582407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0066 - accuracy: 0.2406 - top_k_categorical_accuracy: 0.9469 - val_loss: 2.6332 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=323 in 500;  max_index=583707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1207 - accuracy: 0.6062 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2473 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=324 in 500;  max_index=585007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.5205 - accuracy: 0.4906 - top_k_categorical_accuracy: 0.9750 - val_loss: 2.4054 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=325 in 500;  max_index=586307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.1488 - accuracy: 0.6125 - top_k_categorical_accuracy: 0.9937 - val_loss: 2.3386 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=326 in 500;  max_index=587607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.9164 - accuracy: 0.7281 - top_k_categorical_accuracy: 0.9937 - val_loss: 1.9501 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=327 in 500;  max_index=588907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.8265 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.2688 - val_loss: 3.0347 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=328 in 500;  max_index=590207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.4796 - accuracy: 0.4781 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4888 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=329 in 500;  max_index=591507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1404 - accuracy: 0.5688 - top_k_categorical_accuracy: 0.9969 - val_loss: 3.1934 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=330 in 500;  max_index=592807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.6800 - accuracy: 0.3250 - top_k_categorical_accuracy: 0.9812 - val_loss: 2.0421 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=331 in 500;  max_index=594107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.3665 - accuracy: 0.5094 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4573 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=332 in 500;  max_index=595407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.2500 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.6375 - val_loss: 2.7181 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=333 in 500;  max_index=596707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.4302 - accuracy: 0.9219 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8639 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=334 in 500;  max_index=598007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.4796 - accuracy: 0.0312 - top_k_categorical_accuracy: 0.9937 - val_loss: 0.8038 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=335 in 500;  max_index=599307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.9157 - accuracy: 0.6969 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2060 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=336 in 500;  max_index=600607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 5.4698 - accuracy: 0.0094 - top_k_categorical_accuracy: 0.0500 - val_loss: 4.1287 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=337 in 500;  max_index=601907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9391 - accuracy: 0.2625 - top_k_categorical_accuracy: 0.9281 - val_loss: 2.4059 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=338 in 500;  max_index=603207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.8881 - accuracy: 0.8062 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=339 in 500;  max_index=604507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.3778 - accuracy: 0.5281 - top_k_categorical_accuracy: 0.9563 - val_loss: 1.4204 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=340 in 500;  max_index=605807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.7329 - accuracy: 0.0844 - top_k_categorical_accuracy: 0.8906 - val_loss: 2.5218 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=341 in 500;  max_index=607107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.9099 - accuracy: 0.8094 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9046 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=342 in 500;  max_index=608407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0428 - accuracy: 0.6094 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.0172 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=343 in 500;  max_index=609707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.5022 - accuracy: 0.0812 - top_k_categorical_accuracy: 0.9406 - val_loss: 2.4064 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625, 0.0, 0.58125, 0.0, 0.871875, 0.96875, 0.9875, 0.584375, 0.428125, 0.6375, 0.0, 0.05625, 0.525, 0.7875, 0.278125, 0.59375, 0.009375, 0.653125, 0.51875, 0.49375, 0.0, 0.125, 0.05625, 0.496875, 0.403125, 0.703125, 0.65, 0.309375, 0.221875, 0.671875, 0.384375, 0.0, 0.728125, 0.26875, 0.721875, 0.325, 0.0, 0.190625, 0.0, 0.971875, 0.89375, 0.0, 0.140625, 0.015625, 0.93125, 0.0125, 0.878125, 0.975, 0.0, 0.0, 0.484375, 0.9375, 0.025, 0.01875, 0.796875, 0.06875, 0.584375, 0.0, 0.73125, 0.0, 0.58125, 0.0, 0.94375, 0.990625, 0.0, 0.171875, 0.0, 0.0, 0.50625, 0.2875, 0.23125, 0.403125, 0.89375, 0.0, 0.825, 0.0375, 0.371875, 0.0, 0.984375, 0.684375, 0.815625, 0.3875, 0.0125, 0.0, 0.003125, 0.93125, 0.503125, 0.0, 0.840625, 0.4375, 0.0, 0.128125, 0.109375, 0.41875, 0.671875, 0.60625, 0.328125, 0.459375, 0.0, 0.03125, 0.253125, 0.865625, 0.0, 0.45, 0.5125, 0.0, 0.0, 0.93125, 0.996875, 0.478125, 0.0, 0.946875, 0.4375, 0.0, 0.80625, 0.69375, 0.503125, 0.0375, 0.69375, 0.0, 0.846875, 0.44375, 0.021875, 0.0, 0.859375, 0.409375, 0.2375, 0.453125, 0.765625, 0.471875, 0.0, 0.071875, 0.046875, 0.984375, 0.95625, 0.3875, 0.990625, 0.5375, 0.015625, 0.06875, 0.0, 0.0375, 0.028125, 0.446875, 0.728125, 0.590625, 0.28125, 0.55, 0.909375, 0.5375, 0.00625, 0.028125, 0.184375, 0.825, 0.521875, 0.503125, 0.803125, 0.03125, 0.90625, 0.0, 0.228125, 0.41875, 0.040625, 0.5625, 0.821875, 0.0, 0.84375, 0.659375, 0.0, 0.371875, 0.628125, 0.9, 0.09375, 0.6625, 0.703125, 0.240625, 0.60625, 0.490625, 0.6125, 0.728125, 0.0, 0.478125, 0.56875, 0.325, 0.509375, 0.003125, 0.921875, 0.03125, 0.696875, 0.009375, 0.2625, 0.80625, 0.528125, 0.084375, 0.809375, 0.609375, 0.08125]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875, 0.184375, 0.996875, 0.06875, 1.0, 1.0, 1.0, 0.996875, 0.959375, 0.996875, 0.003125, 0.721875, 0.8875, 0.984375, 0.815625, 0.96875, 0.0375, 0.878125, 0.86875, 0.9, 0.896875, 0.965625, 0.39375, 0.884375, 1.0, 0.990625, 1.0, 0.79375, 0.8875, 0.990625, 0.996875, 0.009375, 0.990625, 0.96875, 1.0, 0.978125, 0.4625, 0.86875, 0.0, 1.0, 1.0, 0.296875, 0.4875, 0.515625, 1.0, 0.3125, 0.984375, 1.0, 0.05625, 0.0, 0.8, 0.984375, 0.478125, 0.715625, 1.0, 0.575, 0.98125, 0.003125, 0.940625, 0.434375, 1.0, 0.0, 1.0, 1.0, 0.0375, 0.684375, 0.6125, 0.009375, 0.83125, 0.98125, 0.96875, 0.978125, 1.0, 0.534375, 0.996875, 0.446875, 0.9875, 0.36875, 1.0, 1.0, 1.0, 0.98125, 0.80625, 0.45, 0.096875, 1.0, 0.99375, 0.840625, 1.0, 1.0, 0.0, 0.678125, 0.95, 1.0, 0.978125, 1.0, 0.871875, 1.0, 0.11875, 0.6875, 0.978125, 1.0, 0.325, 0.91875, 1.0, 0.11875, 0.471875, 1.0, 1.0, 0.9875, 0.596875, 0.99375, 0.96875, 0.409375, 1.0, 0.953125, 1.0, 0.94375, 1.0, 0.0, 1.0, 1.0, 0.7375, 0.0, 1.0, 0.93125, 0.95, 0.984375, 1.0, 0.940625, 0.134375, 0.5375, 0.390625, 1.0, 1.0, 0.909375, 1.0, 0.990625, 0.240625, 0.728125, 0.0125, 0.434375, 0.446875, 0.878125, 0.996875, 0.965625, 0.775, 0.93125, 1.0, 0.940625, 0.434375, 0.609375, 0.85625, 0.99375, 0.925, 0.953125, 0.990625, 0.753125, 0.9875, 0.025, 0.88125, 0.94375, 0.834375, 0.99375, 1.0, 0.003125, 0.996875, 0.990625, 0.003125, 0.996875, 0.965625, 1.0, 0.74375, 0.990625, 0.990625, 0.946875, 1.0, 0.975, 0.99375, 0.99375, 0.26875, 0.996875, 0.996875, 0.98125, 0.996875, 0.6375, 1.0, 0.99375, 1.0, 0.05, 0.928125, 1.0, 0.95625, 0.890625, 1.0, 0.984375, 0.940625]\n",
      "i_s=344 in 500;  max_index=611007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.8244 - accuracy: 0.7406 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7925 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=345 in 500;  max_index=612307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3467 - accuracy: 0.9531 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8466 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=346 in 500;  max_index=613607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 6.4062 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.3868 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=347 in 500;  max_index=614907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2178 - accuracy: 0.9937 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7712 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=348 in 500;  max_index=616207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.9750 - accuracy: 0.3469 - top_k_categorical_accuracy: 0.8938 - val_loss: 2.3287 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=349 in 500;  max_index=617507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0858 - accuracy: 0.6250 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.7698 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=350 in 500;  max_index=618807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.5536 - accuracy: 0.4281 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4402 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=351 in 500;  max_index=620107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.7403 - accuracy: 0.7281 - top_k_categorical_accuracy: 0.9937 - val_loss: 1.6016 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=352 in 500;  max_index=621407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.1178 - accuracy: 0.2594 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4895 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=353 in 500;  max_index=622707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.7382 - accuracy: 0.4406 - top_k_categorical_accuracy: 0.9656 - val_loss: 1.3202 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=354 in 500;  max_index=624007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.9608 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0063 - val_loss: 4.2539 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=355 in 500;  max_index=625307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2966 - accuracy: 0.5469 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6618 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=356 in 500;  max_index=626607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 6.1511 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.7423 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=357 in 500;  max_index=627907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.6488 - accuracy: 0.8813 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6301 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=358 in 500;  max_index=629207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3063 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9299 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=359 in 500;  max_index=630507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 4.2719 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.2281 - val_loss: 4.3250 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=360 in 500;  max_index=631807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1433 - accuracy: 0.6500 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.5192 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=361 in 500;  max_index=633107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9638 - accuracy: 0.3000 - top_k_categorical_accuracy: 0.9719 - val_loss: 1.4514 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=362 in 500;  max_index=634407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.9934 - accuracy: 0.6719 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9684 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=363 in 500;  max_index=635707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 3.6267 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.3906 - val_loss: 3.4945 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=364 in 500;  max_index=637007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9348 - accuracy: 0.2313 - top_k_categorical_accuracy: 0.9844 - val_loss: 3.3384 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=365 in 500;  max_index=638307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.4548 - accuracy: 0.5594 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5185 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=366 in 500;  max_index=639607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 4.6202 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0094 - val_loss: 3.5134 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=367 in 500;  max_index=640907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.1110 - accuracy: 0.6750 - top_k_categorical_accuracy: 0.9719 - val_loss: 2.4468 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=368 in 500;  max_index=642207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.2884 - accuracy: 0.0125 - top_k_categorical_accuracy: 0.5125 - val_loss: 2.8739 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=369 in 500;  max_index=643507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 4.0048 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0531 - val_loss: 3.7310 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=370 in 500;  max_index=644807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.7005 - accuracy: 0.4969 - top_k_categorical_accuracy: 0.9375 - val_loss: 2.0880 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=371 in 500;  max_index=646107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.6676 - accuracy: 0.4062 - top_k_categorical_accuracy: 0.9281 - val_loss: 1.6420 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=372 in 500;  max_index=647407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.8806 - accuracy: 0.0094 - top_k_categorical_accuracy: 0.5813 - val_loss: 3.8435 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=373 in 500;  max_index=648707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.0751 - accuracy: 0.0719 - top_k_categorical_accuracy: 0.4688 - val_loss: 2.7457 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=374 in 500;  max_index=650007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.8705 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0219 - val_loss: 3.2653 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=375 in 500;  max_index=651307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.2794 - accuracy: 0.7344 - top_k_categorical_accuracy: 0.9937 - val_loss: 2.6244 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=376 in 500;  max_index=652607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.6210 - accuracy: 0.3281 - top_k_categorical_accuracy: 0.9594 - val_loss: 1.0581 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=377 in 500;  max_index=653907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.6420 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.9502 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=378 in 500;  max_index=655207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.7365 - accuracy: 0.8406 - top_k_categorical_accuracy: 0.9937 - val_loss: 2.0221 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=379 in 500;  max_index=656507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5178 - accuracy: 0.9594 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0327 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=380 in 500;  max_index=657807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.1923 - accuracy: 0.9937 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=381 in 500;  max_index=659107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.2475 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.3281 - val_loss: 3.8745 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=382 in 500;  max_index=660407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.7268 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.1281 - val_loss: 3.4741 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=383 in 500;  max_index=661707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.1598 - accuracy: 0.7594 - top_k_categorical_accuracy: 0.9844 - val_loss: 1.1089 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=384 in 500;  max_index=663007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.7560 - accuracy: 0.4000 - top_k_categorical_accuracy: 0.9594 - val_loss: 1.5431 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=385 in 500;  max_index=664307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4730 - accuracy: 0.9281 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.8841 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=386 in 500;  max_index=665607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.2092 - accuracy: 0.2188 - top_k_categorical_accuracy: 0.8625 - val_loss: 2.1702 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=387 in 500;  max_index=666907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.3414 - accuracy: 0.2156 - top_k_categorical_accuracy: 0.9812 - val_loss: 1.7903 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=388 in 500;  max_index=668207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.8081 - accuracy: 0.7031 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0267 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=389 in 500;  max_index=669507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 6.1934 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0031 - val_loss: 3.6829 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=390 in 500;  max_index=670807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.6808 - accuracy: 0.0188 - top_k_categorical_accuracy: 0.9312 - val_loss: 2.2039 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=391 in 500;  max_index=672107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.9926 - accuracy: 0.7063 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3099 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=392 in 500;  max_index=673407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.4726 - accuracy: 0.3812 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.3205 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625, 0.0, 0.58125, 0.0, 0.871875, 0.96875, 0.9875, 0.584375, 0.428125, 0.6375, 0.0, 0.05625, 0.525, 0.7875, 0.278125, 0.59375, 0.009375, 0.653125, 0.51875, 0.49375, 0.0, 0.125, 0.05625, 0.496875, 0.403125, 0.703125, 0.65, 0.309375, 0.221875, 0.671875, 0.384375, 0.0, 0.728125, 0.26875, 0.721875, 0.325, 0.0, 0.190625, 0.0, 0.971875, 0.89375, 0.0, 0.140625, 0.015625, 0.93125, 0.0125, 0.878125, 0.975, 0.0, 0.0, 0.484375, 0.9375, 0.025, 0.01875, 0.796875, 0.06875, 0.584375, 0.0, 0.73125, 0.0, 0.58125, 0.0, 0.94375, 0.990625, 0.0, 0.171875, 0.0, 0.0, 0.50625, 0.2875, 0.23125, 0.403125, 0.89375, 0.0, 0.825, 0.0375, 0.371875, 0.0, 0.984375, 0.684375, 0.815625, 0.3875, 0.0125, 0.0, 0.003125, 0.93125, 0.503125, 0.0, 0.840625, 0.4375, 0.0, 0.128125, 0.109375, 0.41875, 0.671875, 0.60625, 0.328125, 0.459375, 0.0, 0.03125, 0.253125, 0.865625, 0.0, 0.45, 0.5125, 0.0, 0.0, 0.93125, 0.996875, 0.478125, 0.0, 0.946875, 0.4375, 0.0, 0.80625, 0.69375, 0.503125, 0.0375, 0.69375, 0.0, 0.846875, 0.44375, 0.021875, 0.0, 0.859375, 0.409375, 0.2375, 0.453125, 0.765625, 0.471875, 0.0, 0.071875, 0.046875, 0.984375, 0.95625, 0.3875, 0.990625, 0.5375, 0.015625, 0.06875, 0.0, 0.0375, 0.028125, 0.446875, 0.728125, 0.590625, 0.28125, 0.55, 0.909375, 0.5375, 0.00625, 0.028125, 0.184375, 0.825, 0.521875, 0.503125, 0.803125, 0.03125, 0.90625, 0.0, 0.228125, 0.41875, 0.040625, 0.5625, 0.821875, 0.0, 0.84375, 0.659375, 0.0, 0.371875, 0.628125, 0.9, 0.09375, 0.6625, 0.703125, 0.240625, 0.60625, 0.490625, 0.6125, 0.728125, 0.0, 0.478125, 0.56875, 0.325, 0.509375, 0.003125, 0.921875, 0.03125, 0.696875, 0.009375, 0.2625, 0.80625, 0.528125, 0.084375, 0.809375, 0.609375, 0.08125, 0.740625, 0.953125, 0.0, 0.99375, 0.346875, 0.625, 0.428125, 0.728125, 0.259375, 0.440625, 0.0, 0.546875, 0.0, 0.88125, 0.9875, 0.0, 0.65, 0.3, 0.671875, 0.003125, 0.23125, 0.559375, 0.0, 0.675, 0.0125, 0.0, 0.496875, 0.40625, 0.009375, 0.071875, 0.0, 0.734375, 0.328125, 0.0, 0.840625, 0.959375, 0.99375, 0.003125, 0.003125, 0.759375, 0.4, 0.928125, 0.21875, 0.215625, 0.703125, 0.0, 0.01875, 0.70625, 0.38125]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875, 0.184375, 0.996875, 0.06875, 1.0, 1.0, 1.0, 0.996875, 0.959375, 0.996875, 0.003125, 0.721875, 0.8875, 0.984375, 0.815625, 0.96875, 0.0375, 0.878125, 0.86875, 0.9, 0.896875, 0.965625, 0.39375, 0.884375, 1.0, 0.990625, 1.0, 0.79375, 0.8875, 0.990625, 0.996875, 0.009375, 0.990625, 0.96875, 1.0, 0.978125, 0.4625, 0.86875, 0.0, 1.0, 1.0, 0.296875, 0.4875, 0.515625, 1.0, 0.3125, 0.984375, 1.0, 0.05625, 0.0, 0.8, 0.984375, 0.478125, 0.715625, 1.0, 0.575, 0.98125, 0.003125, 0.940625, 0.434375, 1.0, 0.0, 1.0, 1.0, 0.0375, 0.684375, 0.6125, 0.009375, 0.83125, 0.98125, 0.96875, 0.978125, 1.0, 0.534375, 0.996875, 0.446875, 0.9875, 0.36875, 1.0, 1.0, 1.0, 0.98125, 0.80625, 0.45, 0.096875, 1.0, 0.99375, 0.840625, 1.0, 1.0, 0.0, 0.678125, 0.95, 1.0, 0.978125, 1.0, 0.871875, 1.0, 0.11875, 0.6875, 0.978125, 1.0, 0.325, 0.91875, 1.0, 0.11875, 0.471875, 1.0, 1.0, 0.9875, 0.596875, 0.99375, 0.96875, 0.409375, 1.0, 0.953125, 1.0, 0.94375, 1.0, 0.0, 1.0, 1.0, 0.7375, 0.0, 1.0, 0.93125, 0.95, 0.984375, 1.0, 0.940625, 0.134375, 0.5375, 0.390625, 1.0, 1.0, 0.909375, 1.0, 0.990625, 0.240625, 0.728125, 0.0125, 0.434375, 0.446875, 0.878125, 0.996875, 0.965625, 0.775, 0.93125, 1.0, 0.940625, 0.434375, 0.609375, 0.85625, 0.99375, 0.925, 0.953125, 0.990625, 0.753125, 0.9875, 0.025, 0.88125, 0.94375, 0.834375, 0.99375, 1.0, 0.003125, 0.996875, 0.990625, 0.003125, 0.996875, 0.965625, 1.0, 0.74375, 0.990625, 0.990625, 0.946875, 1.0, 0.975, 0.99375, 0.99375, 0.26875, 0.996875, 0.996875, 0.98125, 0.996875, 0.6375, 1.0, 0.99375, 1.0, 0.05, 0.928125, 1.0, 0.95625, 0.890625, 1.0, 0.984375, 0.940625, 1.0, 1.0, 0.0, 1.0, 0.89375, 0.996875, 1.0, 0.99375, 0.996875, 0.965625, 0.00625, 1.0, 0.0, 1.0, 1.0, 0.228125, 0.990625, 0.971875, 1.0, 0.390625, 0.984375, 1.0, 0.009375, 0.971875, 0.5125, 0.053125, 0.9375, 0.928125, 0.58125, 0.46875, 0.021875, 0.99375, 0.959375, 0.0, 0.99375, 1.0, 1.0, 0.328125, 0.128125, 0.984375, 0.959375, 0.996875, 0.8625, 0.98125, 1.0, 0.003125, 0.93125, 1.0, 0.990625]\n",
      "i_s=393 in 500;  max_index=674707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2892 - accuracy: 0.3750 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1528 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=394 in 500;  max_index=676007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.2294 - accuracy: 0.0156 - top_k_categorical_accuracy: 0.5781 - val_loss: 3.7607 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=395 in 500;  max_index=677307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.6192 - accuracy: 0.9750 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6478 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=396 in 500;  max_index=678607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.7229 - accuracy: 0.7000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1100 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=397 in 500;  max_index=679907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 4.5072 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0469 - val_loss: 4.0339 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=398 in 500;  max_index=681207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.5371 - accuracy: 0.9156 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6616 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=399 in 500;  max_index=682507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0192 - accuracy: 0.3156 - top_k_categorical_accuracy: 0.9406 - val_loss: 4.2561 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=400 in 500;  max_index=683807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.8027 - accuracy: 0.8250 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.6570 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=401 in 500;  max_index=685107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.5598 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.4000 - val_loss: 2.7402 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=402 in 500;  max_index=686407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.9738 - accuracy: 0.5875 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4595 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=403 in 500;  max_index=687707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.4843 - accuracy: 0.8375 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0053 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=404 in 500;  max_index=689007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0283 - accuracy: 0.7625 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.7860 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=405 in 500;  max_index=690307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.6352 - accuracy: 0.2937 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1836 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=406 in 500;  max_index=691607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.4187 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.1531 - val_loss: 3.3933 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=407 in 500;  max_index=692907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.8498 - accuracy: 0.3719 - top_k_categorical_accuracy: 0.9656 - val_loss: 3.1340 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=408 in 500;  max_index=694207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.0537 - accuracy: 0.6438 - top_k_categorical_accuracy: 0.9781 - val_loss: 2.3428 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=409 in 500;  max_index=695507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.0084 - accuracy: 0.0125 - top_k_categorical_accuracy: 0.6125 - val_loss: 2.9068 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=410 in 500;  max_index=696807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.6935 - accuracy: 0.9031 - top_k_categorical_accuracy: 0.9937 - val_loss: 1.9119 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=411 in 500;  max_index=698107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.7263 - accuracy: 0.3531 - top_k_categorical_accuracy: 0.9656 - val_loss: 2.2742 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=412 in 500;  max_index=699407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.5384 - accuracy: 0.9062 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8412 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=413 in 500;  max_index=700707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.4102 - accuracy: 0.8969 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6766 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=414 in 500;  max_index=702007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.3609 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.3969 - val_loss: 2.6899 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=415 in 500;  max_index=703307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.9055 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.1656 - val_loss: 2.6836 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=416 in 500;  max_index=704607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1811 - accuracy: 0.7125 - top_k_categorical_accuracy: 0.9688 - val_loss: 1.5735 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=417 in 500;  max_index=705907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.8118 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0437 - val_loss: 4.4256 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=418 in 500;  max_index=707207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.5595 - accuracy: 0.0625 - top_k_categorical_accuracy: 0.8719 - val_loss: 3.3460 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=419 in 500;  max_index=708507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.0878 - accuracy: 0.0406 - top_k_categorical_accuracy: 0.4219 - val_loss: 3.6120 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=420 in 500;  max_index=709807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.8674 - accuracy: 0.4688 - top_k_categorical_accuracy: 0.9375 - val_loss: 1.1697 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=421 in 500;  max_index=711107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.8528 - accuracy: 0.0156 - top_k_categorical_accuracy: 0.5813 - val_loss: 1.8483 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=422 in 500;  max_index=712407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5253 - accuracy: 0.4938 - top_k_categorical_accuracy: 0.9031 - val_loss: 1.7868 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=423 in 500;  max_index=713707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 4.9753 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.1483 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=424 in 500;  max_index=715007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.1496 - accuracy: 0.8594 - top_k_categorical_accuracy: 0.9719 - val_loss: 1.9790 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=425 in 500;  max_index=716307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.8954 - accuracy: 0.3812 - top_k_categorical_accuracy: 0.9219 - val_loss: 3.3222 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=426 in 500;  max_index=717607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 3.2917 - accuracy: 0.0344 - top_k_categorical_accuracy: 0.3187 - val_loss: 3.7072 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=427 in 500;  max_index=718907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3521 - accuracy: 0.9375 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.9139 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=428 in 500;  max_index=720207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.9120 - accuracy: 0.4000 - top_k_categorical_accuracy: 0.9406 - val_loss: 2.8159 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=429 in 500;  max_index=721507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.8038 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.5406 - val_loss: 2.9632 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=430 in 500;  max_index=722807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.7227 - accuracy: 0.0594 - top_k_categorical_accuracy: 0.6281 - val_loss: 2.4630 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=431 in 500;  max_index=724107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.1590 - accuracy: 0.7500 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.0896 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=432 in 500;  max_index=725407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.7255 - accuracy: 0.9406 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3666 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=433 in 500;  max_index=726707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.1531 - accuracy: 0.2594 - top_k_categorical_accuracy: 0.8906 - val_loss: 1.6900 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=434 in 500;  max_index=728007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.8075 - accuracy: 0.7937 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1891 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=435 in 500;  max_index=729307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.3355 - accuracy: 0.9875 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1117 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=436 in 500;  max_index=730607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.0830 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0266 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=437 in 500;  max_index=731907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1574 - accuracy: 0.9937 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0256 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=438 in 500;  max_index=733207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.3593 - accuracy: 0.0781 - top_k_categorical_accuracy: 0.9969 - val_loss: 3.2756 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=439 in 500;  max_index=734507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.4140 - accuracy: 0.5375 - top_k_categorical_accuracy: 0.9563 - val_loss: 1.9469 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=440 in 500;  max_index=735807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.2011 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9668 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=441 in 500;  max_index=737107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0480 - accuracy: 0.2688 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.9617 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625, 0.0, 0.58125, 0.0, 0.871875, 0.96875, 0.9875, 0.584375, 0.428125, 0.6375, 0.0, 0.05625, 0.525, 0.7875, 0.278125, 0.59375, 0.009375, 0.653125, 0.51875, 0.49375, 0.0, 0.125, 0.05625, 0.496875, 0.403125, 0.703125, 0.65, 0.309375, 0.221875, 0.671875, 0.384375, 0.0, 0.728125, 0.26875, 0.721875, 0.325, 0.0, 0.190625, 0.0, 0.971875, 0.89375, 0.0, 0.140625, 0.015625, 0.93125, 0.0125, 0.878125, 0.975, 0.0, 0.0, 0.484375, 0.9375, 0.025, 0.01875, 0.796875, 0.06875, 0.584375, 0.0, 0.73125, 0.0, 0.58125, 0.0, 0.94375, 0.990625, 0.0, 0.171875, 0.0, 0.0, 0.50625, 0.2875, 0.23125, 0.403125, 0.89375, 0.0, 0.825, 0.0375, 0.371875, 0.0, 0.984375, 0.684375, 0.815625, 0.3875, 0.0125, 0.0, 0.003125, 0.93125, 0.503125, 0.0, 0.840625, 0.4375, 0.0, 0.128125, 0.109375, 0.41875, 0.671875, 0.60625, 0.328125, 0.459375, 0.0, 0.03125, 0.253125, 0.865625, 0.0, 0.45, 0.5125, 0.0, 0.0, 0.93125, 0.996875, 0.478125, 0.0, 0.946875, 0.4375, 0.0, 0.80625, 0.69375, 0.503125, 0.0375, 0.69375, 0.0, 0.846875, 0.44375, 0.021875, 0.0, 0.859375, 0.409375, 0.2375, 0.453125, 0.765625, 0.471875, 0.0, 0.071875, 0.046875, 0.984375, 0.95625, 0.3875, 0.990625, 0.5375, 0.015625, 0.06875, 0.0, 0.0375, 0.028125, 0.446875, 0.728125, 0.590625, 0.28125, 0.55, 0.909375, 0.5375, 0.00625, 0.028125, 0.184375, 0.825, 0.521875, 0.503125, 0.803125, 0.03125, 0.90625, 0.0, 0.228125, 0.41875, 0.040625, 0.5625, 0.821875, 0.0, 0.84375, 0.659375, 0.0, 0.371875, 0.628125, 0.9, 0.09375, 0.6625, 0.703125, 0.240625, 0.60625, 0.490625, 0.6125, 0.728125, 0.0, 0.478125, 0.56875, 0.325, 0.509375, 0.003125, 0.921875, 0.03125, 0.696875, 0.009375, 0.2625, 0.80625, 0.528125, 0.084375, 0.809375, 0.609375, 0.08125, 0.740625, 0.953125, 0.0, 0.99375, 0.346875, 0.625, 0.428125, 0.728125, 0.259375, 0.440625, 0.0, 0.546875, 0.0, 0.88125, 0.9875, 0.0, 0.65, 0.3, 0.671875, 0.003125, 0.23125, 0.559375, 0.0, 0.675, 0.0125, 0.0, 0.496875, 0.40625, 0.009375, 0.071875, 0.0, 0.734375, 0.328125, 0.0, 0.840625, 0.959375, 0.99375, 0.003125, 0.003125, 0.759375, 0.4, 0.928125, 0.21875, 0.215625, 0.703125, 0.0, 0.01875, 0.70625, 0.38125, 0.375, 0.015625, 0.975, 0.7, 0.0, 0.915625, 0.315625, 0.825, 0.0, 0.5875, 0.8375, 0.7625, 0.29375, 0.0, 0.371875, 0.64375, 0.0125, 0.903125, 0.353125, 0.90625, 0.896875, 0.003125, 0.0, 0.7125, 0.0, 0.0625, 0.040625, 0.46875, 0.015625, 0.49375, 0.0, 0.859375, 0.38125, 0.034375, 0.9375, 0.4, 0.003125, 0.059375, 0.75, 0.940625, 0.259375, 0.79375, 0.9875, 1.0, 0.99375, 0.078125, 0.5375, 0.984375, 0.26875]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875, 0.184375, 0.996875, 0.06875, 1.0, 1.0, 1.0, 0.996875, 0.959375, 0.996875, 0.003125, 0.721875, 0.8875, 0.984375, 0.815625, 0.96875, 0.0375, 0.878125, 0.86875, 0.9, 0.896875, 0.965625, 0.39375, 0.884375, 1.0, 0.990625, 1.0, 0.79375, 0.8875, 0.990625, 0.996875, 0.009375, 0.990625, 0.96875, 1.0, 0.978125, 0.4625, 0.86875, 0.0, 1.0, 1.0, 0.296875, 0.4875, 0.515625, 1.0, 0.3125, 0.984375, 1.0, 0.05625, 0.0, 0.8, 0.984375, 0.478125, 0.715625, 1.0, 0.575, 0.98125, 0.003125, 0.940625, 0.434375, 1.0, 0.0, 1.0, 1.0, 0.0375, 0.684375, 0.6125, 0.009375, 0.83125, 0.98125, 0.96875, 0.978125, 1.0, 0.534375, 0.996875, 0.446875, 0.9875, 0.36875, 1.0, 1.0, 1.0, 0.98125, 0.80625, 0.45, 0.096875, 1.0, 0.99375, 0.840625, 1.0, 1.0, 0.0, 0.678125, 0.95, 1.0, 0.978125, 1.0, 0.871875, 1.0, 0.11875, 0.6875, 0.978125, 1.0, 0.325, 0.91875, 1.0, 0.11875, 0.471875, 1.0, 1.0, 0.9875, 0.596875, 0.99375, 0.96875, 0.409375, 1.0, 0.953125, 1.0, 0.94375, 1.0, 0.0, 1.0, 1.0, 0.7375, 0.0, 1.0, 0.93125, 0.95, 0.984375, 1.0, 0.940625, 0.134375, 0.5375, 0.390625, 1.0, 1.0, 0.909375, 1.0, 0.990625, 0.240625, 0.728125, 0.0125, 0.434375, 0.446875, 0.878125, 0.996875, 0.965625, 0.775, 0.93125, 1.0, 0.940625, 0.434375, 0.609375, 0.85625, 0.99375, 0.925, 0.953125, 0.990625, 0.753125, 0.9875, 0.025, 0.88125, 0.94375, 0.834375, 0.99375, 1.0, 0.003125, 0.996875, 0.990625, 0.003125, 0.996875, 0.965625, 1.0, 0.74375, 0.990625, 0.990625, 0.946875, 1.0, 0.975, 0.99375, 0.99375, 0.26875, 0.996875, 0.996875, 0.98125, 0.996875, 0.6375, 1.0, 0.99375, 1.0, 0.05, 0.928125, 1.0, 0.95625, 0.890625, 1.0, 0.984375, 0.940625, 1.0, 1.0, 0.0, 1.0, 0.89375, 0.996875, 1.0, 0.99375, 0.996875, 0.965625, 0.00625, 1.0, 0.0, 1.0, 1.0, 0.228125, 0.990625, 0.971875, 1.0, 0.390625, 0.984375, 1.0, 0.009375, 0.971875, 0.5125, 0.053125, 0.9375, 0.928125, 0.58125, 0.46875, 0.021875, 0.99375, 0.959375, 0.0, 0.99375, 1.0, 1.0, 0.328125, 0.128125, 0.984375, 0.959375, 0.996875, 0.8625, 0.98125, 1.0, 0.003125, 0.93125, 1.0, 0.990625, 1.0, 0.578125, 1.0, 1.0, 0.046875, 1.0, 0.940625, 0.9875, 0.4, 1.0, 1.0, 0.996875, 1.0, 0.153125, 0.965625, 0.978125, 0.6125, 0.99375, 0.965625, 1.0, 1.0, 0.396875, 0.165625, 0.96875, 0.04375, 0.871875, 0.421875, 0.9375, 0.58125, 0.903125, 0.0, 0.971875, 0.921875, 0.31875, 0.996875, 0.940625, 0.540625, 0.628125, 0.9875, 1.0, 0.890625, 1.0, 1.0, 1.0, 1.0, 0.996875, 0.95625, 1.0, 0.996875]\n",
      "i_s=442 in 500;  max_index=738407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.4109 - accuracy: 0.9156 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=443 in 500;  max_index=739707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.6622 - accuracy: 0.0094 - top_k_categorical_accuracy: 0.9625 - val_loss: 2.8592 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=444 in 500;  max_index=741007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.5096 - accuracy: 0.8813 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0836 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=445 in 500;  max_index=742307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.7105 - accuracy: 0.7781 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5914 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=446 in 500;  max_index=743607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.5352 - accuracy: 0.0656 - top_k_categorical_accuracy: 0.5156 - val_loss: 3.8825 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=447 in 500;  max_index=744907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.6288 - accuracy: 0.4250 - top_k_categorical_accuracy: 0.9406 - val_loss: 1.8436 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=448 in 500;  max_index=746207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.3724 - accuracy: 0.0781 - top_k_categorical_accuracy: 0.9187 - val_loss: 2.6528 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=449 in 500;  max_index=747507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 4.9139 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0188 - val_loss: 4.1663 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=450 in 500;  max_index=748807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.6775 - accuracy: 0.8813 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3665 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=451 in 500;  max_index=750107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.2598 - accuracy: 0.9844 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=452 in 500;  max_index=751407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.0951 - accuracy: 0.2812 - top_k_categorical_accuracy: 0.9531 - val_loss: 1.6739 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=453 in 500;  max_index=752707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0416 - accuracy: 0.3594 - top_k_categorical_accuracy: 0.8156 - val_loss: 3.2958 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=454 in 500;  max_index=754007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.2844 - accuracy: 0.9469 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8055 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=455 in 500;  max_index=755307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 6.3438 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 4.3655 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=456 in 500;  max_index=756607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.8666 - accuracy: 0.0063 - top_k_categorical_accuracy: 0.2781 - val_loss: 3.9238 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=457 in 500;  max_index=757907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 3.6913 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.2781 - val_loss: 1.8885 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=458 in 500;  max_index=759207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 3.2061 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.2625 - val_loss: 3.6221 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=459 in 500;  max_index=760507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.1370 - accuracy: 0.3406 - top_k_categorical_accuracy: 0.9219 - val_loss: 3.3082 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=460 in 500;  max_index=761807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.3951 - accuracy: 0.2094 - top_k_categorical_accuracy: 0.6031 - val_loss: 1.3130 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=461 in 500;  max_index=763107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.3286 - accuracy: 0.2719 - top_k_categorical_accuracy: 0.6875 - val_loss: 1.5678 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=462 in 500;  max_index=764407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.8675 - accuracy: 0.2281 - top_k_categorical_accuracy: 0.8969 - val_loss: 2.4422 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=463 in 500;  max_index=765707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.5987 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 3.6448 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=464 in 500;  max_index=767007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 18s 4s/step - loss: 3.8742 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0375 - val_loss: 4.7892 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=465 in 500;  max_index=768307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.5317 - accuracy: 0.2125 - top_k_categorical_accuracy: 0.7812 - val_loss: 2.9048 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=466 in 500;  max_index=769607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.1431 - accuracy: 0.7531 - top_k_categorical_accuracy: 0.9219 - val_loss: 1.2647 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=467 in 500;  max_index=770907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.9375 - accuracy: 0.8938 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2834 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=468 in 500;  max_index=772207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.4335 - accuracy: 0.0969 - top_k_categorical_accuracy: 0.8000 - val_loss: 0.6082 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=469 in 500;  max_index=773507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.1142 - accuracy: 0.2562 - top_k_categorical_accuracy: 0.9219 - val_loss: 3.5974 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=470 in 500;  max_index=774807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.9207 - accuracy: 0.2469 - top_k_categorical_accuracy: 0.9031 - val_loss: 2.5927 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=471 in 500;  max_index=776107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.6528 - accuracy: 0.0375 - top_k_categorical_accuracy: 0.6500 - val_loss: 2.0190 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=472 in 500;  max_index=777407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.9496 - accuracy: 0.4844 - top_k_categorical_accuracy: 0.8188 - val_loss: 4.3338 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=473 in 500;  max_index=778707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.6987 - accuracy: 0.4500 - top_k_categorical_accuracy: 0.8844 - val_loss: 2.0352 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=474 in 500;  max_index=780007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.4468 - accuracy: 0.2250 - top_k_categorical_accuracy: 0.6094 - val_loss: 3.6483 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=475 in 500;  max_index=781307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.6021 - accuracy: 0.4969 - top_k_categorical_accuracy: 0.9094 - val_loss: 1.7274 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=476 in 500;  max_index=782607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.0077 - accuracy: 0.1312 - top_k_categorical_accuracy: 0.9094 - val_loss: 1.8166 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=477 in 500;  max_index=783907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.5602 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.3625 - val_loss: 2.8417 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=478 in 500;  max_index=785207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.4546 - accuracy: 0.5969 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6414 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=479 in 500;  max_index=786507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2350 - accuracy: 0.6156 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6228 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=480 in 500;  max_index=787807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.9202 - accuracy: 0.0156 - top_k_categorical_accuracy: 0.5531 - val_loss: 3.0202 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=481 in 500;  max_index=789107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5862 - accuracy: 0.4156 - top_k_categorical_accuracy: 0.9219 - val_loss: 1.0786 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=482 in 500;  max_index=790407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 16s 3s/step - loss: 0.7921 - accuracy: 0.8156 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0846 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=483 in 500;  max_index=791707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.2189 - accuracy: 0.2344 - top_k_categorical_accuracy: 0.7719 - val_loss: 2.7175 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=484 in 500;  max_index=793007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.9703 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.5500 - val_loss: 3.5111 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=485 in 500;  max_index=794307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 4.2384 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0063 - val_loss: 4.0335 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=486 in 500;  max_index=795607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.4852 - accuracy: 0.5625 - top_k_categorical_accuracy: 0.9375 - val_loss: 2.0993 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=487 in 500;  max_index=796907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.8231 - accuracy: 0.8156 - top_k_categorical_accuracy: 0.9875 - val_loss: 2.2757 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=488 in 500;  max_index=798207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 2.0711 - accuracy: 0.2250 - top_k_categorical_accuracy: 0.8656 - val_loss: 2.2763 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=489 in 500;  max_index=799507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.7884 - accuracy: 0.0000e+00 - top_k_categorical_accuracy: 0.0594 - val_loss: 3.9599 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=490 in 500;  max_index=800807\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.5014 - accuracy: 0.6313 - top_k_categorical_accuracy: 0.8844 - val_loss: 2.1174 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.753125, 0.896875, 0.0, 0.0, 0.0, 0.784375, 0.0625, 0.121875, 0.0, 0.85625, 0.065625, 0.771875, 0.271875, 0.921875, 0.0, 0.0, 0.7125, 0.0, 0.071875, 0.75625, 0.00625, 0.10625, 0.190625, 0.03125, 0.43125, 0.36875, 0.03125, 0.31875, 0.421875, 0.934375, 0.0, 0.0, 0.59375, 0.159375, 0.475, 0.89375, 0.0, 0.678125, 0.0, 0.003125, 0.478125, 0.346875, 0.73125, 0.0, 0.628125, 0.89375, 0.284375, 0.903125, 0.0, 0.146875, 0.35625, 0.89375, 0.025, 0.021875, 0.65, 0.00625, 0.025, 0.0, 0.15625, 0.0, 0.41875, 0.984375, 0.0, 0.384375, 0.55625, 0.0, 0.54375, 0.0, 0.928125, 0.975, 0.059375, 0.21875, 0.15625, 0.978125, 0.703125, 0.43125, 0.240625, 0.465625, 0.0, 0.0, 0.696875, 0.021875, 0.390625, 0.171875, 0.634375, 0.615625, 0.325, 0.359375, 0.8125, 0.353125, 0.796875, 0.103125, 0.678125, 0.0, 0.996875, 0.0, 0.0, 0.634375, 0.9375, 0.5625, 0.175, 0.834375, 0.64375, 0.0, 0.478125, 0.765625, 0.878125, 0.98125, 0.934375, 0.790625, 0.0, 0.28125, 0.85625, 0.565625, 0.871875, 0.009375, 0.578125, 0.2875, 0.0, 0.415625, 0.028125, 0.0, 0.328125, 0.0125, 0.8625, 0.934375, 0.5875, 0.50625, 0.996875, 0.590625, 0.896875, 0.853125, 0.8375, 0.909375, 0.996875, 0.2625, 0.228125, 0.009375, 0.959375, 0.159375, 0.0, 0.99375, 0.0125, 0.071875, 0.615625, 0.715625, 0.559375, 0.665625, 0.0, 0.58125, 0.0, 0.871875, 0.96875, 0.9875, 0.584375, 0.428125, 0.6375, 0.0, 0.05625, 0.525, 0.7875, 0.278125, 0.59375, 0.009375, 0.653125, 0.51875, 0.49375, 0.0, 0.125, 0.05625, 0.496875, 0.403125, 0.703125, 0.65, 0.309375, 0.221875, 0.671875, 0.384375, 0.0, 0.728125, 0.26875, 0.721875, 0.325, 0.0, 0.190625, 0.0, 0.971875, 0.89375, 0.0, 0.140625, 0.015625, 0.93125, 0.0125, 0.878125, 0.975, 0.0, 0.0, 0.484375, 0.9375, 0.025, 0.01875, 0.796875, 0.06875, 0.584375, 0.0, 0.73125, 0.0, 0.58125, 0.0, 0.94375, 0.990625, 0.0, 0.171875, 0.0, 0.0, 0.50625, 0.2875, 0.23125, 0.403125, 0.89375, 0.0, 0.825, 0.0375, 0.371875, 0.0, 0.984375, 0.684375, 0.815625, 0.3875, 0.0125, 0.0, 0.003125, 0.93125, 0.503125, 0.0, 0.840625, 0.4375, 0.0, 0.128125, 0.109375, 0.41875, 0.671875, 0.60625, 0.328125, 0.459375, 0.0, 0.03125, 0.253125, 0.865625, 0.0, 0.45, 0.5125, 0.0, 0.0, 0.93125, 0.996875, 0.478125, 0.0, 0.946875, 0.4375, 0.0, 0.80625, 0.69375, 0.503125, 0.0375, 0.69375, 0.0, 0.846875, 0.44375, 0.021875, 0.0, 0.859375, 0.409375, 0.2375, 0.453125, 0.765625, 0.471875, 0.0, 0.071875, 0.046875, 0.984375, 0.95625, 0.3875, 0.990625, 0.5375, 0.015625, 0.06875, 0.0, 0.0375, 0.028125, 0.446875, 0.728125, 0.590625, 0.28125, 0.55, 0.909375, 0.5375, 0.00625, 0.028125, 0.184375, 0.825, 0.521875, 0.503125, 0.803125, 0.03125, 0.90625, 0.0, 0.228125, 0.41875, 0.040625, 0.5625, 0.821875, 0.0, 0.84375, 0.659375, 0.0, 0.371875, 0.628125, 0.9, 0.09375, 0.6625, 0.703125, 0.240625, 0.60625, 0.490625, 0.6125, 0.728125, 0.0, 0.478125, 0.56875, 0.325, 0.509375, 0.003125, 0.921875, 0.03125, 0.696875, 0.009375, 0.2625, 0.80625, 0.528125, 0.084375, 0.809375, 0.609375, 0.08125, 0.740625, 0.953125, 0.0, 0.99375, 0.346875, 0.625, 0.428125, 0.728125, 0.259375, 0.440625, 0.0, 0.546875, 0.0, 0.88125, 0.9875, 0.0, 0.65, 0.3, 0.671875, 0.003125, 0.23125, 0.559375, 0.0, 0.675, 0.0125, 0.0, 0.496875, 0.40625, 0.009375, 0.071875, 0.0, 0.734375, 0.328125, 0.0, 0.840625, 0.959375, 0.99375, 0.003125, 0.003125, 0.759375, 0.4, 0.928125, 0.21875, 0.215625, 0.703125, 0.0, 0.01875, 0.70625, 0.38125, 0.375, 0.015625, 0.975, 0.7, 0.0, 0.915625, 0.315625, 0.825, 0.0, 0.5875, 0.8375, 0.7625, 0.29375, 0.0, 0.371875, 0.64375, 0.0125, 0.903125, 0.353125, 0.90625, 0.896875, 0.003125, 0.0, 0.7125, 0.0, 0.0625, 0.040625, 0.46875, 0.015625, 0.49375, 0.0, 0.859375, 0.38125, 0.034375, 0.9375, 0.4, 0.003125, 0.059375, 0.75, 0.940625, 0.259375, 0.79375, 0.9875, 1.0, 0.99375, 0.078125, 0.5375, 0.984375, 0.26875, 0.915625, 0.009375, 0.88125, 0.778125, 0.065625, 0.425, 0.078125, 0.0, 0.88125, 0.984375, 0.28125, 0.359375, 0.946875, 0.0, 0.00625, 0.0, 0.003125, 0.340625, 0.209375, 0.271875, 0.228125, 0.0, 0.0, 0.2125, 0.753125, 0.89375, 0.096875, 0.25625, 0.246875, 0.0375, 0.484375, 0.45, 0.225, 0.496875, 0.13125, 0.0, 0.596875, 0.615625, 0.015625, 0.415625, 0.815625, 0.234375, 0.0, 0.0, 0.5625, 0.815625, 0.225, 0.0, 0.63125]\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 1.0, 0.996875, 0.309375, 0.825, 0.3125, 0.996875, 0.990625, 0.915625, 0.0, 0.996875, 0.5375, 0.9875, 0.790625, 1.0, 0.01875, 0.0, 0.953125, 0.003125, 0.96875, 0.984375, 0.265625, 0.765625, 0.51875, 0.396875, 0.865625, 0.9625, 0.440625, 0.56875, 0.984375, 1.0, 0.5375, 0.25625, 0.94375, 0.771875, 0.890625, 1.0, 0.75, 0.928125, 0.0, 0.0125, 0.990625, 0.834375, 0.9875, 0.01875, 1.0, 0.990625, 0.965625, 0.99375, 0.0, 0.953125, 0.9875, 1.0, 0.884375, 0.36875, 0.996875, 0.221875, 0.590625, 0.06875, 0.565625, 0.115625, 0.7125, 1.0, 0.0, 0.79375, 0.996875, 0.0, 0.940625, 0.884375, 1.0, 1.0, 1.0, 0.69375, 0.75625, 1.0, 0.996875, 0.984375, 0.875, 0.8875, 0.328125, 0.021875, 0.978125, 0.946875, 0.753125, 0.709375, 0.88125, 0.95625, 0.828125, 0.95625, 1.0, 0.959375, 0.996875, 0.665625, 0.909375, 0.40625, 1.0, 0.025, 0.35625, 0.978125, 1.0, 0.959375, 0.9, 0.990625, 1.0, 0.365625, 0.90625, 1.0, 0.996875, 1.0, 1.0, 1.0, 0.0, 0.94375, 1.0, 0.9125, 1.0, 0.89375, 0.978125, 0.909375, 0.0, 0.996875, 0.5125, 0.0, 0.88125, 0.775, 0.99375, 0.996875, 0.9625, 0.965625, 1.0, 0.98125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85625, 0.6875, 0.228125, 0.996875, 0.965625, 0.0, 1.0, 0.078125, 0.584375, 0.996875, 1.0, 0.871875, 0.9875, 0.184375, 0.996875, 0.06875, 1.0, 1.0, 1.0, 0.996875, 0.959375, 0.996875, 0.003125, 0.721875, 0.8875, 0.984375, 0.815625, 0.96875, 0.0375, 0.878125, 0.86875, 0.9, 0.896875, 0.965625, 0.39375, 0.884375, 1.0, 0.990625, 1.0, 0.79375, 0.8875, 0.990625, 0.996875, 0.009375, 0.990625, 0.96875, 1.0, 0.978125, 0.4625, 0.86875, 0.0, 1.0, 1.0, 0.296875, 0.4875, 0.515625, 1.0, 0.3125, 0.984375, 1.0, 0.05625, 0.0, 0.8, 0.984375, 0.478125, 0.715625, 1.0, 0.575, 0.98125, 0.003125, 0.940625, 0.434375, 1.0, 0.0, 1.0, 1.0, 0.0375, 0.684375, 0.6125, 0.009375, 0.83125, 0.98125, 0.96875, 0.978125, 1.0, 0.534375, 0.996875, 0.446875, 0.9875, 0.36875, 1.0, 1.0, 1.0, 0.98125, 0.80625, 0.45, 0.096875, 1.0, 0.99375, 0.840625, 1.0, 1.0, 0.0, 0.678125, 0.95, 1.0, 0.978125, 1.0, 0.871875, 1.0, 0.11875, 0.6875, 0.978125, 1.0, 0.325, 0.91875, 1.0, 0.11875, 0.471875, 1.0, 1.0, 0.9875, 0.596875, 0.99375, 0.96875, 0.409375, 1.0, 0.953125, 1.0, 0.94375, 1.0, 0.0, 1.0, 1.0, 0.7375, 0.0, 1.0, 0.93125, 0.95, 0.984375, 1.0, 0.940625, 0.134375, 0.5375, 0.390625, 1.0, 1.0, 0.909375, 1.0, 0.990625, 0.240625, 0.728125, 0.0125, 0.434375, 0.446875, 0.878125, 0.996875, 0.965625, 0.775, 0.93125, 1.0, 0.940625, 0.434375, 0.609375, 0.85625, 0.99375, 0.925, 0.953125, 0.990625, 0.753125, 0.9875, 0.025, 0.88125, 0.94375, 0.834375, 0.99375, 1.0, 0.003125, 0.996875, 0.990625, 0.003125, 0.996875, 0.965625, 1.0, 0.74375, 0.990625, 0.990625, 0.946875, 1.0, 0.975, 0.99375, 0.99375, 0.26875, 0.996875, 0.996875, 0.98125, 0.996875, 0.6375, 1.0, 0.99375, 1.0, 0.05, 0.928125, 1.0, 0.95625, 0.890625, 1.0, 0.984375, 0.940625, 1.0, 1.0, 0.0, 1.0, 0.89375, 0.996875, 1.0, 0.99375, 0.996875, 0.965625, 0.00625, 1.0, 0.0, 1.0, 1.0, 0.228125, 0.990625, 0.971875, 1.0, 0.390625, 0.984375, 1.0, 0.009375, 0.971875, 0.5125, 0.053125, 0.9375, 0.928125, 0.58125, 0.46875, 0.021875, 0.99375, 0.959375, 0.0, 0.99375, 1.0, 1.0, 0.328125, 0.128125, 0.984375, 0.959375, 0.996875, 0.8625, 0.98125, 1.0, 0.003125, 0.93125, 1.0, 0.990625, 1.0, 0.578125, 1.0, 1.0, 0.046875, 1.0, 0.940625, 0.9875, 0.4, 1.0, 1.0, 0.996875, 1.0, 0.153125, 0.965625, 0.978125, 0.6125, 0.99375, 0.965625, 1.0, 1.0, 0.396875, 0.165625, 0.96875, 0.04375, 0.871875, 0.421875, 0.9375, 0.58125, 0.903125, 0.0, 0.971875, 0.921875, 0.31875, 0.996875, 0.940625, 0.540625, 0.628125, 0.9875, 1.0, 0.890625, 1.0, 1.0, 1.0, 1.0, 0.996875, 0.95625, 1.0, 0.996875, 1.0, 0.9625, 1.0, 1.0, 0.515625, 0.940625, 0.91875, 0.01875, 1.0, 1.0, 0.953125, 0.815625, 1.0, 0.0, 0.278125, 0.278125, 0.2625, 0.921875, 0.603125, 0.6875, 0.896875, 0.0, 0.0375, 0.78125, 0.921875, 1.0, 0.8, 0.921875, 0.903125, 0.65, 0.81875, 0.884375, 0.609375, 0.909375, 0.909375, 0.3625, 1.0, 1.0, 0.553125, 0.921875, 1.0, 0.771875, 0.55, 0.00625, 0.9375, 0.9875, 0.865625, 0.059375, 0.884375]\n",
      "i_s=491 in 500;  max_index=802107\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 3.9641 - accuracy: 0.0031 - top_k_categorical_accuracy: 0.0875 - val_loss: 3.2336 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=492 in 500;  max_index=803407\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.8159 - accuracy: 0.8844 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5035 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=493 in 500;  max_index=804707\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.0308 - accuracy: 0.2344 - top_k_categorical_accuracy: 0.8875 - val_loss: 1.9700 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=494 in 500;  max_index=806007\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.2321 - accuracy: 0.6031 - top_k_categorical_accuracy: 0.9937 - val_loss: 1.8017 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=495 in 500;  max_index=807307\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.5093 - accuracy: 0.9781 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0572 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=496 in 500;  max_index=808607\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.9448 - accuracy: 0.1656 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.0674 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=497 in 500;  max_index=809907\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.9245 - accuracy: 0.1562 - top_k_categorical_accuracy: 0.6438 - val_loss: 3.1215 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=498 in 500;  max_index=811207\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.5850 - accuracy: 0.9125 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2399 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=499 in 500;  max_index=812507\n",
      "Epoch 1/1\n",
      "5/5 [==============================] - 15s 3s/step - loss: 0.3993 - accuracy: 0.9625 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6431 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.41156874965969475\n",
      "0.214\n",
      "0.7574562496403232\n"
     ]
    }
   ],
   "source": [
    "print('-----------------Start the loop training!!---------------------')\n",
    "# Scores_all=np.zeros([N_Split,4])\n",
    "# ACC=[0.0,0.0]\n",
    "# val_ACC=[0.0,0.0]\n",
    "# val_TopACC=[0.0,0.0]\n",
    "# for i_s in range(N_Split):\n",
    "#     train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "#     print('i_s='+str(i_s)+ ' in '+ str(N_Split) +';  max_index='+str(N_Train_OverSampler+(i_s+1)*BlockSize+1))\n",
    "#     val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "#     #history = RNNmodel.fit_generator(train_generator,steps_per_epoch=1,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=(N_Val_OverSampler - lookback) // N_BATCH)\n",
    "#     history = RNNmodel.fit_generator(train_generator,steps_per_epoch=17,epochs=1,verbose=2,validation_data=val_generator,validation_steps=1)\n",
    "\n",
    "#     ACC.extend(history.history['accuracy'])\n",
    "#     val_ACC.extend(history.history['val_accuracy'])\n",
    "#     val_TopACC.extend(history.history['top_k_categorical_accuracy'])\n",
    "#     if i_s%100==0:\n",
    "#         print(ACC)\n",
    "#         print(val_ACC)\n",
    "#         print(val_TopACC)\n",
    "# RNNmodel=load_model('jjs_model_0203LSTMV1.h5')\n",
    "ACC=[0.0,0.0]\n",
    "val_ACC=[0.0,0.0]\n",
    "val_TopACC=[0.0,0.0]\n",
    "for i_s in range(N_Split):\n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    print('i_s='+str(i_s)+ ' in '+ str(N_Split) +';  max_index='+str(N_Train_OverSampler+(i_s+1)*BlockSize+1))\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    #history = RNNmodel.fit_generator(train_generator,steps_per_epoch=1,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=(N_Val_OverSampler - lookback) // N_BATCH)\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=5,epochs=1,verbose=1,validation_data=val_generator,validation_steps=1)\n",
    "    ACC.extend(history.history['accuracy'])\n",
    "    val_ACC.extend(history.history['val_accuracy'])\n",
    "    val_TopACC.extend(history.history['top_k_categorical_accuracy'])#\n",
    "    if i_s%49==0:\n",
    "        print(ACC)\n",
    "        print(val_ACC)\n",
    "        print(val_TopACC)\n",
    "RNNmodel.save('jjs_model_0204LSTMV2.h5')        \n",
    "print(val_ACC)\n",
    "NP_ACC=np.array(ACC)\n",
    "print(np.sum(NP_ACC)/500)\n",
    "NP_val_ACC=np.array(val_ACC)\n",
    "print(np.sum(NP_val_ACC)/500)\n",
    "NP_val_ACCTop5=np.array(val_TopACC)\n",
    "print(np.sum(NP_val_ACCTop5)/500)\n",
    "#     loss_i, acc_i, top5acc_i=RNNmodel.evaluate(x=x_val_i, y=y_val_i, batch_size=None, verbose=0, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "# print('i_s='+str(i_s)+' , '+str(np.array([[loss_i, acc_i, top5acc_i]])))\n",
    "#     Scores_all[i_s,:]=np.array([[loss_i, acc_i, top5acc_i]])# np.mean(Scores_all, axis=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R4：把steps_per_epoch搞大，设为70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Start the loop training!!---------------------\n",
      "i_s=0 in 500;  max_index=163807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.1269 - accuracy: 0.9826 - top_k_categorical_accuracy: 0.9998 - val_loss: 2.3472 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.9825893]\n",
      "[0.0, 0.0, 1.0]\n",
      "[0.0, 0.0, 0.9997768]\n",
      "i_s=1 in 500;  max_index=165107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 202s 3s/step - loss: 0.0138 - accuracy: 0.9975 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=2 in 500;  max_index=166407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 215s 3s/step - loss: 0.9448 - accuracy: 0.8565 - top_k_categorical_accuracy: 0.9473 - val_loss: 3.9968 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=3 in 500;  max_index=167707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 235s 3s/step - loss: 0.9615 - accuracy: 0.7960 - top_k_categorical_accuracy: 0.9375 - val_loss: 1.3800 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=4 in 500;  max_index=169007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 209s 3s/step - loss: 0.7446 - accuracy: 0.8779 - top_k_categorical_accuracy: 0.9458 - val_loss: 1.5556 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=5 in 500;  max_index=170307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 193s 3s/step - loss: 0.3866 - accuracy: 0.9239 - top_k_categorical_accuracy: 0.9951 - val_loss: 0.9297 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=6 in 500;  max_index=171607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 199s 3s/step - loss: 0.0596 - accuracy: 0.9859 - top_k_categorical_accuracy: 0.9993 - val_loss: 2.6736 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=7 in 500;  max_index=172907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 201s 3s/step - loss: 0.6105 - accuracy: 0.8710 - top_k_categorical_accuracy: 0.9772 - val_loss: 3.3709 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=8 in 500;  max_index=174207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 210s 3s/step - loss: 1.2643 - accuracy: 0.7632 - top_k_categorical_accuracy: 0.8779 - val_loss: 3.0359 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=9 in 500;  max_index=175507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 217s 3s/step - loss: 0.0814 - accuracy: 0.9795 - top_k_categorical_accuracy: 0.9980 - val_loss: 1.8055 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=10 in 500;  max_index=176807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 206s 3s/step - loss: 0.4159 - accuracy: 0.9027 - top_k_categorical_accuracy: 0.9739 - val_loss: 4.0936 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=11 in 500;  max_index=178107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 206s 3s/step - loss: 0.2225 - accuracy: 0.9529 - top_k_categorical_accuracy: 0.9868 - val_loss: 3.4130 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=12 in 500;  max_index=179407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 208s 3s/step - loss: 0.5624 - accuracy: 0.8933 - top_k_categorical_accuracy: 0.9656 - val_loss: 2.2809 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=13 in 500;  max_index=180707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 207s 3s/step - loss: 0.0281 - accuracy: 0.9915 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0409 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=14 in 500;  max_index=182007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 1.1098 - accuracy: 0.7511 - top_k_categorical_accuracy: 0.8987 - val_loss: 1.9625 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=15 in 500;  max_index=183307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 1.3912 - accuracy: 0.7254 - top_k_categorical_accuracy: 0.8647 - val_loss: 2.4268 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=16 in 500;  max_index=184607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.4732 - accuracy: 0.9009 - top_k_categorical_accuracy: 0.9569 - val_loss: 1.7353 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=17 in 500;  max_index=185907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 1.1841 - accuracy: 0.7518 - top_k_categorical_accuracy: 0.8475 - val_loss: 3.6283 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=18 in 500;  max_index=187207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.3781 - accuracy: 0.8996 - top_k_categorical_accuracy: 0.9904 - val_loss: 3.0530 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=19 in 500;  max_index=188507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.2613 - accuracy: 0.9498 - top_k_categorical_accuracy: 0.9830 - val_loss: 2.8777 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=20 in 500;  max_index=189807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 233s 3s/step - loss: 1.0447 - accuracy: 0.7705 - top_k_categorical_accuracy: 0.8815 - val_loss: 2.2048 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=21 in 500;  max_index=191107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 223s 3s/step - loss: 0.0074 - accuracy: 0.9987 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6433 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=22 in 500;  max_index=192407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 220s 3s/step - loss: 0.9068 - accuracy: 0.8170 - top_k_categorical_accuracy: 0.9502 - val_loss: 2.1180 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=23 in 500;  max_index=193707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 210s 3s/step - loss: 0.4996 - accuracy: 0.8987 - top_k_categorical_accuracy: 0.9618 - val_loss: 4.0690 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=24 in 500;  max_index=195007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 195s 3s/step - loss: 0.4784 - accuracy: 0.9098 - top_k_categorical_accuracy: 0.9766 - val_loss: 2.1369 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=25 in 500;  max_index=196307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.5060 - accuracy: 0.9103 - top_k_categorical_accuracy: 0.9641 - val_loss: 2.1015 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=26 in 500;  max_index=197607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 236s 3s/step - loss: 0.5808 - accuracy: 0.8621 - top_k_categorical_accuracy: 0.9507 - val_loss: 2.5335 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=27 in 500;  max_index=198907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.8510 - accuracy: 0.8225 - top_k_categorical_accuracy: 0.9161 - val_loss: 4.0352 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=28 in 500;  max_index=200207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 221s 3s/step - loss: 0.3306 - accuracy: 0.9118 - top_k_categorical_accuracy: 0.9978 - val_loss: 3.0883 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=29 in 500;  max_index=201507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 217s 3s/step - loss: 0.4128 - accuracy: 0.9217 - top_k_categorical_accuracy: 0.9900 - val_loss: 0.7104 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=30 in 500;  max_index=202807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 216s 3s/step - loss: 0.5255 - accuracy: 0.9000 - top_k_categorical_accuracy: 0.9489 - val_loss: 2.0751 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=31 in 500;  max_index=204107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 196s 3s/step - loss: 0.7579 - accuracy: 0.8384 - top_k_categorical_accuracy: 0.9165 - val_loss: 2.8725 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=32 in 500;  max_index=205407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.1681 - accuracy: 0.9594 - top_k_categorical_accuracy: 0.9942 - val_loss: 2.3909 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=33 in 500;  max_index=206707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 200s 3s/step - loss: 0.3747 - accuracy: 0.9208 - top_k_categorical_accuracy: 0.9746 - val_loss: 4.3805 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=34 in 500;  max_index=208007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 199s 3s/step - loss: 0.2003 - accuracy: 0.9585 - top_k_categorical_accuracy: 0.9913 - val_loss: 1.0381 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=35 in 500;  max_index=209307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 220s 3s/step - loss: 0.0224 - accuracy: 0.9949 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=36 in 500;  max_index=210607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 228s 3s/step - loss: 0.7783 - accuracy: 0.8473 - top_k_categorical_accuracy: 0.9507 - val_loss: 2.6369 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=37 in 500;  max_index=211907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.4089 - accuracy: 0.9134 - top_k_categorical_accuracy: 0.9748 - val_loss: 3.0543 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=38 in 500;  max_index=213207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 225s 3s/step - loss: 1.3183 - accuracy: 0.7188 - top_k_categorical_accuracy: 0.8672 - val_loss: 4.9230 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=39 in 500;  max_index=214507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 231s 3s/step - loss: 0.5720 - accuracy: 0.8953 - top_k_categorical_accuracy: 0.9549 - val_loss: 5.0558 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=40 in 500;  max_index=215807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 239s 3s/step - loss: 0.2892 - accuracy: 0.9281 - top_k_categorical_accuracy: 0.9804 - val_loss: 1.1932 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=41 in 500;  max_index=217107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 225s 3s/step - loss: 0.2933 - accuracy: 0.9364 - top_k_categorical_accuracy: 0.9759 - val_loss: 1.3457 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=42 in 500;  max_index=218407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 227s 3s/step - loss: 0.1842 - accuracy: 0.9498 - top_k_categorical_accuracy: 0.9984 - val_loss: 3.1653 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=43 in 500;  max_index=219707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 259s 4s/step - loss: 1.4345 - accuracy: 0.7527 - top_k_categorical_accuracy: 0.8612 - val_loss: 3.6702 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=44 in 500;  max_index=221007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 229s 3s/step - loss: 0.0735 - accuracy: 0.9783 - top_k_categorical_accuracy: 0.9991 - val_loss: 0.5549 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=45 in 500;  max_index=222307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.0075 - accuracy: 0.9975 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2873 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=46 in 500;  max_index=223607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.4769 - accuracy: 0.9228 - top_k_categorical_accuracy: 0.9958 - val_loss: 0.3323 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=47 in 500;  max_index=224907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.0983 - accuracy: 0.9783 - top_k_categorical_accuracy: 0.9996 - val_loss: 2.2499 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=48 in 500;  max_index=226207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.9468 - accuracy: 0.8442 - top_k_categorical_accuracy: 0.9585 - val_loss: 5.6021 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=49 in 500;  max_index=227507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.6526 - accuracy: 0.8618 - top_k_categorical_accuracy: 0.9710 - val_loss: 2.3935 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=50 in 500;  max_index=228807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.5123 - accuracy: 0.8904 - top_k_categorical_accuracy: 0.9752 - val_loss: 3.3682 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=51 in 500;  max_index=230107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 0.2668 - accuracy: 0.9368 - top_k_categorical_accuracy: 0.9982 - val_loss: 1.2380 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=52 in 500;  max_index=231407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.2118 - accuracy: 0.9522 - top_k_categorical_accuracy: 0.9996 - val_loss: 2.2092 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=53 in 500;  max_index=232707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 241s 3s/step - loss: 0.6497 - accuracy: 0.8725 - top_k_categorical_accuracy: 0.9763 - val_loss: 2.6250 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=54 in 500;  max_index=234007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.1982 - accuracy: 0.9560 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.4994 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=55 in 500;  max_index=235307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 217s 3s/step - loss: 1.0250 - accuracy: 0.8194 - top_k_categorical_accuracy: 0.8980 - val_loss: 2.5824 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=56 in 500;  max_index=236607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.4437 - accuracy: 0.8879 - top_k_categorical_accuracy: 0.9877 - val_loss: 2.7168 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=57 in 500;  max_index=237907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 1.3070 - accuracy: 0.7297 - top_k_categorical_accuracy: 0.8864 - val_loss: 4.3221 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=58 in 500;  max_index=239207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 260s 4s/step - loss: 0.4902 - accuracy: 0.9089 - top_k_categorical_accuracy: 0.9554 - val_loss: 0.3456 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=59 in 500;  max_index=240507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.9370 - accuracy: 0.8020 - top_k_categorical_accuracy: 0.9154 - val_loss: 5.2238 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=60 in 500;  max_index=241807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.4877 - accuracy: 0.8908 - top_k_categorical_accuracy: 0.9607 - val_loss: 1.9083 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=61 in 500;  max_index=243107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 235s 3s/step - loss: 0.2254 - accuracy: 0.9480 - top_k_categorical_accuracy: 0.9855 - val_loss: 0.3103 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=62 in 500;  max_index=244407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 235s 3s/step - loss: 1.5095 - accuracy: 0.7221 - top_k_categorical_accuracy: 0.8804 - val_loss: 3.8223 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=63 in 500;  max_index=245707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 239s 3s/step - loss: 0.6683 - accuracy: 0.8585 - top_k_categorical_accuracy: 0.9304 - val_loss: 3.0632 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=64 in 500;  max_index=247007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 262s 4s/step - loss: 0.4024 - accuracy: 0.9172 - top_k_categorical_accuracy: 0.9600 - val_loss: 2.1940 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=65 in 500;  max_index=248307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 262s 4s/step - loss: 0.9584 - accuracy: 0.7989 - top_k_categorical_accuracy: 0.9283 - val_loss: 3.4020 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=66 in 500;  max_index=249607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 0.1840 - accuracy: 0.9580 - top_k_categorical_accuracy: 0.9886 - val_loss: 2.8571 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=67 in 500;  max_index=250907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.7240 - accuracy: 0.8388 - top_k_categorical_accuracy: 0.9676 - val_loss: 2.7376 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=68 in 500;  max_index=252207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 0.1751 - accuracy: 0.9609 - top_k_categorical_accuracy: 0.9982 - val_loss: 0.2141 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=69 in 500;  max_index=253507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.0020 - accuracy: 0.9991 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=70 in 500;  max_index=254807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 236s 3s/step - loss: 0.5404 - accuracy: 0.9013 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.8513 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=71 in 500;  max_index=256107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 278s 4s/step - loss: 0.4154 - accuracy: 0.9172 - top_k_categorical_accuracy: 0.9786 - val_loss: 2.7178 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=72 in 500;  max_index=257407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.4277 - accuracy: 0.9080 - top_k_categorical_accuracy: 0.9714 - val_loss: 4.1942 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=73 in 500;  max_index=258707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 0.1801 - accuracy: 0.9498 - top_k_categorical_accuracy: 0.9913 - val_loss: 0.2791 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=74 in 500;  max_index=260007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.1170 - accuracy: 0.9676 - top_k_categorical_accuracy: 0.9998 - val_loss: 3.4799 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=75 in 500;  max_index=261307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.4955 - accuracy: 0.8998 - top_k_categorical_accuracy: 0.9904 - val_loss: 1.7367 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=76 in 500;  max_index=262607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 0.1153 - accuracy: 0.9730 - top_k_categorical_accuracy: 0.9987 - val_loss: 2.8889 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=77 in 500;  max_index=263907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 235s 3s/step - loss: 6.6512e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0632 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=78 in 500;  max_index=265207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 220s 3s/step - loss: 1.3026 - accuracy: 0.7368 - top_k_categorical_accuracy: 0.8690 - val_loss: 3.5932 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=79 in 500;  max_index=266507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.3219 - accuracy: 0.9194 - top_k_categorical_accuracy: 0.9734 - val_loss: 3.2908 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=80 in 500;  max_index=267807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 229s 3s/step - loss: 0.2609 - accuracy: 0.9337 - top_k_categorical_accuracy: 0.9922 - val_loss: 4.2661 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=81 in 500;  max_index=269107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 265s 4s/step - loss: 0.4573 - accuracy: 0.9042 - top_k_categorical_accuracy: 0.9752 - val_loss: 3.7420 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=82 in 500;  max_index=270407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.4100 - accuracy: 0.9254 - top_k_categorical_accuracy: 0.9725 - val_loss: 3.4611 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=83 in 500;  max_index=271707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.5570 - accuracy: 0.8929 - top_k_categorical_accuracy: 0.9435 - val_loss: 0.6947 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=84 in 500;  max_index=273007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 225s 3s/step - loss: 0.4605 - accuracy: 0.9223 - top_k_categorical_accuracy: 0.9578 - val_loss: 2.7735 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=85 in 500;  max_index=274307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 209s 3s/step - loss: 0.3448 - accuracy: 0.9272 - top_k_categorical_accuracy: 0.9812 - val_loss: 1.9266 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=86 in 500;  max_index=275607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 208s 3s/step - loss: 0.3074 - accuracy: 0.9321 - top_k_categorical_accuracy: 0.9766 - val_loss: 2.6822 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=87 in 500;  max_index=276907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 205s 3s/step - loss: 0.2247 - accuracy: 0.9500 - top_k_categorical_accuracy: 0.9844 - val_loss: 3.0413 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=88 in 500;  max_index=278207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.0531 - accuracy: 0.9871 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=89 in 500;  max_index=279507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 262s 4s/step - loss: 0.4040 - accuracy: 0.9156 - top_k_categorical_accuracy: 0.9842 - val_loss: 1.9685 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=90 in 500;  max_index=280807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 265s 4s/step - loss: 0.0131 - accuracy: 0.9962 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.3176 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=91 in 500;  max_index=282107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.4707 - accuracy: 0.9170 - top_k_categorical_accuracy: 0.9759 - val_loss: 2.5940 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=92 in 500;  max_index=283407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 234s 3s/step - loss: 0.4759 - accuracy: 0.8973 - top_k_categorical_accuracy: 0.9772 - val_loss: 0.9587 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=93 in 500;  max_index=284707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 234s 3s/step - loss: 0.2831 - accuracy: 0.9371 - top_k_categorical_accuracy: 0.9692 - val_loss: 1.1980 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=94 in 500;  max_index=286007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 232s 3s/step - loss: 0.1843 - accuracy: 0.9607 - top_k_categorical_accuracy: 0.9958 - val_loss: 0.2979 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=95 in 500;  max_index=287307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 1.3152 - accuracy: 0.7788 - top_k_categorical_accuracy: 0.8627 - val_loss: 3.7851 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=96 in 500;  max_index=288607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.6047 - accuracy: 0.8632 - top_k_categorical_accuracy: 0.9424 - val_loss: 2.3260 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=97 in 500;  max_index=289907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 251s 4s/step - loss: 0.1554 - accuracy: 0.9634 - top_k_categorical_accuracy: 0.9964 - val_loss: 0.4576 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=98 in 500;  max_index=291207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 228s 3s/step - loss: 0.0926 - accuracy: 0.9739 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7648 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=99 in 500;  max_index=292507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 0.0706 - accuracy: 0.9808 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7414 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=100 in 500;  max_index=293807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.6552 - accuracy: 0.8902 - top_k_categorical_accuracy: 0.9933 - val_loss: 1.5526 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.9825893, 0.99754465, 0.8564732, 0.7959821, 0.8779018, 0.9238839, 0.9859375, 0.87098217, 0.76316965, 0.9794643, 0.90267855, 0.9529018, 0.8933036, 0.99151784, 0.7511161, 0.7254464, 0.90089285, 0.7517857, 0.8995536, 0.94977677, 0.7705357, 0.99866074, 0.81696427, 0.8986607, 0.90982145, 0.91026783, 0.8620536, 0.82254463, 0.91183037, 0.9216518, 0.9, 0.83839285, 0.959375, 0.9207589, 0.95848215, 0.9948661, 0.84732145, 0.91339284, 0.71875, 0.8953125, 0.928125, 0.9363839, 0.94977677, 0.7526786, 0.9783482, 0.99754465, 0.9227679, 0.9783482, 0.84419644, 0.86183035, 0.8904018, 0.93683034, 0.9522321, 0.87254465, 0.9560268, 0.8194196, 0.8879464, 0.7296875, 0.9089286, 0.8020089, 0.8908482, 0.9479911, 0.72209823, 0.8584821, 0.9171875, 0.7988839, 0.9580357, 0.8388393, 0.9609375, 0.9991071, 0.9013393, 0.9171875, 0.9080357, 0.94977677, 0.9676339, 0.89977676, 0.97299105, 1.0, 0.73683035, 0.91941965, 0.93370533, 0.9042411, 0.92544645, 0.89285713, 0.92232144, 0.92723215, 0.93214285, 0.95, 0.9870536, 0.915625, 0.99620533, 0.9169643, 0.8973214, 0.93705356, 0.9607143, 0.77879465, 0.86316967, 0.96339285, 0.9738839, 0.98080355, 0.89017856]\n",
      "[0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.9997768, 1.0, 0.9473214, 0.9375, 0.94575894, 0.9950893, 0.99933034, 0.97723216, 0.8779018, 0.9979911, 0.9738839, 0.98683035, 0.965625, 1.0, 0.8986607, 0.86473215, 0.95691967, 0.84754467, 0.9904018, 0.98303574, 0.88147324, 1.0, 0.9502232, 0.9618304, 0.9765625, 0.9640625, 0.95066965, 0.9160714, 0.99776787, 0.98995537, 0.94888395, 0.91651785, 0.9941964, 0.9745536, 0.9912946, 1.0, 0.95066965, 0.9747768, 0.8671875, 0.9549107, 0.98035717, 0.97589284, 0.9984375, 0.8611607, 0.9991071, 1.0, 0.99575895, 0.99955356, 0.95848215, 0.97098213, 0.97522324, 0.9982143, 0.99955356, 0.9763393, 0.99754465, 0.89799106, 0.98772323, 0.88638395, 0.95535713, 0.91540176, 0.9607143, 0.9854911, 0.88035715, 0.93035716, 0.9600446, 0.92834824, 0.98861605, 0.9676339, 0.9982143, 1.0, 0.99955356, 0.9785714, 0.9714286, 0.9912946, 0.9997768, 0.9904018, 0.99866074, 1.0, 0.8689732, 0.9734375, 0.9921875, 0.97522324, 0.97254467, 0.9435268, 0.9578125, 0.98125, 0.9765625, 0.984375, 1.0, 0.9841518, 1.0, 0.97589284, 0.97723216, 0.96919644, 0.99575895, 0.86272323, 0.9424107, 0.99642855, 1.0, 1.0, 0.9933036]\n",
      "i_s=101 in 500;  max_index=295107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 235s 3s/step - loss: 0.1699 - accuracy: 0.9623 - top_k_categorical_accuracy: 0.9980 - val_loss: 0.0708 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=102 in 500;  max_index=296407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.2097 - accuracy: 0.9661 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3497 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=103 in 500;  max_index=297707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.6393 - accuracy: 0.8866 - top_k_categorical_accuracy: 0.9790 - val_loss: 4.1913 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=104 in 500;  max_index=299007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.3386 - accuracy: 0.9283 - top_k_categorical_accuracy: 0.9879 - val_loss: 1.4762 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=105 in 500;  max_index=300307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 265s 4s/step - loss: 0.2509 - accuracy: 0.9542 - top_k_categorical_accuracy: 0.9940 - val_loss: 2.4532 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=106 in 500;  max_index=301607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 0.1017 - accuracy: 0.9748 - top_k_categorical_accuracy: 0.9987 - val_loss: 2.6969 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=107 in 500;  max_index=302907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 0.0085 - accuracy: 0.9978 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4534 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=108 in 500;  max_index=304207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.0188 - accuracy: 0.9926 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=109 in 500;  max_index=305507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 0.3665 - accuracy: 0.9221 - top_k_categorical_accuracy: 0.9962 - val_loss: 1.3018 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=110 in 500;  max_index=306807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 1.4652 - accuracy: 0.7781 - top_k_categorical_accuracy: 0.8654 - val_loss: 6.8142 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=111 in 500;  max_index=308107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.5189 - accuracy: 0.8971 - top_k_categorical_accuracy: 0.9489 - val_loss: 4.1706 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=112 in 500;  max_index=309407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.3405 - accuracy: 0.9248 - top_k_categorical_accuracy: 0.9792 - val_loss: 0.2546 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=113 in 500;  max_index=310707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 220s 3s/step - loss: 0.1284 - accuracy: 0.9643 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.0656 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=114 in 500;  max_index=312007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 216s 3s/step - loss: 0.0114 - accuracy: 0.9967 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6866 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=115 in 500;  max_index=313307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 216s 3s/step - loss: 0.9676 - accuracy: 0.8281 - top_k_categorical_accuracy: 0.9232 - val_loss: 5.9268 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=116 in 500;  max_index=314607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 216s 3s/step - loss: 0.2587 - accuracy: 0.9404 - top_k_categorical_accuracy: 0.9902 - val_loss: 2.6676 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=117 in 500;  max_index=315907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 211s 3s/step - loss: 0.1499 - accuracy: 0.9632 - top_k_categorical_accuracy: 0.9973 - val_loss: 1.0692 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=118 in 500;  max_index=317207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 229s 3s/step - loss: 1.0994 - accuracy: 0.8297 - top_k_categorical_accuracy: 0.9176 - val_loss: 5.3571 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=119 in 500;  max_index=318507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 208s 3s/step - loss: 0.3165 - accuracy: 0.9346 - top_k_categorical_accuracy: 0.9806 - val_loss: 3.1866 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=120 in 500;  max_index=319807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 251s 4s/step - loss: 0.5214 - accuracy: 0.8830 - top_k_categorical_accuracy: 0.9705 - val_loss: 5.4799 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=121 in 500;  max_index=321107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 241s 3s/step - loss: 0.1623 - accuracy: 0.9571 - top_k_categorical_accuracy: 0.9980 - val_loss: 4.3574 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=122 in 500;  max_index=322407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.6289 - accuracy: 0.8710 - top_k_categorical_accuracy: 0.9643 - val_loss: 0.9936 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=123 in 500;  max_index=323707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.6051 - accuracy: 0.8676 - top_k_categorical_accuracy: 0.9717 - val_loss: 1.4880 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=124 in 500;  max_index=325007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 271s 4s/step - loss: 0.2571 - accuracy: 0.9518 - top_k_categorical_accuracy: 0.9777 - val_loss: 2.3752 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=125 in 500;  max_index=326307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 270s 4s/step - loss: 0.0051 - accuracy: 0.9989 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4152 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=126 in 500;  max_index=327607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 283s 4s/step - loss: 0.1306 - accuracy: 0.9685 - top_k_categorical_accuracy: 0.9982 - val_loss: 0.8674 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=127 in 500;  max_index=328907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.2477 - accuracy: 0.9382 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.2069 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=128 in 500;  max_index=330207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.0146 - accuracy: 0.9949 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7751 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=129 in 500;  max_index=331507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.0290 - accuracy: 0.9902 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7462 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=130 in 500;  max_index=332807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 4.4229e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=131 in 500;  max_index=334107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 238s 3s/step - loss: 0.2717 - accuracy: 0.9511 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=132 in 500;  max_index=335407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 8.3712e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=133 in 500;  max_index=336707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 0.0281 - accuracy: 0.9920 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=134 in 500;  max_index=338007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.1235 - accuracy: 0.9754 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.0168 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=135 in 500;  max_index=339307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.6687 - accuracy: 0.8819 - top_k_categorical_accuracy: 0.9913 - val_loss: 6.4028 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=136 in 500;  max_index=340607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 282s 4s/step - loss: 0.4510 - accuracy: 0.9181 - top_k_categorical_accuracy: 0.9906 - val_loss: 1.4336 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=137 in 500;  max_index=341907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 0.7637 - accuracy: 0.8377 - top_k_categorical_accuracy: 0.9449 - val_loss: 7.0701 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=138 in 500;  max_index=343207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.0387 - accuracy: 0.9893 - top_k_categorical_accuracy: 0.9998 - val_loss: 4.3222 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=139 in 500;  max_index=344507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.3840 - accuracy: 0.9373 - top_k_categorical_accuracy: 0.9877 - val_loss: 0.8817 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=140 in 500;  max_index=345807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 1.6779 - accuracy: 0.7065 - top_k_categorical_accuracy: 0.8667 - val_loss: 4.7464 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=141 in 500;  max_index=347107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.0224 - accuracy: 0.9931 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4497 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=142 in 500;  max_index=348407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.6789 - accuracy: 0.9051 - top_k_categorical_accuracy: 0.9719 - val_loss: 5.4324 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=143 in 500;  max_index=349707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.8823 - accuracy: 0.8748 - top_k_categorical_accuracy: 0.9371 - val_loss: 3.9475 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=144 in 500;  max_index=351007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.1429 - accuracy: 0.9661 - top_k_categorical_accuracy: 0.9951 - val_loss: 0.2315 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=145 in 500;  max_index=352307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 0.2820 - accuracy: 0.9489 - top_k_categorical_accuracy: 0.9978 - val_loss: 1.6815 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=146 in 500;  max_index=353607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.6128 - accuracy: 0.8781 - top_k_categorical_accuracy: 0.9455 - val_loss: 3.4721 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=147 in 500;  max_index=354907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.1576 - accuracy: 0.9629 - top_k_categorical_accuracy: 0.9900 - val_loss: 0.3951 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=148 in 500;  max_index=356207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.8887 - accuracy: 0.8125 - top_k_categorical_accuracy: 0.9152 - val_loss: 5.1499 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=149 in 500;  max_index=357507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.1361 - accuracy: 0.9618 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.1737 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=150 in 500;  max_index=358807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 213s 3s/step - loss: 0.4634 - accuracy: 0.8967 - top_k_categorical_accuracy: 0.9607 - val_loss: 7.1099 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=151 in 500;  max_index=360107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 0.1064 - accuracy: 0.9781 - top_k_categorical_accuracy: 0.9964 - val_loss: 4.5230 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=152 in 500;  max_index=361407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.0073 - accuracy: 0.9978 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.3895 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=153 in 500;  max_index=362707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.0012 - accuracy: 0.9993 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=154 in 500;  max_index=364007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.6531 - accuracy: 0.8779 - top_k_categorical_accuracy: 0.9522 - val_loss: 1.8836 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=155 in 500;  max_index=365307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.4935 - accuracy: 0.9029 - top_k_categorical_accuracy: 0.9790 - val_loss: 1.5551 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=156 in 500;  max_index=366607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 241s 3s/step - loss: 0.1478 - accuracy: 0.9632 - top_k_categorical_accuracy: 0.9998 - val_loss: 3.8012 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=157 in 500;  max_index=367907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 277s 4s/step - loss: 1.4265 - accuracy: 0.7460 - top_k_categorical_accuracy: 0.8904 - val_loss: 4.7756 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=158 in 500;  max_index=369207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 233s 3s/step - loss: 0.3976 - accuracy: 0.8984 - top_k_categorical_accuracy: 0.9833 - val_loss: 6.4310 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=159 in 500;  max_index=370507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 238s 3s/step - loss: 0.3886 - accuracy: 0.9268 - top_k_categorical_accuracy: 0.9694 - val_loss: 2.6517 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=160 in 500;  max_index=371807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 0.3770 - accuracy: 0.9297 - top_k_categorical_accuracy: 0.9812 - val_loss: 4.2090 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=161 in 500;  max_index=373107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 271s 4s/step - loss: 0.6227 - accuracy: 0.8848 - top_k_categorical_accuracy: 0.9458 - val_loss: 3.8157 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=162 in 500;  max_index=374407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.3504 - accuracy: 0.9315 - top_k_categorical_accuracy: 0.9797 - val_loss: 0.7571 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=163 in 500;  max_index=375707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 262s 4s/step - loss: 1.3818 - accuracy: 0.8098 - top_k_categorical_accuracy: 0.8944 - val_loss: 4.4955 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=164 in 500;  max_index=377007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 3s/step - loss: 0.5157 - accuracy: 0.8960 - top_k_categorical_accuracy: 0.9558 - val_loss: 2.6858 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=165 in 500;  max_index=378307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.0305 - accuracy: 0.9937 - top_k_categorical_accuracy: 0.9980 - val_loss: 3.6570 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=166 in 500;  max_index=379607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.5924 - accuracy: 0.9062 - top_k_categorical_accuracy: 0.9984 - val_loss: 1.9558 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=167 in 500;  max_index=380907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.4766 - accuracy: 0.9196 - top_k_categorical_accuracy: 0.9621 - val_loss: 0.4973 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=168 in 500;  max_index=382207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 0.0020 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7888 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=169 in 500;  max_index=383507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.4394 - accuracy: 0.9145 - top_k_categorical_accuracy: 0.9750 - val_loss: 2.5684 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=170 in 500;  max_index=384807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.6533 - accuracy: 0.8768 - top_k_categorical_accuracy: 0.9509 - val_loss: 3.6532 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=171 in 500;  max_index=386107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 235s 3s/step - loss: 0.1043 - accuracy: 0.9741 - top_k_categorical_accuracy: 0.9989 - val_loss: 1.1516 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=172 in 500;  max_index=387407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.2217 - accuracy: 0.9598 - top_k_categorical_accuracy: 0.9964 - val_loss: 1.6139 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=173 in 500;  max_index=388707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.1268 - accuracy: 0.9683 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8947 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=174 in 500;  max_index=390007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.1293 - accuracy: 0.9730 - top_k_categorical_accuracy: 0.9993 - val_loss: 2.7050 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=175 in 500;  max_index=391307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.8936 - accuracy: 0.8375 - top_k_categorical_accuracy: 0.9732 - val_loss: 6.4188 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=176 in 500;  max_index=392607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 268s 4s/step - loss: 0.1306 - accuracy: 0.9676 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.7516 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=177 in 500;  max_index=393907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 268s 4s/step - loss: 0.3927 - accuracy: 0.9279 - top_k_categorical_accuracy: 0.9971 - val_loss: 1.1446 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=178 in 500;  max_index=395207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.9896 - accuracy: 0.7993 - top_k_categorical_accuracy: 0.9199 - val_loss: 4.1287 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=179 in 500;  max_index=396507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.1343 - accuracy: 0.9654 - top_k_categorical_accuracy: 0.9944 - val_loss: 0.6483 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=180 in 500;  max_index=397807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.5152 - accuracy: 0.8946 - top_k_categorical_accuracy: 0.9563 - val_loss: 2.9112 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=181 in 500;  max_index=399107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 259s 4s/step - loss: 0.2813 - accuracy: 0.9384 - top_k_categorical_accuracy: 0.9853 - val_loss: 3.0303 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=182 in 500;  max_index=400407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.4323 - accuracy: 0.9042 - top_k_categorical_accuracy: 0.9859 - val_loss: 1.8646 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=183 in 500;  max_index=401707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 1.1996 - accuracy: 0.7513 - top_k_categorical_accuracy: 0.8777 - val_loss: 3.4121 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=184 in 500;  max_index=403007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.1918 - accuracy: 0.9484 - top_k_categorical_accuracy: 0.9953 - val_loss: 4.7236 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=185 in 500;  max_index=404307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.8883 - accuracy: 0.8237 - top_k_categorical_accuracy: 0.9344 - val_loss: 3.1059 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=186 in 500;  max_index=405607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 251s 4s/step - loss: 0.2483 - accuracy: 0.9491 - top_k_categorical_accuracy: 0.9846 - val_loss: 0.7201 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=187 in 500;  max_index=406907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.0087 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6368 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=188 in 500;  max_index=408207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.3355 - accuracy: 0.9346 - top_k_categorical_accuracy: 0.9929 - val_loss: 2.3092 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=189 in 500;  max_index=409507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 271s 4s/step - loss: 0.6190 - accuracy: 0.8996 - top_k_categorical_accuracy: 0.9569 - val_loss: 4.4570 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=190 in 500;  max_index=410807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.9076 - accuracy: 0.8132 - top_k_categorical_accuracy: 0.9301 - val_loss: 1.7843 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=191 in 500;  max_index=412107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 259s 4s/step - loss: 0.0956 - accuracy: 0.9737 - top_k_categorical_accuracy: 0.9973 - val_loss: 1.2283 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=192 in 500;  max_index=413407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.3454 - accuracy: 0.9161 - top_k_categorical_accuracy: 0.9801 - val_loss: 3.0752 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=193 in 500;  max_index=414707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.2800 - accuracy: 0.9246 - top_k_categorical_accuracy: 0.9911 - val_loss: 0.7050 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=194 in 500;  max_index=416007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.0501 - accuracy: 0.9835 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.8860 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=195 in 500;  max_index=417307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 260s 4s/step - loss: 1.5963 - accuracy: 0.6900 - top_k_categorical_accuracy: 0.8458 - val_loss: 4.4488 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=196 in 500;  max_index=418607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.9170 - accuracy: 0.8167 - top_k_categorical_accuracy: 0.9179 - val_loss: 9.2201 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=197 in 500;  max_index=419907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.8488 - accuracy: 0.8413 - top_k_categorical_accuracy: 0.9179 - val_loss: 6.0304 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=198 in 500;  max_index=421207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 0.1680 - accuracy: 0.9558 - top_k_categorical_accuracy: 0.9993 - val_loss: 3.3389 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=199 in 500;  max_index=422507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.3719 - accuracy: 0.9241 - top_k_categorical_accuracy: 0.9982 - val_loss: 2.8811 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=200 in 500;  max_index=423807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.3767 - accuracy: 0.9275 - top_k_categorical_accuracy: 0.9759 - val_loss: 1.8701 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.9825893, 0.99754465, 0.8564732, 0.7959821, 0.8779018, 0.9238839, 0.9859375, 0.87098217, 0.76316965, 0.9794643, 0.90267855, 0.9529018, 0.8933036, 0.99151784, 0.7511161, 0.7254464, 0.90089285, 0.7517857, 0.8995536, 0.94977677, 0.7705357, 0.99866074, 0.81696427, 0.8986607, 0.90982145, 0.91026783, 0.8620536, 0.82254463, 0.91183037, 0.9216518, 0.9, 0.83839285, 0.959375, 0.9207589, 0.95848215, 0.9948661, 0.84732145, 0.91339284, 0.71875, 0.8953125, 0.928125, 0.9363839, 0.94977677, 0.7526786, 0.9783482, 0.99754465, 0.9227679, 0.9783482, 0.84419644, 0.86183035, 0.8904018, 0.93683034, 0.9522321, 0.87254465, 0.9560268, 0.8194196, 0.8879464, 0.7296875, 0.9089286, 0.8020089, 0.8908482, 0.9479911, 0.72209823, 0.8584821, 0.9171875, 0.7988839, 0.9580357, 0.8388393, 0.9609375, 0.9991071, 0.9013393, 0.9171875, 0.9080357, 0.94977677, 0.9676339, 0.89977676, 0.97299105, 1.0, 0.73683035, 0.91941965, 0.93370533, 0.9042411, 0.92544645, 0.89285713, 0.92232144, 0.92723215, 0.93214285, 0.95, 0.9870536, 0.915625, 0.99620533, 0.9169643, 0.8973214, 0.93705356, 0.9607143, 0.77879465, 0.86316967, 0.96339285, 0.9738839, 0.98080355, 0.89017856, 0.96227676, 0.9660714, 0.88660717, 0.92834824, 0.9542411, 0.9747768, 0.99776787, 0.99263394, 0.9220982, 0.778125, 0.89709824, 0.9247768, 0.96428573, 0.99665177, 0.828125, 0.9404018, 0.96316963, 0.8296875, 0.9345982, 0.8830357, 0.95714283, 0.87098217, 0.86763394, 0.95178574, 0.9988839, 0.9685268, 0.93816966, 0.9948661, 0.9901786, 1.0, 0.9511161, 1.0, 0.9919643, 0.9754464, 0.8819196, 0.91808033, 0.8377232, 0.9892857, 0.9372768, 0.70647323, 0.9930804, 0.9051339, 0.8747768, 0.9660714, 0.94888395, 0.878125, 0.9629464, 0.8125, 0.9618304, 0.8966518, 0.978125, 0.99776787, 0.99933034, 0.8779018, 0.90290177, 0.96316963, 0.74598217, 0.8984375, 0.9267857, 0.9296875, 0.8848214, 0.9314732, 0.8098214, 0.89598215, 0.99375, 0.90625, 0.91964287, 1.0, 0.91450894, 0.8767857, 0.97410715, 0.9598214, 0.96830356, 0.97299105, 0.8375, 0.9676339, 0.9279018, 0.79933035, 0.96540177, 0.89464283, 0.9383929, 0.9042411, 0.75133926, 0.9484375, 0.82366073, 0.94910717, 0.996875, 0.9345982, 0.8995536, 0.81316966, 0.9736607, 0.9160714, 0.9245536, 0.9834821, 0.68995535, 0.81674105, 0.84129465, 0.9558036, 0.92410713, 0.92745537]\n",
      "[0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.9997768, 1.0, 0.9473214, 0.9375, 0.94575894, 0.9950893, 0.99933034, 0.97723216, 0.8779018, 0.9979911, 0.9738839, 0.98683035, 0.965625, 1.0, 0.8986607, 0.86473215, 0.95691967, 0.84754467, 0.9904018, 0.98303574, 0.88147324, 1.0, 0.9502232, 0.9618304, 0.9765625, 0.9640625, 0.95066965, 0.9160714, 0.99776787, 0.98995537, 0.94888395, 0.91651785, 0.9941964, 0.9745536, 0.9912946, 1.0, 0.95066965, 0.9747768, 0.8671875, 0.9549107, 0.98035717, 0.97589284, 0.9984375, 0.8611607, 0.9991071, 1.0, 0.99575895, 0.99955356, 0.95848215, 0.97098213, 0.97522324, 0.9982143, 0.99955356, 0.9763393, 0.99754465, 0.89799106, 0.98772323, 0.88638395, 0.95535713, 0.91540176, 0.9607143, 0.9854911, 0.88035715, 0.93035716, 0.9600446, 0.92834824, 0.98861605, 0.9676339, 0.9982143, 1.0, 0.99955356, 0.9785714, 0.9714286, 0.9912946, 0.9997768, 0.9904018, 0.99866074, 1.0, 0.8689732, 0.9734375, 0.9921875, 0.97522324, 0.97254467, 0.9435268, 0.9578125, 0.98125, 0.9765625, 0.984375, 1.0, 0.9841518, 1.0, 0.97589284, 0.97723216, 0.96919644, 0.99575895, 0.86272323, 0.9424107, 0.99642855, 1.0, 1.0, 0.9933036, 0.9979911, 1.0, 0.97901785, 0.98794645, 0.9939732, 0.99866074, 1.0, 1.0, 0.99620533, 0.8654018, 0.94888395, 0.9792411, 0.99933034, 1.0, 0.92321426, 0.9901786, 0.9973214, 0.91763395, 0.98058033, 0.9705357, 0.9979911, 0.96428573, 0.9716518, 0.9776786, 1.0, 0.9982143, 0.9997768, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997768, 0.9912946, 0.990625, 0.94486606, 0.9997768, 0.98772323, 0.86674106, 1.0, 0.971875, 0.93705356, 0.9950893, 0.99776787, 0.9455357, 0.98995537, 0.9151786, 0.9997768, 0.9607143, 0.99642855, 0.9997768, 1.0, 0.9522321, 0.97901785, 0.9997768, 0.8904018, 0.9832589, 0.96941966, 0.98125, 0.94575894, 0.9796875, 0.89441967, 0.9558036, 0.9979911, 0.9984375, 0.9620536, 1.0, 0.975, 0.95089287, 0.9988839, 0.99642855, 1.0, 0.99933034, 0.97321427, 0.99754465, 0.9970982, 0.9198661, 0.99441963, 0.95625, 0.9852679, 0.9859375, 0.8776786, 0.9953125, 0.934375, 0.9845982, 1.0, 0.99285716, 0.95691967, 0.93013394, 0.9973214, 0.98013395, 0.9910714, 1.0, 0.8457589, 0.91785717, 0.91785717, 0.99933034, 0.9982143, 0.97589284]\n",
      "i_s=201 in 500;  max_index=425107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 238s 3s/step - loss: 0.0685 - accuracy: 0.9837 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.2620 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=202 in 500;  max_index=426407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.9754 - accuracy: 0.8453 - top_k_categorical_accuracy: 0.9382 - val_loss: 3.2529 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=203 in 500;  max_index=427707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.2261 - accuracy: 0.9536 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.1216 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=204 in 500;  max_index=429007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 1.0205 - accuracy: 0.8458 - top_k_categorical_accuracy: 0.9176 - val_loss: 6.8970 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=205 in 500;  max_index=430307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.2199 - accuracy: 0.9625 - top_k_categorical_accuracy: 0.9839 - val_loss: 2.0395 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=206 in 500;  max_index=431607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 1.1588 - accuracy: 0.7868 - top_k_categorical_accuracy: 0.8938 - val_loss: 3.6998 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=207 in 500;  max_index=432907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.2899 - accuracy: 0.9362 - top_k_categorical_accuracy: 0.9830 - val_loss: 1.0573 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=208 in 500;  max_index=434207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 1.3266 - accuracy: 0.7712 - top_k_categorical_accuracy: 0.8562 - val_loss: 5.6746 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=209 in 500;  max_index=435507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.0565 - accuracy: 0.9862 - top_k_categorical_accuracy: 0.9960 - val_loss: 0.0110 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=210 in 500;  max_index=436807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.1559 - accuracy: 0.9632 - top_k_categorical_accuracy: 0.9960 - val_loss: 3.8436 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=211 in 500;  max_index=438107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 1.5329 - accuracy: 0.7214 - top_k_categorical_accuracy: 0.8299 - val_loss: 6.8714 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=212 in 500;  max_index=439407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.4174 - accuracy: 0.9109 - top_k_categorical_accuracy: 0.9670 - val_loss: 6.6514 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=213 in 500;  max_index=440707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.4410 - accuracy: 0.9100 - top_k_categorical_accuracy: 0.9654 - val_loss: 4.3777 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=214 in 500;  max_index=442007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 0.4927 - accuracy: 0.9002 - top_k_categorical_accuracy: 0.9540 - val_loss: 5.2572 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=215 in 500;  max_index=443307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 0.2077 - accuracy: 0.9513 - top_k_categorical_accuracy: 0.9886 - val_loss: 6.1896 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=216 in 500;  max_index=444607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 268s 4s/step - loss: 0.3267 - accuracy: 0.9252 - top_k_categorical_accuracy: 0.9799 - val_loss: 1.3551 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=217 in 500;  max_index=445907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 272s 4s/step - loss: 0.4819 - accuracy: 0.8875 - top_k_categorical_accuracy: 0.9824 - val_loss: 1.3756 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=218 in 500;  max_index=447207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 262s 4s/step - loss: 0.2185 - accuracy: 0.9462 - top_k_categorical_accuracy: 0.9955 - val_loss: 0.1573 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=219 in 500;  max_index=448507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.0372 - accuracy: 0.9868 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5733 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=220 in 500;  max_index=449807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 1.2179 - accuracy: 0.8029 - top_k_categorical_accuracy: 0.9574 - val_loss: 4.3198 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=221 in 500;  max_index=451107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 278s 4s/step - loss: 0.1922 - accuracy: 0.9484 - top_k_categorical_accuracy: 0.9982 - val_loss: 1.3318 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=222 in 500;  max_index=452407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.6735 - accuracy: 0.8712 - top_k_categorical_accuracy: 0.9560 - val_loss: 4.7305 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=223 in 500;  max_index=453707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.2122 - accuracy: 0.9533 - top_k_categorical_accuracy: 0.9882 - val_loss: 1.9615 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=224 in 500;  max_index=455007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 270s 4s/step - loss: 0.7811 - accuracy: 0.8254 - top_k_categorical_accuracy: 0.9422 - val_loss: 3.5499 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=225 in 500;  max_index=456307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 274s 4s/step - loss: 0.1032 - accuracy: 0.9723 - top_k_categorical_accuracy: 0.9944 - val_loss: 0.0661 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=226 in 500;  max_index=457607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 0.0911 - accuracy: 0.9750 - top_k_categorical_accuracy: 0.9987 - val_loss: 4.6344 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=227 in 500;  max_index=458907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.0448 - accuracy: 0.9904 - top_k_categorical_accuracy: 0.9982 - val_loss: 2.0769 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=228 in 500;  max_index=460207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 273s 4s/step - loss: 0.3234 - accuracy: 0.9339 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=229 in 500;  max_index=461507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 265s 4s/step - loss: 0.7657 - accuracy: 0.8616 - top_k_categorical_accuracy: 0.9683 - val_loss: 4.8186 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=230 in 500;  max_index=462807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 262s 4s/step - loss: 0.5939 - accuracy: 0.8712 - top_k_categorical_accuracy: 0.9565 - val_loss: 5.4949 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=231 in 500;  max_index=464107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 1.4927 - accuracy: 0.7105 - top_k_categorical_accuracy: 0.8129 - val_loss: 3.4802 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=232 in 500;  max_index=465407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 268s 4s/step - loss: 0.2538 - accuracy: 0.9417 - top_k_categorical_accuracy: 0.9815 - val_loss: 1.9308 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=233 in 500;  max_index=466707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 288s 4s/step - loss: 0.1360 - accuracy: 0.9650 - top_k_categorical_accuracy: 0.9946 - val_loss: 3.2418 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=234 in 500;  max_index=468007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.4416 - accuracy: 0.9022 - top_k_categorical_accuracy: 0.9824 - val_loss: 2.0932 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=235 in 500;  max_index=469307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.1905 - accuracy: 0.9525 - top_k_categorical_accuracy: 0.9940 - val_loss: 4.5512 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=236 in 500;  max_index=470607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.1870 - accuracy: 0.9589 - top_k_categorical_accuracy: 0.9844 - val_loss: 2.7682 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=237 in 500;  max_index=471907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 1.1900 - accuracy: 0.7752 - top_k_categorical_accuracy: 0.8692 - val_loss: 5.9335 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=238 in 500;  max_index=473207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.2083 - accuracy: 0.9547 - top_k_categorical_accuracy: 0.9824 - val_loss: 1.8313 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=239 in 500;  max_index=474507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.2336 - accuracy: 0.9420 - top_k_categorical_accuracy: 0.9884 - val_loss: 4.2040 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=240 in 500;  max_index=475807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.0841 - accuracy: 0.9746 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.5329 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=241 in 500;  max_index=477107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.2761 - accuracy: 0.9353 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=242 in 500;  max_index=478407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.4530 - accuracy: 0.9092 - top_k_categorical_accuracy: 0.9902 - val_loss: 6.2452 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=243 in 500;  max_index=479707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 0.7382 - accuracy: 0.8493 - top_k_categorical_accuracy: 0.9475 - val_loss: 3.4889 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=244 in 500;  max_index=481007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 268s 4s/step - loss: 0.2903 - accuracy: 0.9344 - top_k_categorical_accuracy: 0.9895 - val_loss: 1.3488 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=245 in 500;  max_index=482307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 1.1125 - accuracy: 0.7632 - top_k_categorical_accuracy: 0.8884 - val_loss: 4.9800 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=246 in 500;  max_index=483607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.0620 - accuracy: 0.9891 - top_k_categorical_accuracy: 0.9980 - val_loss: 5.2136 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=247 in 500;  max_index=484907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.2958 - accuracy: 0.9337 - top_k_categorical_accuracy: 0.9850 - val_loss: 4.2424 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=248 in 500;  max_index=486207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 229s 3s/step - loss: 0.3154 - accuracy: 0.9304 - top_k_categorical_accuracy: 0.9958 - val_loss: 1.1247 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=249 in 500;  max_index=487507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 1.4020 - accuracy: 0.7491 - top_k_categorical_accuracy: 0.8592 - val_loss: 5.1025 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=250 in 500;  max_index=488807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.4280 - accuracy: 0.8866 - top_k_categorical_accuracy: 0.9808 - val_loss: 0.6562 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=251 in 500;  max_index=490107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 239s 3s/step - loss: 0.0030 - accuracy: 0.9996 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=252 in 500;  max_index=491407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 1.1012 - accuracy: 0.8221 - top_k_categorical_accuracy: 0.9145 - val_loss: 4.7142 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=253 in 500;  max_index=492707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.5560 - accuracy: 0.8853 - top_k_categorical_accuracy: 0.9431 - val_loss: 2.1412 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=254 in 500;  max_index=494007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 236s 3s/step - loss: 0.1207 - accuracy: 0.9679 - top_k_categorical_accuracy: 0.9933 - val_loss: 0.2310 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=255 in 500;  max_index=495307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.0075 - accuracy: 0.9980 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=256 in 500;  max_index=496607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.2397 - accuracy: 0.9462 - top_k_categorical_accuracy: 0.9962 - val_loss: 4.0007 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=257 in 500;  max_index=497907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 229s 3s/step - loss: 0.1388 - accuracy: 0.9656 - top_k_categorical_accuracy: 0.9987 - val_loss: 2.2419 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=258 in 500;  max_index=499207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 251s 4s/step - loss: 0.1596 - accuracy: 0.9609 - top_k_categorical_accuracy: 0.9969 - val_loss: 0.1645 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=259 in 500;  max_index=500507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.2490 - accuracy: 0.9406 - top_k_categorical_accuracy: 0.9913 - val_loss: 1.6763 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=260 in 500;  max_index=501807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 232s 3s/step - loss: 0.2721 - accuracy: 0.9335 - top_k_categorical_accuracy: 0.9770 - val_loss: 4.1822 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=261 in 500;  max_index=503107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 3s/step - loss: 0.2658 - accuracy: 0.9563 - top_k_categorical_accuracy: 0.9969 - val_loss: 0.0413 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=262 in 500;  max_index=504407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 0.1789 - accuracy: 0.9565 - top_k_categorical_accuracy: 0.9987 - val_loss: 0.4878 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=263 in 500;  max_index=505707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.0675 - accuracy: 0.9833 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.2339 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=264 in 500;  max_index=507007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.1638 - accuracy: 0.9645 - top_k_categorical_accuracy: 0.9998 - val_loss: 3.3254 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=265 in 500;  max_index=508307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.3315 - accuracy: 0.9292 - top_k_categorical_accuracy: 0.9969 - val_loss: 0.6366 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=266 in 500;  max_index=509607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 1.8127 - accuracy: 0.6951 - top_k_categorical_accuracy: 0.8335 - val_loss: 5.6954 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=267 in 500;  max_index=510907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.1450 - accuracy: 0.9656 - top_k_categorical_accuracy: 0.9942 - val_loss: 1.3234 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=268 in 500;  max_index=512207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.2184 - accuracy: 0.9547 - top_k_categorical_accuracy: 0.9844 - val_loss: 0.0160 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=269 in 500;  max_index=513507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 231s 3s/step - loss: 1.1052 - accuracy: 0.8196 - top_k_categorical_accuracy: 0.9346 - val_loss: 5.6930 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=270 in 500;  max_index=514807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 1.0219 - accuracy: 0.7949 - top_k_categorical_accuracy: 0.9147 - val_loss: 4.3951 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=271 in 500;  max_index=516107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 0.2417 - accuracy: 0.9366 - top_k_categorical_accuracy: 0.9942 - val_loss: 0.7907 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=272 in 500;  max_index=517407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.4569 - accuracy: 0.9071 - top_k_categorical_accuracy: 0.9866 - val_loss: 2.0357 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=273 in 500;  max_index=518707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.4884 - accuracy: 0.9161 - top_k_categorical_accuracy: 0.9667 - val_loss: 3.5561 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=274 in 500;  max_index=520007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.1251 - accuracy: 0.9681 - top_k_categorical_accuracy: 0.9949 - val_loss: 0.6704 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=275 in 500;  max_index=521307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.3476 - accuracy: 0.9266 - top_k_categorical_accuracy: 0.9924 - val_loss: 0.2651 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=276 in 500;  max_index=522607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.0176 - accuracy: 0.9951 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2152 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=277 in 500;  max_index=523907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 1.4291 - accuracy: 0.7592 - top_k_categorical_accuracy: 0.8654 - val_loss: 4.5348 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=278 in 500;  max_index=525207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 272s 4s/step - loss: 0.3656 - accuracy: 0.9049 - top_k_categorical_accuracy: 0.9846 - val_loss: 3.6427 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=279 in 500;  max_index=526507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 1.1743 - accuracy: 0.7812 - top_k_categorical_accuracy: 0.8770 - val_loss: 3.1755 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=280 in 500;  max_index=527807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 0.0404 - accuracy: 0.9915 - top_k_categorical_accuracy: 0.9987 - val_loss: 0.6189 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=281 in 500;  max_index=529107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 259s 4s/step - loss: 0.0484 - accuracy: 0.9884 - top_k_categorical_accuracy: 0.9973 - val_loss: 1.6153 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=282 in 500;  max_index=530407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 274s 4s/step - loss: 0.3150 - accuracy: 0.9310 - top_k_categorical_accuracy: 0.9955 - val_loss: 0.5791 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=283 in 500;  max_index=531707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.0207 - accuracy: 0.9935 - top_k_categorical_accuracy: 0.9998 - val_loss: 2.7037 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=284 in 500;  max_index=533007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.1167 - accuracy: 0.9714 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6895 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=285 in 500;  max_index=534307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.9985 - accuracy: 0.8210 - top_k_categorical_accuracy: 0.9493 - val_loss: 6.1315 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=286 in 500;  max_index=535607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.2980 - accuracy: 0.9263 - top_k_categorical_accuracy: 0.9815 - val_loss: 2.1540 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=287 in 500;  max_index=536907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 238s 3s/step - loss: 0.6654 - accuracy: 0.8665 - top_k_categorical_accuracy: 0.9480 - val_loss: 4.5192 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=288 in 500;  max_index=538207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 0.9374 - accuracy: 0.7996 - top_k_categorical_accuracy: 0.9116 - val_loss: 2.6984 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=289 in 500;  max_index=539507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 275s 4s/step - loss: 0.0171 - accuracy: 0.9984 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6853 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=290 in 500;  max_index=540807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 275s 4s/step - loss: 0.8151 - accuracy: 0.8433 - top_k_categorical_accuracy: 0.9683 - val_loss: 3.6585 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=291 in 500;  max_index=542107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.1692 - accuracy: 0.9565 - top_k_categorical_accuracy: 0.9996 - val_loss: 2.5786 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=292 in 500;  max_index=543407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 259s 4s/step - loss: 0.4554 - accuracy: 0.9337 - top_k_categorical_accuracy: 0.9911 - val_loss: 0.6452 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=293 in 500;  max_index=544707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 1.0359 - accuracy: 0.7777 - top_k_categorical_accuracy: 0.9279 - val_loss: 5.1699 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=294 in 500;  max_index=546007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 236s 3s/step - loss: 0.1788 - accuracy: 0.9563 - top_k_categorical_accuracy: 0.9949 - val_loss: 3.2544 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=295 in 500;  max_index=547307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 0.1763 - accuracy: 0.9578 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.0085 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=296 in 500;  max_index=548607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.3937 - accuracy: 0.9205 - top_k_categorical_accuracy: 0.9967 - val_loss: 3.2171 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=297 in 500;  max_index=549907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.7254 - accuracy: 0.8587 - top_k_categorical_accuracy: 0.9243 - val_loss: 4.0014 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=298 in 500;  max_index=551207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 276s 4s/step - loss: 0.0073 - accuracy: 0.9991 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=299 in 500;  max_index=552507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.3626 - accuracy: 0.9290 - top_k_categorical_accuracy: 0.9971 - val_loss: 2.7728 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=300 in 500;  max_index=553807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.3136 - accuracy: 0.9304 - top_k_categorical_accuracy: 0.9931 - val_loss: 0.2006 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 0.9825893, 0.99754465, 0.8564732, 0.7959821, 0.8779018, 0.9238839, 0.9859375, 0.87098217, 0.76316965, 0.9794643, 0.90267855, 0.9529018, 0.8933036, 0.99151784, 0.7511161, 0.7254464, 0.90089285, 0.7517857, 0.8995536, 0.94977677, 0.7705357, 0.99866074, 0.81696427, 0.8986607, 0.90982145, 0.91026783, 0.8620536, 0.82254463, 0.91183037, 0.9216518, 0.9, 0.83839285, 0.959375, 0.9207589, 0.95848215, 0.9948661, 0.84732145, 0.91339284, 0.71875, 0.8953125, 0.928125, 0.9363839, 0.94977677, 0.7526786, 0.9783482, 0.99754465, 0.9227679, 0.9783482, 0.84419644, 0.86183035, 0.8904018, 0.93683034, 0.9522321, 0.87254465, 0.9560268, 0.8194196, 0.8879464, 0.7296875, 0.9089286, 0.8020089, 0.8908482, 0.9479911, 0.72209823, 0.8584821, 0.9171875, 0.7988839, 0.9580357, 0.8388393, 0.9609375, 0.9991071, 0.9013393, 0.9171875, 0.9080357, 0.94977677, 0.9676339, 0.89977676, 0.97299105, 1.0, 0.73683035, 0.91941965, 0.93370533, 0.9042411, 0.92544645, 0.89285713, 0.92232144, 0.92723215, 0.93214285, 0.95, 0.9870536, 0.915625, 0.99620533, 0.9169643, 0.8973214, 0.93705356, 0.9607143, 0.77879465, 0.86316967, 0.96339285, 0.9738839, 0.98080355, 0.89017856, 0.96227676, 0.9660714, 0.88660717, 0.92834824, 0.9542411, 0.9747768, 0.99776787, 0.99263394, 0.9220982, 0.778125, 0.89709824, 0.9247768, 0.96428573, 0.99665177, 0.828125, 0.9404018, 0.96316963, 0.8296875, 0.9345982, 0.8830357, 0.95714283, 0.87098217, 0.86763394, 0.95178574, 0.9988839, 0.9685268, 0.93816966, 0.9948661, 0.9901786, 1.0, 0.9511161, 1.0, 0.9919643, 0.9754464, 0.8819196, 0.91808033, 0.8377232, 0.9892857, 0.9372768, 0.70647323, 0.9930804, 0.9051339, 0.8747768, 0.9660714, 0.94888395, 0.878125, 0.9629464, 0.8125, 0.9618304, 0.8966518, 0.978125, 0.99776787, 0.99933034, 0.8779018, 0.90290177, 0.96316963, 0.74598217, 0.8984375, 0.9267857, 0.9296875, 0.8848214, 0.9314732, 0.8098214, 0.89598215, 0.99375, 0.90625, 0.91964287, 1.0, 0.91450894, 0.8767857, 0.97410715, 0.9598214, 0.96830356, 0.97299105, 0.8375, 0.9676339, 0.9279018, 0.79933035, 0.96540177, 0.89464283, 0.9383929, 0.9042411, 0.75133926, 0.9484375, 0.82366073, 0.94910717, 0.996875, 0.9345982, 0.8995536, 0.81316966, 0.9736607, 0.9160714, 0.9245536, 0.9834821, 0.68995535, 0.81674105, 0.84129465, 0.9558036, 0.92410713, 0.92745537, 0.98370534, 0.8453125, 0.95357144, 0.8457589, 0.9625, 0.78683037, 0.93616074, 0.77120537, 0.9861607, 0.96316963, 0.7214286, 0.9109375, 0.91004467, 0.9002232, 0.9513393, 0.92522323, 0.8875, 0.9462054, 0.98683035, 0.8029018, 0.9484375, 0.87120533, 0.9533482, 0.8254464, 0.97232145, 0.975, 0.9904018, 0.93392855, 0.86160713, 0.87120533, 0.71049106, 0.94174105, 0.96495533, 0.90223217, 0.95245534, 0.9589286, 0.7752232, 0.9546875, 0.94196427, 0.9745536, 0.93526787, 0.9091518, 0.84933037, 0.934375, 0.76316965, 0.9890625, 0.93370533, 0.93035716, 0.7491071, 0.88660717, 0.99955356, 0.8220982, 0.88526785, 0.9678571, 0.9979911, 0.9462054, 0.965625, 0.9609375, 0.940625, 0.93348217, 0.95625, 0.95647323, 0.9832589, 0.96450895, 0.92924106, 0.6950893, 0.965625, 0.9546875, 0.81964284, 0.7948661, 0.9366071, 0.9071429, 0.9160714, 0.96808034, 0.9265625, 0.9950893, 0.75915176, 0.90491074, 0.78125, 0.99151784, 0.98839283, 0.93102676, 0.99352676, 0.9714286, 0.82098216, 0.92633927, 0.86651784, 0.7995536, 0.9984375, 0.84330356, 0.95647323, 0.93370533, 0.77767855, 0.95625, 0.9578125, 0.92053574, 0.85870534, 0.9991071, 0.92901784, 0.93035716]\n",
      "[0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
      "[0.0, 0.0, 0.9997768, 1.0, 0.9473214, 0.9375, 0.94575894, 0.9950893, 0.99933034, 0.97723216, 0.8779018, 0.9979911, 0.9738839, 0.98683035, 0.965625, 1.0, 0.8986607, 0.86473215, 0.95691967, 0.84754467, 0.9904018, 0.98303574, 0.88147324, 1.0, 0.9502232, 0.9618304, 0.9765625, 0.9640625, 0.95066965, 0.9160714, 0.99776787, 0.98995537, 0.94888395, 0.91651785, 0.9941964, 0.9745536, 0.9912946, 1.0, 0.95066965, 0.9747768, 0.8671875, 0.9549107, 0.98035717, 0.97589284, 0.9984375, 0.8611607, 0.9991071, 1.0, 0.99575895, 0.99955356, 0.95848215, 0.97098213, 0.97522324, 0.9982143, 0.99955356, 0.9763393, 0.99754465, 0.89799106, 0.98772323, 0.88638395, 0.95535713, 0.91540176, 0.9607143, 0.9854911, 0.88035715, 0.93035716, 0.9600446, 0.92834824, 0.98861605, 0.9676339, 0.9982143, 1.0, 0.99955356, 0.9785714, 0.9714286, 0.9912946, 0.9997768, 0.9904018, 0.99866074, 1.0, 0.8689732, 0.9734375, 0.9921875, 0.97522324, 0.97254467, 0.9435268, 0.9578125, 0.98125, 0.9765625, 0.984375, 1.0, 0.9841518, 1.0, 0.97589284, 0.97723216, 0.96919644, 0.99575895, 0.86272323, 0.9424107, 0.99642855, 1.0, 1.0, 0.9933036, 0.9979911, 1.0, 0.97901785, 0.98794645, 0.9939732, 0.99866074, 1.0, 1.0, 0.99620533, 0.8654018, 0.94888395, 0.9792411, 0.99933034, 1.0, 0.92321426, 0.9901786, 0.9973214, 0.91763395, 0.98058033, 0.9705357, 0.9979911, 0.96428573, 0.9716518, 0.9776786, 1.0, 0.9982143, 0.9997768, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997768, 0.9912946, 0.990625, 0.94486606, 0.9997768, 0.98772323, 0.86674106, 1.0, 0.971875, 0.93705356, 0.9950893, 0.99776787, 0.9455357, 0.98995537, 0.9151786, 0.9997768, 0.9607143, 0.99642855, 0.9997768, 1.0, 0.9522321, 0.97901785, 0.9997768, 0.8904018, 0.9832589, 0.96941966, 0.98125, 0.94575894, 0.9796875, 0.89441967, 0.9558036, 0.9979911, 0.9984375, 0.9620536, 1.0, 0.975, 0.95089287, 0.9988839, 0.99642855, 1.0, 0.99933034, 0.97321427, 0.99754465, 0.9970982, 0.9198661, 0.99441963, 0.95625, 0.9852679, 0.9859375, 0.8776786, 0.9953125, 0.934375, 0.9845982, 1.0, 0.99285716, 0.95691967, 0.93013394, 0.9973214, 0.98013395, 0.9910714, 1.0, 0.8457589, 0.91785717, 0.91785717, 0.99933034, 0.9982143, 0.97589284, 0.99955356, 0.93816966, 0.984375, 0.91763395, 0.98392856, 0.89375, 0.98303574, 0.85625, 0.99598217, 0.99598217, 0.8299107, 0.9669643, 0.96540177, 0.9540179, 0.98861605, 0.97991073, 0.9823661, 0.99553573, 1.0, 0.95736605, 0.9982143, 0.9560268, 0.98816967, 0.9421875, 0.99441963, 0.99866074, 0.9982143, 1.0, 0.96830356, 0.95647323, 0.81294644, 0.9814732, 0.99464285, 0.9823661, 0.9939732, 0.984375, 0.8691964, 0.9823661, 0.98839283, 0.9997768, 0.99955356, 0.9901786, 0.94754463, 0.9895089, 0.88839287, 0.9979911, 0.98504466, 0.99575895, 0.8591518, 0.98080355, 1.0, 0.91450894, 0.94308037, 0.9933036, 1.0, 0.99620533, 0.99866074, 0.996875, 0.9912946, 0.97700894, 0.996875, 0.99866074, 0.99933034, 0.9997768, 0.996875, 0.83348215, 0.9941964, 0.984375, 0.9345982, 0.91473216, 0.9941964, 0.98660713, 0.9667411, 0.9948661, 0.9924107, 1.0, 0.8654018, 0.9845982, 0.8770089, 0.99866074, 0.9973214, 0.99553573, 0.9997768, 1.0, 0.94933033, 0.9814732, 0.9479911, 0.91160715, 1.0, 0.96830356, 0.99955356, 0.9910714, 0.9279018, 0.9948661, 0.9997768, 0.99665177, 0.92433035, 1.0, 0.9970982, 0.9930804]\n",
      "i_s=301 in 500;  max_index=555107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.5832 - accuracy: 0.8875 - top_k_categorical_accuracy: 0.9969 - val_loss: 0.7613 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=302 in 500;  max_index=556407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 260s 4s/step - loss: 0.0033 - accuracy: 0.9996 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5010 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=303 in 500;  max_index=557707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 241s 3s/step - loss: 0.4069 - accuracy: 0.9114 - top_k_categorical_accuracy: 0.9915 - val_loss: 2.6598 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=304 in 500;  max_index=559007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 241s 3s/step - loss: 0.8274 - accuracy: 0.8047 - top_k_categorical_accuracy: 0.9833 - val_loss: 4.4365 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=305 in 500;  max_index=560307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 262s 4s/step - loss: 0.1405 - accuracy: 0.9587 - top_k_categorical_accuracy: 0.9993 - val_loss: 2.3871 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=306 in 500;  max_index=561607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 259s 4s/step - loss: 1.1714 - accuracy: 0.8114 - top_k_categorical_accuracy: 0.9036 - val_loss: 7.1433 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=307 in 500;  max_index=562907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 235s 3s/step - loss: 0.3064 - accuracy: 0.9210 - top_k_categorical_accuracy: 0.9817 - val_loss: 1.2424 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=308 in 500;  max_index=564207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 233s 3s/step - loss: 0.3070 - accuracy: 0.9321 - top_k_categorical_accuracy: 0.9971 - val_loss: 1.4243 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=309 in 500;  max_index=565507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 273s 4s/step - loss: 0.5552 - accuracy: 0.8839 - top_k_categorical_accuracy: 0.9801 - val_loss: 2.7169 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=310 in 500;  max_index=566807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.0193 - accuracy: 0.9942 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7526 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=311 in 500;  max_index=568107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.3586 - accuracy: 0.9194 - top_k_categorical_accuracy: 0.9969 - val_loss: 0.2846 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=312 in 500;  max_index=569407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 259s 4s/step - loss: 1.2823 - accuracy: 0.8056 - top_k_categorical_accuracy: 0.9016 - val_loss: 7.2139 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=313 in 500;  max_index=570707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.2456 - accuracy: 0.9335 - top_k_categorical_accuracy: 0.9915 - val_loss: 4.1833 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=314 in 500;  max_index=572007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.3926 - accuracy: 0.9172 - top_k_categorical_accuracy: 0.9949 - val_loss: 2.4565 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=315 in 500;  max_index=573307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 1.5548 - accuracy: 0.7355 - top_k_categorical_accuracy: 0.8248 - val_loss: 5.8084 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=316 in 500;  max_index=574607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.2024 - accuracy: 0.9527 - top_k_categorical_accuracy: 0.9946 - val_loss: 5.2298 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=317 in 500;  max_index=575907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.2335 - accuracy: 0.9357 - top_k_categorical_accuracy: 0.9908 - val_loss: 0.1187 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=318 in 500;  max_index=577207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 230s 3s/step - loss: 0.0064 - accuracy: 0.9980 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=319 in 500;  max_index=578507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.5523 - accuracy: 0.8953 - top_k_categorical_accuracy: 0.9987 - val_loss: 3.3973 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=320 in 500;  max_index=579807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.2113 - accuracy: 0.9531 - top_k_categorical_accuracy: 0.9975 - val_loss: 4.1926 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=321 in 500;  max_index=581107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.0960 - accuracy: 0.9717 - top_k_categorical_accuracy: 0.9984 - val_loss: 3.1610 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=322 in 500;  max_index=582407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.4360 - accuracy: 0.8900 - top_k_categorical_accuracy: 0.9969 - val_loss: 4.1698 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=323 in 500;  max_index=583707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.2969 - accuracy: 0.9304 - top_k_categorical_accuracy: 0.9926 - val_loss: 0.3539 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=324 in 500;  max_index=585007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 232s 3s/step - loss: 0.1313 - accuracy: 0.9596 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=325 in 500;  max_index=586307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.2453 - accuracy: 0.9493 - top_k_categorical_accuracy: 0.9987 - val_loss: 0.0690 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=326 in 500;  max_index=587607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 0.0538 - accuracy: 0.9839 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5500 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=327 in 500;  max_index=588907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 1.1694 - accuracy: 0.8109 - top_k_categorical_accuracy: 0.9174 - val_loss: 4.7987 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=328 in 500;  max_index=590207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 0.4046 - accuracy: 0.9118 - top_k_categorical_accuracy: 0.9746 - val_loss: 2.9483 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=329 in 500;  max_index=591507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 277s 4s/step - loss: 0.2476 - accuracy: 0.9337 - top_k_categorical_accuracy: 0.9989 - val_loss: 0.0488 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=330 in 500;  max_index=592807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.2020 - accuracy: 0.9589 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.7120 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=331 in 500;  max_index=594107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.1877 - accuracy: 0.9592 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4708 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=332 in 500;  max_index=595407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 1.0159 - accuracy: 0.8080 - top_k_categorical_accuracy: 0.9516 - val_loss: 4.8676 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=333 in 500;  max_index=596707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.0055 - accuracy: 0.9987 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=334 in 500;  max_index=598007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.4484 - accuracy: 0.9092 - top_k_categorical_accuracy: 0.9926 - val_loss: 1.0658 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=335 in 500;  max_index=599307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.2273 - accuracy: 0.9395 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.9296 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=336 in 500;  max_index=600607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 1.5497 - accuracy: 0.7391 - top_k_categorical_accuracy: 0.8632 - val_loss: 4.7673 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=337 in 500;  max_index=601907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 239s 3s/step - loss: 0.4506 - accuracy: 0.9022 - top_k_categorical_accuracy: 0.9638 - val_loss: 1.0624 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=338 in 500;  max_index=603207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.2630 - accuracy: 0.9420 - top_k_categorical_accuracy: 0.9788 - val_loss: 0.0486 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=339 in 500;  max_index=604507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.3883 - accuracy: 0.9080 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.3638 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=340 in 500;  max_index=605807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.2290 - accuracy: 0.9413 - top_k_categorical_accuracy: 0.9900 - val_loss: 3.2150 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=341 in 500;  max_index=607107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.0899 - accuracy: 0.9750 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.1479 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=342 in 500;  max_index=608407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.1806 - accuracy: 0.9609 - top_k_categorical_accuracy: 0.9969 - val_loss: 1.0634 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=343 in 500;  max_index=609707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 279s 4s/step - loss: 0.6333 - accuracy: 0.8746 - top_k_categorical_accuracy: 0.9969 - val_loss: 2.4567 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=344 in 500;  max_index=611007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 281s 4s/step - loss: 0.1690 - accuracy: 0.9547 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=345 in 500;  max_index=612307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 258s 4s/step - loss: 0.1667 - accuracy: 0.9636 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=346 in 500;  max_index=613607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 272s 4s/step - loss: 2.8010 - accuracy: 0.5703 - top_k_categorical_accuracy: 0.6969 - val_loss: 9.8603 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=347 in 500;  max_index=614907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 265s 4s/step - loss: 0.0610 - accuracy: 0.9819 - top_k_categorical_accuracy: 0.9984 - val_loss: 0.6140 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=348 in 500;  max_index=616207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 291s 4s/step - loss: 0.5775 - accuracy: 0.8770 - top_k_categorical_accuracy: 0.9797 - val_loss: 2.2115 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=349 in 500;  max_index=617507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 272s 4s/step - loss: 0.0096 - accuracy: 0.9969 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5522 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=350 in 500;  max_index=618807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 272s 4s/step - loss: 0.8319 - accuracy: 0.8181 - top_k_categorical_accuracy: 0.9877 - val_loss: 4.7792 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=351 in 500;  max_index=620107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 286s 4s/step - loss: 0.1465 - accuracy: 0.9618 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.6942 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=352 in 500;  max_index=621407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.3177 - accuracy: 0.9261 - top_k_categorical_accuracy: 0.9955 - val_loss: 1.4732 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=353 in 500;  max_index=622707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 270s 4s/step - loss: 0.3919 - accuracy: 0.9116 - top_k_categorical_accuracy: 0.9944 - val_loss: 4.5123 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=354 in 500;  max_index=624007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 245s 4s/step - loss: 0.3617 - accuracy: 0.9254 - top_k_categorical_accuracy: 0.9864 - val_loss: 8.6122 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=355 in 500;  max_index=625307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 265s 4s/step - loss: 0.2405 - accuracy: 0.9342 - top_k_categorical_accuracy: 0.9958 - val_loss: 0.9226 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=356 in 500;  max_index=626607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 287s 4s/step - loss: 2.3268 - accuracy: 0.4866 - top_k_categorical_accuracy: 0.7359 - val_loss: 5.5240 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=357 in 500;  max_index=627907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.2384 - accuracy: 0.9469 - top_k_categorical_accuracy: 0.9857 - val_loss: 0.0067 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=358 in 500;  max_index=629207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.0022 - accuracy: 0.9998 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=359 in 500;  max_index=630507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.2768 - accuracy: 0.9239 - top_k_categorical_accuracy: 0.9989 - val_loss: 2.5018 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=360 in 500;  max_index=631807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.1173 - accuracy: 0.9705 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2143 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=361 in 500;  max_index=633107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 239s 3s/step - loss: 0.4563 - accuracy: 0.9326 - top_k_categorical_accuracy: 0.9967 - val_loss: 1.0849 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=362 in 500;  max_index=634407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 269s 4s/step - loss: 0.3121 - accuracy: 0.9268 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.3650 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=363 in 500;  max_index=635707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 238s 3s/step - loss: 1.3458 - accuracy: 0.7292 - top_k_categorical_accuracy: 0.8696 - val_loss: 6.4646 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=364 in 500;  max_index=637007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.3876 - accuracy: 0.9060 - top_k_categorical_accuracy: 0.9741 - val_loss: 6.0346 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=365 in 500;  max_index=638307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 0.1560 - accuracy: 0.9605 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.7717 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=366 in 500;  max_index=639607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 1.1350 - accuracy: 0.7696 - top_k_categorical_accuracy: 0.9232 - val_loss: 5.0898 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=367 in 500;  max_index=640907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 282s 4s/step - loss: 0.2407 - accuracy: 0.9511 - top_k_categorical_accuracy: 0.9839 - val_loss: 2.3475 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=368 in 500;  max_index=642207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 280s 4s/step - loss: 0.7916 - accuracy: 0.8353 - top_k_categorical_accuracy: 0.9426 - val_loss: 3.0736 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=369 in 500;  max_index=643507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 284s 4s/step - loss: 0.7401 - accuracy: 0.8339 - top_k_categorical_accuracy: 0.9315 - val_loss: 4.4492 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=370 in 500;  max_index=644807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 272s 4s/step - loss: 0.2410 - accuracy: 0.9335 - top_k_categorical_accuracy: 0.9973 - val_loss: 0.2167 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=371 in 500;  max_index=646107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 257s 4s/step - loss: 0.3738 - accuracy: 0.9123 - top_k_categorical_accuracy: 0.9848 - val_loss: 0.6568 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=372 in 500;  max_index=647407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 276s 4s/step - loss: 1.2274 - accuracy: 0.7455 - top_k_categorical_accuracy: 0.8991 - val_loss: 4.5051 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=373 in 500;  max_index=648707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 271s 4s/step - loss: 0.0131 - accuracy: 0.9982 - top_k_categorical_accuracy: 0.9998 - val_loss: 1.1452 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=374 in 500;  max_index=650007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 273s 4s/step - loss: 0.5626 - accuracy: 0.8658 - top_k_categorical_accuracy: 0.9859 - val_loss: 2.0405 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=375 in 500;  max_index=651307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 273s 4s/step - loss: 0.2693 - accuracy: 0.9335 - top_k_categorical_accuracy: 0.9911 - val_loss: 1.9308 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=376 in 500;  max_index=652607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 260s 4s/step - loss: 0.3777 - accuracy: 0.9194 - top_k_categorical_accuracy: 0.9812 - val_loss: 0.0508 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=377 in 500;  max_index=653907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 2.4463 - accuracy: 0.5609 - top_k_categorical_accuracy: 0.6931 - val_loss: 2.8716 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=378 in 500;  max_index=655207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 260s 4s/step - loss: 0.1905 - accuracy: 0.9538 - top_k_categorical_accuracy: 0.9864 - val_loss: 0.7435 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=379 in 500;  max_index=656507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.3193 - accuracy: 0.9268 - top_k_categorical_accuracy: 0.9926 - val_loss: 6.7624 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=380 in 500;  max_index=657807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 4.1359e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=381 in 500;  max_index=659107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.6574 - accuracy: 0.8924 - top_k_categorical_accuracy: 0.9904 - val_loss: 0.9639 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=382 in 500;  max_index=660407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 260s 4s/step - loss: 1.0148 - accuracy: 0.8123 - top_k_categorical_accuracy: 0.9132 - val_loss: 4.9236 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=383 in 500;  max_index=661707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 239s 3s/step - loss: 0.6502 - accuracy: 0.8931 - top_k_categorical_accuracy: 0.9455 - val_loss: 0.5928 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=384 in 500;  max_index=663007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.3118 - accuracy: 0.9312 - top_k_categorical_accuracy: 0.9781 - val_loss: 3.1434 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=385 in 500;  max_index=664307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 247s 4s/step - loss: 0.0096 - accuracy: 0.9975 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=386 in 500;  max_index=665607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.9275 - accuracy: 0.8435 - top_k_categorical_accuracy: 0.9621 - val_loss: 5.4227 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=387 in 500;  max_index=666907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 0.3371 - accuracy: 0.9094 - top_k_categorical_accuracy: 0.9897 - val_loss: 1.0000 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=388 in 500;  max_index=668207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 237s 3s/step - loss: 0.2612 - accuracy: 0.9402 - top_k_categorical_accuracy: 0.9971 - val_loss: 2.4007 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=389 in 500;  max_index=669507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 240s 3s/step - loss: 1.6336 - accuracy: 0.6962 - top_k_categorical_accuracy: 0.8348 - val_loss: 4.1296 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=390 in 500;  max_index=670807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.3096 - accuracy: 0.9250 - top_k_categorical_accuracy: 0.9817 - val_loss: 0.4452 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=391 in 500;  max_index=672107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 251s 4s/step - loss: 0.4080 - accuracy: 0.9152 - top_k_categorical_accuracy: 0.9855 - val_loss: 3.0319 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=392 in 500;  max_index=673407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 234s 3s/step - loss: 0.1209 - accuracy: 0.9665 - top_k_categorical_accuracy: 0.9993 - val_loss: 1.9518 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=393 in 500;  max_index=674707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 244s 3s/step - loss: 0.4278 - accuracy: 0.9161 - top_k_categorical_accuracy: 0.9897 - val_loss: 2.8637 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=394 in 500;  max_index=676007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 269s 4s/step - loss: 0.6928 - accuracy: 0.8627 - top_k_categorical_accuracy: 0.9636 - val_loss: 1.7269 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=395 in 500;  max_index=677307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 261s 4s/step - loss: 0.2061 - accuracy: 0.9440 - top_k_categorical_accuracy: 0.9955 - val_loss: 0.1146 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=396 in 500;  max_index=678607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.2282 - accuracy: 0.9449 - top_k_categorical_accuracy: 0.9955 - val_loss: 0.3130 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=397 in 500;  max_index=679907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 260s 4s/step - loss: 1.7591 - accuracy: 0.6842 - top_k_categorical_accuracy: 0.8025 - val_loss: 5.8799 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=398 in 500;  max_index=681207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.0197 - accuracy: 0.9953 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=399 in 500;  max_index=682507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 248s 4s/step - loss: 0.2830 - accuracy: 0.9364 - top_k_categorical_accuracy: 0.9962 - val_loss: 7.2021 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=400 in 500;  max_index=683807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.0279 - accuracy: 0.9902 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3376 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0.0, 0.0, 0.9825893, 0.99754465, 0.8564732, 0.7959821, 0.8779018, 0.9238839, 0.9859375, 0.87098217, 0.76316965, 0.9794643, 0.90267855, 0.9529018, 0.8933036, 0.99151784, 0.7511161, 0.7254464, 0.90089285, 0.7517857, 0.8995536, 0.94977677, 0.7705357, 0.99866074, 0.81696427, 0.8986607, 0.90982145, 0.91026783, 0.8620536, 0.82254463, 0.91183037, 0.9216518, 0.9, 0.83839285, 0.959375, 0.9207589, 0.95848215, 0.9948661, 0.84732145, 0.91339284, 0.71875, 0.8953125, 0.928125, 0.9363839, 0.94977677, 0.7526786, 0.9783482, 0.99754465, 0.9227679, 0.9783482, 0.84419644, 0.86183035, 0.8904018, 0.93683034, 0.9522321, 0.87254465, 0.9560268, 0.8194196, 0.8879464, 0.7296875, 0.9089286, 0.8020089, 0.8908482, 0.9479911, 0.72209823, 0.8584821, 0.9171875, 0.7988839, 0.9580357, 0.8388393, 0.9609375, 0.9991071, 0.9013393, 0.9171875, 0.9080357, 0.94977677, 0.9676339, 0.89977676, 0.97299105, 1.0, 0.73683035, 0.91941965, 0.93370533, 0.9042411, 0.92544645, 0.89285713, 0.92232144, 0.92723215, 0.93214285, 0.95, 0.9870536, 0.915625, 0.99620533, 0.9169643, 0.8973214, 0.93705356, 0.9607143, 0.77879465, 0.86316967, 0.96339285, 0.9738839, 0.98080355, 0.89017856, 0.96227676, 0.9660714, 0.88660717, 0.92834824, 0.9542411, 0.9747768, 0.99776787, 0.99263394, 0.9220982, 0.778125, 0.89709824, 0.9247768, 0.96428573, 0.99665177, 0.828125, 0.9404018, 0.96316963, 0.8296875, 0.9345982, 0.8830357, 0.95714283, 0.87098217, 0.86763394, 0.95178574, 0.9988839, 0.9685268, 0.93816966, 0.9948661, 0.9901786, 1.0, 0.9511161, 1.0, 0.9919643, 0.9754464, 0.8819196, 0.91808033, 0.8377232, 0.9892857, 0.9372768, 0.70647323, 0.9930804, 0.9051339, 0.8747768, 0.9660714, 0.94888395, 0.878125, 0.9629464, 0.8125, 0.9618304, 0.8966518, 0.978125, 0.99776787, 0.99933034, 0.8779018, 0.90290177, 0.96316963, 0.74598217, 0.8984375, 0.9267857, 0.9296875, 0.8848214, 0.9314732, 0.8098214, 0.89598215, 0.99375, 0.90625, 0.91964287, 1.0, 0.91450894, 0.8767857, 0.97410715, 0.9598214, 0.96830356, 0.97299105, 0.8375, 0.9676339, 0.9279018, 0.79933035, 0.96540177, 0.89464283, 0.9383929, 0.9042411, 0.75133926, 0.9484375, 0.82366073, 0.94910717, 0.996875, 0.9345982, 0.8995536, 0.81316966, 0.9736607, 0.9160714, 0.9245536, 0.9834821, 0.68995535, 0.81674105, 0.84129465, 0.9558036, 0.92410713, 0.92745537, 0.98370534, 0.8453125, 0.95357144, 0.8457589, 0.9625, 0.78683037, 0.93616074, 0.77120537, 0.9861607, 0.96316963, 0.7214286, 0.9109375, 0.91004467, 0.9002232, 0.9513393, 0.92522323, 0.8875, 0.9462054, 0.98683035, 0.8029018, 0.9484375, 0.87120533, 0.9533482, 0.8254464, 0.97232145, 0.975, 0.9904018, 0.93392855, 0.86160713, 0.87120533, 0.71049106, 0.94174105, 0.96495533, 0.90223217, 0.95245534, 0.9589286, 0.7752232, 0.9546875, 0.94196427, 0.9745536, 0.93526787, 0.9091518, 0.84933037, 0.934375, 0.76316965, 0.9890625, 0.93370533, 0.93035716, 0.7491071, 0.88660717, 0.99955356, 0.8220982, 0.88526785, 0.9678571, 0.9979911, 0.9462054, 0.965625, 0.9609375, 0.940625, 0.93348217, 0.95625, 0.95647323, 0.9832589, 0.96450895, 0.92924106, 0.6950893, 0.965625, 0.9546875, 0.81964284, 0.7948661, 0.9366071, 0.9071429, 0.9160714, 0.96808034, 0.9265625, 0.9950893, 0.75915176, 0.90491074, 0.78125, 0.99151784, 0.98839283, 0.93102676, 0.99352676, 0.9714286, 0.82098216, 0.92633927, 0.86651784, 0.7995536, 0.9984375, 0.84330356, 0.95647323, 0.93370533, 0.77767855, 0.95625, 0.9578125, 0.92053574, 0.85870534, 0.9991071, 0.92901784, 0.93035716, 0.8875, 0.99955356, 0.9113839, 0.8046875, 0.95870537, 0.8113839, 0.9209821, 0.93214285, 0.8839286, 0.9941964, 0.91941965, 0.8055804, 0.93348217, 0.9171875, 0.7354911, 0.95267856, 0.9357143, 0.9979911, 0.8953125, 0.953125, 0.9716518, 0.88995534, 0.93035716, 0.95959824, 0.94933033, 0.98392856, 0.8109375, 0.91183037, 0.93370533, 0.9589286, 0.9591518, 0.80803573, 0.99866074, 0.9091518, 0.9395089, 0.7390625, 0.90223217, 0.94196427, 0.9080357, 0.94129467, 0.975, 0.9609375, 0.87455356, 0.9546875, 0.9636161, 0.5703125, 0.98191965, 0.8770089, 0.996875, 0.81808037, 0.9618304, 0.92611605, 0.91160715, 0.92544645, 0.93415177, 0.48660713, 0.946875, 0.9997768, 0.9238839, 0.9705357, 0.9325893, 0.9267857, 0.7292411, 0.9060268, 0.96049106, 0.76964283, 0.9511161, 0.83526784, 0.8339286, 0.93348217, 0.9122768, 0.74553573, 0.9982143, 0.86584824, 0.93348217, 0.91941965, 0.5609375, 0.95379466, 0.9267857, 1.0, 0.8924107, 0.8122768, 0.89308035, 0.93125, 0.99754465, 0.8435268, 0.909375, 0.9401786, 0.6962054, 0.925, 0.9151786, 0.96651787, 0.9160714, 0.86272323, 0.94397324, 0.94486606, 0.68415177, 0.9953125, 0.9363839, 0.9901786]\n",
      "[0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.9997768, 1.0, 0.9473214, 0.9375, 0.94575894, 0.9950893, 0.99933034, 0.97723216, 0.8779018, 0.9979911, 0.9738839, 0.98683035, 0.965625, 1.0, 0.8986607, 0.86473215, 0.95691967, 0.84754467, 0.9904018, 0.98303574, 0.88147324, 1.0, 0.9502232, 0.9618304, 0.9765625, 0.9640625, 0.95066965, 0.9160714, 0.99776787, 0.98995537, 0.94888395, 0.91651785, 0.9941964, 0.9745536, 0.9912946, 1.0, 0.95066965, 0.9747768, 0.8671875, 0.9549107, 0.98035717, 0.97589284, 0.9984375, 0.8611607, 0.9991071, 1.0, 0.99575895, 0.99955356, 0.95848215, 0.97098213, 0.97522324, 0.9982143, 0.99955356, 0.9763393, 0.99754465, 0.89799106, 0.98772323, 0.88638395, 0.95535713, 0.91540176, 0.9607143, 0.9854911, 0.88035715, 0.93035716, 0.9600446, 0.92834824, 0.98861605, 0.9676339, 0.9982143, 1.0, 0.99955356, 0.9785714, 0.9714286, 0.9912946, 0.9997768, 0.9904018, 0.99866074, 1.0, 0.8689732, 0.9734375, 0.9921875, 0.97522324, 0.97254467, 0.9435268, 0.9578125, 0.98125, 0.9765625, 0.984375, 1.0, 0.9841518, 1.0, 0.97589284, 0.97723216, 0.96919644, 0.99575895, 0.86272323, 0.9424107, 0.99642855, 1.0, 1.0, 0.9933036, 0.9979911, 1.0, 0.97901785, 0.98794645, 0.9939732, 0.99866074, 1.0, 1.0, 0.99620533, 0.8654018, 0.94888395, 0.9792411, 0.99933034, 1.0, 0.92321426, 0.9901786, 0.9973214, 0.91763395, 0.98058033, 0.9705357, 0.9979911, 0.96428573, 0.9716518, 0.9776786, 1.0, 0.9982143, 0.9997768, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997768, 0.9912946, 0.990625, 0.94486606, 0.9997768, 0.98772323, 0.86674106, 1.0, 0.971875, 0.93705356, 0.9950893, 0.99776787, 0.9455357, 0.98995537, 0.9151786, 0.9997768, 0.9607143, 0.99642855, 0.9997768, 1.0, 0.9522321, 0.97901785, 0.9997768, 0.8904018, 0.9832589, 0.96941966, 0.98125, 0.94575894, 0.9796875, 0.89441967, 0.9558036, 0.9979911, 0.9984375, 0.9620536, 1.0, 0.975, 0.95089287, 0.9988839, 0.99642855, 1.0, 0.99933034, 0.97321427, 0.99754465, 0.9970982, 0.9198661, 0.99441963, 0.95625, 0.9852679, 0.9859375, 0.8776786, 0.9953125, 0.934375, 0.9845982, 1.0, 0.99285716, 0.95691967, 0.93013394, 0.9973214, 0.98013395, 0.9910714, 1.0, 0.8457589, 0.91785717, 0.91785717, 0.99933034, 0.9982143, 0.97589284, 0.99955356, 0.93816966, 0.984375, 0.91763395, 0.98392856, 0.89375, 0.98303574, 0.85625, 0.99598217, 0.99598217, 0.8299107, 0.9669643, 0.96540177, 0.9540179, 0.98861605, 0.97991073, 0.9823661, 0.99553573, 1.0, 0.95736605, 0.9982143, 0.9560268, 0.98816967, 0.9421875, 0.99441963, 0.99866074, 0.9982143, 1.0, 0.96830356, 0.95647323, 0.81294644, 0.9814732, 0.99464285, 0.9823661, 0.9939732, 0.984375, 0.8691964, 0.9823661, 0.98839283, 0.9997768, 0.99955356, 0.9901786, 0.94754463, 0.9895089, 0.88839287, 0.9979911, 0.98504466, 0.99575895, 0.8591518, 0.98080355, 1.0, 0.91450894, 0.94308037, 0.9933036, 1.0, 0.99620533, 0.99866074, 0.996875, 0.9912946, 0.97700894, 0.996875, 0.99866074, 0.99933034, 0.9997768, 0.996875, 0.83348215, 0.9941964, 0.984375, 0.9345982, 0.91473216, 0.9941964, 0.98660713, 0.9667411, 0.9948661, 0.9924107, 1.0, 0.8654018, 0.9845982, 0.8770089, 0.99866074, 0.9973214, 0.99553573, 0.9997768, 1.0, 0.94933033, 0.9814732, 0.9479911, 0.91160715, 1.0, 0.96830356, 0.99955356, 0.9910714, 0.9279018, 0.9948661, 0.9997768, 0.99665177, 0.92433035, 1.0, 0.9970982, 0.9930804, 0.996875, 1.0, 0.99151784, 0.9832589, 0.99933034, 0.9035714, 0.9816964, 0.9970982, 0.98013395, 1.0, 0.996875, 0.9015625, 0.99151784, 0.9948661, 0.82477677, 0.99464285, 0.99084824, 1.0, 0.99866074, 0.99754465, 0.9984375, 0.996875, 0.99263394, 1.0, 0.99866074, 1.0, 0.91741073, 0.9745536, 0.9988839, 0.99955356, 1.0, 0.9515625, 1.0, 0.99263394, 0.99955356, 0.86316967, 0.9638393, 0.97879463, 0.9997768, 0.98995537, 0.99955356, 0.996875, 0.996875, 1.0, 1.0, 0.696875, 0.9984375, 0.9796875, 1.0, 0.98772323, 0.9997768, 0.99553573, 0.99441963, 0.9863839, 0.99575895, 0.7359375, 0.98571426, 1.0, 0.9988839, 1.0, 0.99665177, 1.0, 0.86964285, 0.97410715, 0.9997768, 0.92321426, 0.98392856, 0.9426339, 0.9314732, 0.9973214, 0.98482144, 0.89910716, 0.9997768, 0.9859375, 0.9910714, 0.98125, 0.69308037, 0.9863839, 0.99263394, 1.0, 0.9904018, 0.9131696, 0.9455357, 0.978125, 1.0, 0.9620536, 0.98973215, 0.9970982, 0.8348214, 0.9816964, 0.9854911, 0.99933034, 0.98973215, 0.9636161, 0.99553573, 0.99553573, 0.80245537, 1.0, 0.99620533, 1.0]\n",
      "i_s=401 in 500;  max_index=685107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.9675 - accuracy: 0.7835 - top_k_categorical_accuracy: 0.9931 - val_loss: 2.4810 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=402 in 500;  max_index=686407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.1338 - accuracy: 0.9632 - top_k_categorical_accuracy: 0.9973 - val_loss: 1.7022 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=403 in 500;  max_index=687707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 0.1497 - accuracy: 0.9614 - top_k_categorical_accuracy: 0.9989 - val_loss: 1.9178 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=404 in 500;  max_index=689007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.5231 - accuracy: 0.8967 - top_k_categorical_accuracy: 0.9868 - val_loss: 3.9235 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=405 in 500;  max_index=690307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.1305 - accuracy: 0.9623 - top_k_categorical_accuracy: 0.9996 - val_loss: 5.2837 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=406 in 500;  max_index=691607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 243s 3s/step - loss: 0.9335 - accuracy: 0.8179 - top_k_categorical_accuracy: 0.9217 - val_loss: 5.9290 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=407 in 500;  max_index=692907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 284s 4s/step - loss: 0.3869 - accuracy: 0.9025 - top_k_categorical_accuracy: 0.9929 - val_loss: 1.6319 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=408 in 500;  max_index=694207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 254s 4s/step - loss: 0.2499 - accuracy: 0.9391 - top_k_categorical_accuracy: 0.9975 - val_loss: 0.0503 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=409 in 500;  max_index=695507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 249s 4s/step - loss: 0.6483 - accuracy: 0.8737 - top_k_categorical_accuracy: 0.9538 - val_loss: 7.2559 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=410 in 500;  max_index=696807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.1648 - accuracy: 0.9529 - top_k_categorical_accuracy: 0.9962 - val_loss: 0.2113 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=411 in 500;  max_index=698107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 0.1756 - accuracy: 0.9641 - top_k_categorical_accuracy: 0.9980 - val_loss: 2.3695 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=412 in 500;  max_index=699407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.1147 - accuracy: 0.9739 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=413 in 500;  max_index=700707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 267s 4s/step - loss: 0.1615 - accuracy: 0.9565 - top_k_categorical_accuracy: 0.9993 - val_loss: 5.2477 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=414 in 500;  max_index=702007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 253s 4s/step - loss: 0.7971 - accuracy: 0.8449 - top_k_categorical_accuracy: 0.9721 - val_loss: 5.0926 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=415 in 500;  max_index=703307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 1.1330 - accuracy: 0.7897 - top_k_categorical_accuracy: 0.8982 - val_loss: 5.8827 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=416 in 500;  max_index=704607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 255s 4s/step - loss: 0.1232 - accuracy: 0.9645 - top_k_categorical_accuracy: 0.9982 - val_loss: 0.8341 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=417 in 500;  max_index=705907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 242s 3s/step - loss: 1.1664 - accuracy: 0.7629 - top_k_categorical_accuracy: 0.9100 - val_loss: 8.5385 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=418 in 500;  max_index=707207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 238s 3s/step - loss: 0.7908 - accuracy: 0.8263 - top_k_categorical_accuracy: 0.9219 - val_loss: 3.1296 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=419 in 500;  max_index=708507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 293s 4s/step - loss: 0.8712 - accuracy: 0.7982 - top_k_categorical_accuracy: 0.9246 - val_loss: 4.9442 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=420 in 500;  max_index=709807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 289s 4s/step - loss: 0.1963 - accuracy: 0.9496 - top_k_categorical_accuracy: 0.9906 - val_loss: 2.5330 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=421 in 500;  max_index=711107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 273s 4s/step - loss: 0.4159 - accuracy: 0.9027 - top_k_categorical_accuracy: 0.9924 - val_loss: 1.8447 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=422 in 500;  max_index=712407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 291s 4s/step - loss: 0.3843 - accuracy: 0.9221 - top_k_categorical_accuracy: 0.9855 - val_loss: 0.2588 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=423 in 500;  max_index=713707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 279s 4s/step - loss: 1.7724 - accuracy: 0.6306 - top_k_categorical_accuracy: 0.8022 - val_loss: 5.9177 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=424 in 500;  max_index=715007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 300s 4s/step - loss: 0.4378 - accuracy: 0.8958 - top_k_categorical_accuracy: 0.9636 - val_loss: 1.4314 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=425 in 500;  max_index=716307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 276s 4s/step - loss: 0.4306 - accuracy: 0.8949 - top_k_categorical_accuracy: 0.9799 - val_loss: 7.0983 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=426 in 500;  max_index=717607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 276s 4s/step - loss: 0.4625 - accuracy: 0.8993 - top_k_categorical_accuracy: 0.9750 - val_loss: 3.9737 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=427 in 500;  max_index=718907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 265s 4s/step - loss: 0.1015 - accuracy: 0.9696 - top_k_categorical_accuracy: 0.9998 - val_loss: 0.1495 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=428 in 500;  max_index=720207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 268s 4s/step - loss: 0.3410 - accuracy: 0.9150 - top_k_categorical_accuracy: 0.9920 - val_loss: 2.7882 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=429 in 500;  max_index=721507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 263s 4s/step - loss: 0.6933 - accuracy: 0.8721 - top_k_categorical_accuracy: 0.9464 - val_loss: 6.5242 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=430 in 500;  max_index=722807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 269s 4s/step - loss: 0.0403 - accuracy: 0.9891 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7201 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=431 in 500;  max_index=724107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 264s 4s/step - loss: 0.5683 - accuracy: 0.8723 - top_k_categorical_accuracy: 0.9984 - val_loss: 1.5294 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=432 in 500;  max_index=725407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 300s 4s/step - loss: 0.0104 - accuracy: 0.9958 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=433 in 500;  max_index=726707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 281s 4s/step - loss: 0.4773 - accuracy: 0.9174 - top_k_categorical_accuracy: 0.9929 - val_loss: 2.1996 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=434 in 500;  max_index=728007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 270s 4s/step - loss: 0.0586 - accuracy: 0.9846 - top_k_categorical_accuracy: 0.9996 - val_loss: 0.9049 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=435 in 500;  max_index=729307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 279s 4s/step - loss: 6.0946e-05 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=436 in 500;  max_index=730607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 246s 4s/step - loss: 0.0022 - accuracy: 0.9996 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=437 in 500;  max_index=731907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 250s 4s/step - loss: 2.6077e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=438 in 500;  max_index=733207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 256s 4s/step - loss: 0.8812 - accuracy: 0.8540 - top_k_categorical_accuracy: 0.9783 - val_loss: 6.5169 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=439 in 500;  max_index=734507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 268s 4s/step - loss: 0.4974 - accuracy: 0.8958 - top_k_categorical_accuracy: 0.9982 - val_loss: 1.7495 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=440 in 500;  max_index=735807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 306s 4s/step - loss: 0.0606 - accuracy: 0.9848 - top_k_categorical_accuracy: 0.9996 - val_loss: 3.3621 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=441 in 500;  max_index=737107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 292s 4s/step - loss: 0.1108 - accuracy: 0.9752 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8019 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=442 in 500;  max_index=738407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 328s 5s/step - loss: 0.1299 - accuracy: 0.9703 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=443 in 500;  max_index=739707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 342s 5s/step - loss: 0.7072 - accuracy: 0.8638 - top_k_categorical_accuracy: 0.9728 - val_loss: 4.3058 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=444 in 500;  max_index=741007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 316s 5s/step - loss: 0.0385 - accuracy: 0.9904 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=445 in 500;  max_index=742307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 289s 4s/step - loss: 0.1032 - accuracy: 0.9719 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.1464 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=446 in 500;  max_index=743607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 304s 4s/step - loss: 1.2677 - accuracy: 0.7571 - top_k_categorical_accuracy: 0.9078 - val_loss: 6.5134 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=447 in 500;  max_index=744907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 342s 5s/step - loss: 0.2939 - accuracy: 0.9335 - top_k_categorical_accuracy: 0.9862 - val_loss: 0.0063 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=448 in 500;  max_index=746207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 292s 4s/step - loss: 0.8966 - accuracy: 0.8306 - top_k_categorical_accuracy: 0.9842 - val_loss: 8.2758 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=449 in 500;  max_index=747507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 283s 4s/step - loss: 1.9777 - accuracy: 0.6266 - top_k_categorical_accuracy: 0.7942 - val_loss: 6.8838 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=450 in 500;  max_index=748807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 309s 4s/step - loss: 0.2453 - accuracy: 0.9391 - top_k_categorical_accuracy: 0.9850 - val_loss: 0.0372 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=451 in 500;  max_index=750107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 293s 4s/step - loss: 0.0026 - accuracy: 0.9996 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=452 in 500;  max_index=751407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 288s 4s/step - loss: 0.7749 - accuracy: 0.8801 - top_k_categorical_accuracy: 0.9690 - val_loss: 1.2245 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=453 in 500;  max_index=752707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 311s 4s/step - loss: 1.2117 - accuracy: 0.7464 - top_k_categorical_accuracy: 0.9098 - val_loss: 5.6649 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=454 in 500;  max_index=754007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 290s 4s/step - loss: 0.1055 - accuracy: 0.9692 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.4225 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=455 in 500;  max_index=755307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 310s 4s/step - loss: 3.3525 - accuracy: 0.4714 - top_k_categorical_accuracy: 0.5893 - val_loss: 8.5026 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=456 in 500;  max_index=756607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 296s 4s/step - loss: 1.4393 - accuracy: 0.6306 - top_k_categorical_accuracy: 0.8346 - val_loss: 7.3189 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=457 in 500;  max_index=757907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 306s 4s/step - loss: 0.3632 - accuracy: 0.9074 - top_k_categorical_accuracy: 0.9824 - val_loss: 1.3739 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=458 in 500;  max_index=759207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 282s 4s/step - loss: 1.0304 - accuracy: 0.7690 - top_k_categorical_accuracy: 0.9007 - val_loss: 6.9395 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=459 in 500;  max_index=760507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 319s 5s/step - loss: 0.0793 - accuracy: 0.9786 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4902 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=460 in 500;  max_index=761807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 296s 4s/step - loss: 0.4606 - accuracy: 0.9268 - top_k_categorical_accuracy: 0.9750 - val_loss: 0.0512 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=461 in 500;  max_index=763107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 281s 4s/step - loss: 0.5296 - accuracy: 0.8690 - top_k_categorical_accuracy: 0.9949 - val_loss: 0.8716 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=462 in 500;  max_index=764407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 293s 4s/step - loss: 0.4604 - accuracy: 0.8853 - top_k_categorical_accuracy: 0.9953 - val_loss: 1.7717 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=463 in 500;  max_index=765707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 280s 4s/step - loss: 1.8003 - accuracy: 0.6467 - top_k_categorical_accuracy: 0.8346 - val_loss: 4.0207 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=464 in 500;  max_index=767007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 301s 4s/step - loss: 1.8738 - accuracy: 0.6080 - top_k_categorical_accuracy: 0.7592 - val_loss: 8.0299 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=465 in 500;  max_index=768307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 286s 4s/step - loss: 0.9846 - accuracy: 0.7897 - top_k_categorical_accuracy: 0.8951 - val_loss: 4.4041 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=466 in 500;  max_index=769607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 314s 4s/step - loss: 0.2133 - accuracy: 0.9357 - top_k_categorical_accuracy: 0.9953 - val_loss: 0.0807 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=467 in 500;  max_index=770907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 299s 4s/step - loss: 0.0051 - accuracy: 0.9987 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=468 in 500;  max_index=772207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 282s 4s/step - loss: 0.7734 - accuracy: 0.8643 - top_k_categorical_accuracy: 0.9940 - val_loss: 1.0199 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=469 in 500;  max_index=773507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 298s 4s/step - loss: 0.7096 - accuracy: 0.8225 - top_k_categorical_accuracy: 0.9348 - val_loss: 6.2962 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=470 in 500;  max_index=774807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 300s 4s/step - loss: 0.7135 - accuracy: 0.8509 - top_k_categorical_accuracy: 0.9422 - val_loss: 2.6899 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=471 in 500;  max_index=776107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 329s 5s/step - loss: 0.4713 - accuracy: 0.8799 - top_k_categorical_accuracy: 0.9781 - val_loss: 2.1417 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=472 in 500;  max_index=777407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 301s 4s/step - loss: 0.7637 - accuracy: 0.8252 - top_k_categorical_accuracy: 0.9308 - val_loss: 5.3905 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=473 in 500;  max_index=778707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 325s 5s/step - loss: 0.2560 - accuracy: 0.9386 - top_k_categorical_accuracy: 0.9953 - val_loss: 0.5633 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=474 in 500;  max_index=780007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 305s 4s/step - loss: 0.7631 - accuracy: 0.8391 - top_k_categorical_accuracy: 0.9208 - val_loss: 5.6422 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=475 in 500;  max_index=781307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 316s 5s/step - loss: 0.1789 - accuracy: 0.9538 - top_k_categorical_accuracy: 0.9929 - val_loss: 1.1900 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=476 in 500;  max_index=782607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 317s 5s/step - loss: 0.2312 - accuracy: 0.9397 - top_k_categorical_accuracy: 0.9886 - val_loss: 4.8718 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=477 in 500;  max_index=783907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 314s 4s/step - loss: 0.5774 - accuracy: 0.8746 - top_k_categorical_accuracy: 0.9598 - val_loss: 7.4049 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=478 in 500;  max_index=785207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 309s 4s/step - loss: 0.1279 - accuracy: 0.9679 - top_k_categorical_accuracy: 0.9964 - val_loss: 1.0947 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=479 in 500;  max_index=786507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 320s 5s/step - loss: 0.0723 - accuracy: 0.9810 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.8252 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=480 in 500;  max_index=787807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 293s 4s/step - loss: 1.4095 - accuracy: 0.7703 - top_k_categorical_accuracy: 0.9259 - val_loss: 4.8485 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=481 in 500;  max_index=789107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 294s 4s/step - loss: 0.1355 - accuracy: 0.9605 - top_k_categorical_accuracy: 0.9967 - val_loss: 0.0315 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=482 in 500;  max_index=790407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 325s 5s/step - loss: 0.1286 - accuracy: 0.9672 - top_k_categorical_accuracy: 0.9982 - val_loss: 4.1598 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=483 in 500;  max_index=791707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 301s 4s/step - loss: 0.5489 - accuracy: 0.8676 - top_k_categorical_accuracy: 0.9886 - val_loss: 3.2893 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=484 in 500;  max_index=793007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 311s 4s/step - loss: 0.3723 - accuracy: 0.9125 - top_k_categorical_accuracy: 0.9717 - val_loss: 5.0867 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=485 in 500;  max_index=794307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 315s 5s/step - loss: 1.8623 - accuracy: 0.6252 - top_k_categorical_accuracy: 0.8085 - val_loss: 7.3186 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=486 in 500;  max_index=795607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 318s 5s/step - loss: 0.0968 - accuracy: 0.9717 - top_k_categorical_accuracy: 0.9993 - val_loss: 1.7945 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=487 in 500;  max_index=796907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 281s 4s/step - loss: 0.2028 - accuracy: 0.9424 - top_k_categorical_accuracy: 0.9987 - val_loss: 2.4475 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=488 in 500;  max_index=798207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 321s 5s/step - loss: 0.6604 - accuracy: 0.8538 - top_k_categorical_accuracy: 0.9730 - val_loss: 1.4415 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=489 in 500;  max_index=799507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 303s 4s/step - loss: 1.9251 - accuracy: 0.5875 - top_k_categorical_accuracy: 0.7513 - val_loss: 6.9564 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=490 in 500;  max_index=800807\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 298s 4s/step - loss: 0.0800 - accuracy: 0.9759 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=491 in 500;  max_index=802107\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 307s 4s/step - loss: 0.7986 - accuracy: 0.8123 - top_k_categorical_accuracy: 0.9346 - val_loss: 3.4016 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=492 in 500;  max_index=803407\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 311s 4s/step - loss: 0.0576 - accuracy: 0.9812 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.3874 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=493 in 500;  max_index=804707\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 286s 4s/step - loss: 0.4049 - accuracy: 0.8819 - top_k_categorical_accuracy: 0.9982 - val_loss: 3.7220 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=494 in 500;  max_index=806007\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 301s 4s/step - loss: 0.0173 - accuracy: 0.9951 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=495 in 500;  max_index=807307\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 299s 4s/step - loss: 5.4296e-05 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=496 in 500;  max_index=808607\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 332s 5s/step - loss: 1.0170 - accuracy: 0.8504 - top_k_categorical_accuracy: 0.9652 - val_loss: 2.0093 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=497 in 500;  max_index=809907\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 293s 4s/step - loss: 1.3167 - accuracy: 0.7254 - top_k_categorical_accuracy: 0.9310 - val_loss: 4.6974 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=498 in 500;  max_index=811207\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 304s 4s/step - loss: 0.0197 - accuracy: 0.9951 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=499 in 500;  max_index=812507\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 305s 4s/step - loss: 0.0059 - accuracy: 0.9984 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.9031214276552201\n",
      "0.298\n",
      "0.9679165189266205\n"
     ]
    }
   ],
   "source": [
    "print('-----------------Start the loop training!!---------------------')\n",
    "\n",
    "RNNmodel=load_model('jjs_model_0204LSTMV1.h5')\n",
    "ACC=[0.0,0.0]\n",
    "val_ACC=[0.0,0.0]\n",
    "val_TopACC=[0.0,0.0]\n",
    "for i_s in range(N_Split):\n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    print('i_s='+str(i_s)+ ' in '+ str(N_Split) +';  max_index='+str(N_Train_OverSampler+(i_s+1)*BlockSize+1))\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    #history = RNNmodel.fit_generator(train_generator,steps_per_epoch=1,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=(N_Val_OverSampler - lookback) // N_BATCH)\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=70,epochs=1,verbose=1,validation_data=val_generator,validation_steps=1)\n",
    "    ACC.extend(history.history['accuracy'])\n",
    "    val_ACC.extend(history.history['val_accuracy'])\n",
    "    val_TopACC.extend(history.history['top_k_categorical_accuracy'])#\n",
    "    if i_s%100==0:\n",
    "        print(ACC)\n",
    "        print(val_ACC)\n",
    "        print(val_TopACC)\n",
    "RNNmodel.save('jjs_model_0204LSTMV3.h5')        \n",
    "print(val_ACC)\n",
    "NP_ACC=np.array(ACC)\n",
    "print(np.sum(NP_ACC)/500)\n",
    "NP_val_ACC=np.array(val_ACC)\n",
    "print(np.sum(NP_val_ACC)/500)\n",
    "NP_val_ACCTop5=np.array(val_TopACC)\n",
    "print(np.sum(NP_val_ACCTop5)/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
