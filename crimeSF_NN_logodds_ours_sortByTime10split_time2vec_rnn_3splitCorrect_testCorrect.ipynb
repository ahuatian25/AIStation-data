{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras import layers,metrics\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU, ELU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.utils import shuffle as reset\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "# import \n",
    "from matplotlib.pylab import plt\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler #https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.RandomOverSampler.html?highlight=randomoversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_DataFrame(data, test_size=0.2, considerTime=True, random_state=None):\n",
    "    # ConsiderTime-------trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "    if considerTime:\n",
    "        data=data.sort_values(by=\"Dates\", ascending=True)\n",
    "    else:\n",
    "        data=reset(data, random_state=random_state)\n",
    "    train=data[int(len(data)*test_size):].reset_index(drop=True)\n",
    "    test=data[:int(len(data)*test_size)].reset_index(drop=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj    \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "def Dates2TDMY(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj  \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    #T_D_M_Y=str(time)+str(day)+str(month)+str(year)\n",
    "    T_D_M_Y=str(time)+str(day)+str(month)\n",
    "    return T_D_M_Y\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field2Vec(trainDF,testDF,fieldStr):\n",
    "    fields=sorted(trainDF[fieldStr].unique())\n",
    "    categories=sorted(trainDF[\"Category\"].unique())\n",
    "    C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "    F_C_counts=trainDF.groupby([fieldStr,\"Category\"]).size()\n",
    "    F_counts=trainDF.groupby([fieldStr]).size()\n",
    "    logodds={}\n",
    "    logoddsPF={}\n",
    "    MIN_CAT_COUNTS=2\n",
    "    default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "    for f in fields:\n",
    "        PA=F_counts[f]/float(len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "        logodds[f]=deepcopy(default_logodds)\n",
    "        for cat in F_C_counts[f].keys():\n",
    "            if (F_C_counts[f][cat]>MIN_CAT_COUNTS) and F_C_counts[f][cat]<F_counts[f]:\n",
    "                PA=F_C_counts[f][cat]/float(F_counts[f])\n",
    "                logodds[f][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "        logodds[f]=pd.Series(logodds[f])\n",
    "        logodds[f].index=range(len(categories))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #fieldsTest=sorted(testDF[fieldStr].unique())\n",
    "    #N_count=0\n",
    "    #for f in fieldsTest:\n",
    "        #if f not in fields:\n",
    "            #logoddsPF[f]=-50.0  #np.log(0.)-np.log(1.)=-inf,便于计算，改为-99999.0\n",
    "            #logodds[f]=deepcopy(default_logodds)\n",
    "            #pa=1.0/float(len(categories))\n",
    "            #logodds[f][range(len(categories))]=np.log(pa)-np.log(1.0-pa)\n",
    "            #logodds[f]=pd.Series(logodds[f])\n",
    "            #logodds[f].index=range(len(categories))\n",
    "            #N_count=N_count+1\n",
    "    #print(fieldStr+' N_count: '+str(N_count))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #引进代码原作者的新思想\n",
    "    new_fields=sorted(testDF[fieldStr].unique())\n",
    "    new_F_counts=testDF.groupby(fieldStr).size()\n",
    "    only_new=set(new_fields+fields)-set(fields)\n",
    "    only_old=set(new_fields+fields)-set(new_fields)\n",
    "    in_both=set(new_fields).intersection(fields)\n",
    "    print('# only_new_fieldds:'+str(len(only_new)))\n",
    "    for f in only_new:\n",
    "        PA=new_F_counts[f]/float(len(testDF)+len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "        logodds[f]=deepcopy(default_logodds)\n",
    "        logodds[f].index=range(len(categories))\n",
    "    for f in in_both:\n",
    "        PA=(F_counts[f]+new_F_counts[f])/float(len(testDF)+len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)    \n",
    "    return logodds,logoddsPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(df,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print(\"Creating address features\")###Creating address features###\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds_A[x])\n",
    "    address_features.columns=[\"logodds_A\"+str(x) for x in range(len(address_features.columns))]\n",
    "    print(\"Creating time T_D_M_Y features\")###Creating time T_D_M_Y features###\n",
    "    T_D_M_Y_features=cleanData[\"T_D_M_Y\"].apply(lambda xx: logodds_T[xx])\n",
    "    T_D_M_Y_features.columns=[\"logodds_T\"+str(xx) for xx in range(len(T_D_M_Y_features.columns))]\n",
    "\n",
    "    print(\"Parsing dates\")            ###Creating address features###\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    #     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    #     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print(\"Creating one-hot variables\")\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPF_A\"]=cleanData[\"Address\"].apply(lambda x: logoddsPF_A[x])\n",
    "    cleanData[\"logoddsPF_T\"]=cleanData[\"T_D_M_Y\"].apply(lambda x: logoddsPF_T[x])\n",
    "    print(\"droping processed columns\")\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)\n",
    "    cleanData=cleanData.drop(\"T_D_M_Y\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print(\"joining one-hot features\")\n",
    "    features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:]).join(T_D_M_Y_features.iloc[:,:])\n",
    "    print(\"creating new features\")\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(keep='last')).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, Y, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(X) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, X.shape[-1]))\n",
    "        targets = np.zeros((len(rows),Y.shape[1]))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = X[indices]\n",
    "            targets[j] = Y[rows[j]+delay]\n",
    "        yield samples, targets\n",
    "    #Now here is the data generator that we will use. It yields a tuple (samples, targets) where samples is one batch of input data and targets is the corresponding array of target temperatures. It takes the following arguments:\n",
    "        # •data: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "        # •lookback: How many timesteps back should our input data go.\n",
    "        # •delay: How many timesteps in the future should our target be.\n",
    "        # •min_index and max_index: Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another one for testing.\n",
    "        # •shuffle: Whether to shuffle our samples or draw them in chronological order.\n",
    "        # •batch_size: The number of samples per batch.\n",
    "        # •step: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of OrginalAllDF: (878049, 9)\n",
      "The shape of AllDF after del wrong X and Y values: (877982, 9)\n",
      "The shape of AllDF after drop_duplicates: (812529, 9)\n",
      "(689038, 2)\n",
      "Address_counts_allDF_trainDF_testDF: 23191_22661_17720\n",
      "The # of AllDF, AllTrain, AllTest, is: 812529,650024,162505\n",
      "-----------LOGOODS: T_D_M_Y-------------\n",
      "# only_new_fieldds:92\n",
      "-----------LOGOODS: Address-------------\n",
      "# only_new_fieldds:530\n",
      "-----------LOGOODS: parse_data of Alltrain  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "-----------LOGOODS: parse_data of Alltest  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n",
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPF_A', 'logoddsPF_T', 'PD_BAYVIEW', 'PD_CENTRAL', 'PD_INGLESIDE', 'PD_MISSION', 'PD_NORTHERN', 'PD_PARK', 'PD_RICHMOND', 'PD_SOUTHERN', 'PD_TARAVAL', 'PD_TENDERLOIN', 'DAY_Friday', 'DAY_Monday', 'DAY_Saturday', 'DAY_Sunday', 'DAY_Thursday', 'DAY_Tuesday', 'DAY_Wednesday', 'logodds_A0', 'logodds_A1', 'logodds_A2', 'logodds_A3', 'logodds_A4', 'logodds_A5', 'logodds_A6', 'logodds_A7', 'logodds_A8', 'logodds_A9', 'logodds_A10', 'logodds_A11', 'logodds_A12', 'logodds_A13', 'logodds_A14', 'logodds_A15', 'logodds_A16', 'logodds_A17', 'logodds_A18', 'logodds_A19', 'logodds_A20', 'logodds_A21', 'logodds_A22', 'logodds_A23', 'logodds_A24', 'logodds_A25', 'logodds_A26', 'logodds_A27', 'logodds_A28', 'logodds_A29', 'logodds_A30', 'logodds_A31', 'logodds_A32', 'logodds_A33', 'logodds_A34', 'logodds_A35', 'logodds_A36', 'logodds_A37', 'logodds_A38', 'logodds_T0', 'logodds_T1', 'logodds_T2', 'logodds_T3', 'logodds_T4', 'logodds_T5', 'logodds_T6', 'logodds_T7', 'logodds_T8', 'logodds_T9', 'logodds_T10', 'logodds_T11', 'logodds_T12', 'logodds_T13', 'logodds_T14', 'logodds_T15', 'logodds_T16', 'logodds_T17', 'logodds_T18', 'logodds_T19', 'logodds_T20', 'logodds_T21', 'logodds_T22', 'logodds_T23', 'logodds_T24', 'logodds_T25', 'logodds_T26', 'logodds_T27', 'logodds_T28', 'logodds_T29', 'logodds_T30', 'logodds_T31', 'logodds_T32', 'logodds_T33', 'logodds_T34', 'logodds_T35', 'logodds_T36', 'logodds_T37', 'logodds_T38', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n",
      "110\n",
      "------------RandomOverSampler--------------\n",
      "Shape of OverSampler of AllTrain: (5386485, 110)\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "ConsiderTime=False# True##trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "Rate_ALL=0.2\n",
    "allDF=pd.read_csv(\"./train_addrCorrect.csv\")\n",
    "print('The shape of OrginalAllDF: '+str(allDF.shape))\n",
    "\n",
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(allDF[[\"X\",\"Y\"]])\n",
    "allDF[[\"X\",\"Y\"]]=xy_scaler.transform(allDF[[\"X\",\"Y\"]])\n",
    "allDF=allDF[abs(allDF[\"Y\"])<100]\n",
    "allDF.index=range(len(allDF))\n",
    "print('The shape of AllDF after del wrong X and Y values: '+str(allDF.shape))\n",
    "\n",
    "def listCat(x):\n",
    "    return list(x)\n",
    "allDF.drop_duplicates(inplace=True,subset=['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Category'])\n",
    "Train_duplicated=pd.pivot_table(allDF,index=['Dates','DayOfWeek','PdDistrict', 'Address', 'X', 'Y'], values='Category',aggfunc=[len,listCat])\n",
    "print('The shape of AllDF after drop_duplicates: '+str(allDF.shape))\n",
    "print(Train_duplicated.shape)\n",
    "\n",
    "trainDF,testDF=train_test_split_DataFrame(allDF, test_size=Rate_ALL, considerTime=ConsiderTime, random_state=None)\n",
    "print('Address_counts_allDF_trainDF_testDF: ' + str(len(allDF[\"Address\"].unique())) + '_'+ str(len(trainDF[\"Address\"].unique())) + '_' + str(len(testDF[\"Address\"].unique())))\n",
    "\n",
    "N_AllSample=allDF.shape[0]\n",
    "N_AllTrain=trainDF.shape[0]\n",
    "N_AllTest=testDF.shape[0]\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "print('The # of AllDF, AllTrain, AllTest, is: '+str(N_AllSample)+','+str(N_AllTrain)+','+str(N_AllTest))\n",
    "#################Now proceed as before#################\n",
    "\n",
    "trainDF[\"T_D_M_Y\"]=trainDF[\"Dates\"].apply(Dates2TDMY)\n",
    "trainDF[\"T_D_M_Y\"]=trainDF[\"T_D_M_Y\"]+trainDF[\"DayOfWeek\"]\n",
    "\n",
    "testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "testDF[\"T_D_M_Y\"]=testDF[\"Dates\"].apply(Dates2TDMY)\n",
    "testDF[\"T_D_M_Y\"]=testDF[\"T_D_M_Y\"]+testDF[\"DayOfWeek\"]\n",
    "\n",
    "print('-----------LOGOODS: T_D_M_Y-------------')\n",
    "logodds_T,logoddsPF_T=field2Vec(trainDF,testDF,\"T_D_M_Y\")\n",
    "print('-----------LOGOODS: Address-------------')\n",
    "logodds_A,logoddsPF_A=field2Vec(trainDF,testDF,\"Address\")\n",
    "print('-----------LOGOODS: parse_data of Alltrain  -------------')\n",
    "features, labels=parse_data(trainDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T) \n",
    "print('-----------LOGOODS: parse_data of Alltest  -------------')\n",
    "features_test, labels_test=parse_data(testDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T)###########和训练集使用同样的时间和地点Logoodds值#####\n",
    "x_test=features_test.values\n",
    "y_test=labels_test.values\n",
    "y_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_test)), num_classes=N_CLASS)\n",
    "\n",
    "print(features.columns.tolist())\n",
    "print(len(features.columns))\n",
    "\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)\n",
    "features_test[collist]=scaler.transform(features_test)###########和训练集使用同样的scaler值#####\n",
    "######################################################\n",
    "#############################先进行过采样，然后再根据时间来排序##################################\n",
    "print('------------RandomOverSampler--------------')\n",
    "ros = RandomOverSampler()\n",
    "featuresArray, labelsArray = ros.fit_resample(features.values,labels.values)#####过采样#####\n",
    "N_AllTrain_OverSampler=int(featuresArray.shape[0])\n",
    "print('Shape of OverSampler of AllTrain: '+str(featuresArray.shape))\n",
    "if ConsiderTime:\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    print('------------Sort--------------')\n",
    "    time_temp=featuresArray[:,2]+np.dot(featuresArray[:,3],100)+np.dot(featuresArray[:,4],10000)+np.dot(featuresArray[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresArray,labelsArray))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    labelsArray=features_label_time[:,-2]\n",
    "    featuresArray=features_label_time[:,0:featuresArray.shape[1]]\n",
    "    del features_label_time\n",
    "    #############################先进行过采样，然后再根据时间来排序----结束############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------RandomOverSampler--------------\n",
      "Shape of OverSampler of AllTest: (1344603, 110)\n"
     ]
    }
   ],
   "source": [
    "print('------------RandomOverSampler--------------')\n",
    "ros = RandomOverSampler()\n",
    "featuresArray_test, labelsArray_test = ros.fit_resample(features_test.values,labels_test.values)#####过采样#####\n",
    "N_AllTest_OverSampler=int(featuresArray_test.shape[0])\n",
    "labelsArray_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArray_test)), num_classes=N_CLASS)\n",
    "print('Shape of OverSampler of AllTest: '+str(featuresArray_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Building DNN model--------------\n",
      "------------DNN Training Go! Go! Go!!!!-----------\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 5359553 samples, validate on 1344603 samples\n",
      "Epoch 1/30\n",
      " - 350s - loss: 1.4129 - accuracy: 0.6055 - top_k_categorical_accuracy: 0.8165 - val_loss: 2201.6299 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      " - 355s - loss: 1.0654 - accuracy: 0.6928 - top_k_categorical_accuracy: 0.8814 - val_loss: 3326.9071 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      " - 355s - loss: 0.9781 - accuracy: 0.7143 - top_k_categorical_accuracy: 0.8968 - val_loss: 2231.1416 - val_accuracy: 0.0259 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      " - 352s - loss: 0.9291 - accuracy: 0.7263 - top_k_categorical_accuracy: 0.9054 - val_loss: 3016.1962 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      " - 356s - loss: 0.8967 - accuracy: 0.7344 - top_k_categorical_accuracy: 0.9115 - val_loss: 3966.9368 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      " - 357s - loss: 0.8722 - accuracy: 0.7405 - top_k_categorical_accuracy: 0.9161 - val_loss: 3587.1602 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      " - 353s - loss: 0.8525 - accuracy: 0.7455 - top_k_categorical_accuracy: 0.9197 - val_loss: 4198.1174 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      " - 349s - loss: 0.8364 - accuracy: 0.7496 - top_k_categorical_accuracy: 0.9226 - val_loss: 4603.0438 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      " - 351s - loss: 0.8230 - accuracy: 0.7532 - top_k_categorical_accuracy: 0.9252 - val_loss: 4085.1187 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      " - 345s - loss: 0.8110 - accuracy: 0.7562 - top_k_categorical_accuracy: 0.9275 - val_loss: 4568.1549 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      " - 352s - loss: 0.8013 - accuracy: 0.7588 - top_k_categorical_accuracy: 0.9292 - val_loss: 4527.6687 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      " - 356s - loss: 0.7921 - accuracy: 0.7610 - top_k_categorical_accuracy: 0.9309 - val_loss: 5089.5876 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      " - 353s - loss: 0.7842 - accuracy: 0.7632 - top_k_categorical_accuracy: 0.9324 - val_loss: 4729.1756 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      " - 355s - loss: 0.7774 - accuracy: 0.7650 - top_k_categorical_accuracy: 0.9337 - val_loss: 4443.5673 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      " - 352s - loss: 0.7710 - accuracy: 0.7667 - top_k_categorical_accuracy: 0.9347 - val_loss: 5155.0840 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      " - 351s - loss: 0.7650 - accuracy: 0.7681 - top_k_categorical_accuracy: 0.9358 - val_loss: 4442.8644 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      " - 353s - loss: 0.7599 - accuracy: 0.7695 - top_k_categorical_accuracy: 0.9368 - val_loss: 4964.4836 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      " - 344s - loss: 0.7551 - accuracy: 0.7707 - top_k_categorical_accuracy: 0.9377 - val_loss: 5354.6910 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      " - 351s - loss: 0.7506 - accuracy: 0.7720 - top_k_categorical_accuracy: 0.9386 - val_loss: 5208.4619 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      " - 347s - loss: 0.7465 - accuracy: 0.7728 - top_k_categorical_accuracy: 0.9393 - val_loss: 5028.6544 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      " - 351s - loss: 0.7423 - accuracy: 0.7741 - top_k_categorical_accuracy: 0.9399 - val_loss: 5553.8553 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      " - 355s - loss: 0.7391 - accuracy: 0.7748 - top_k_categorical_accuracy: 0.9405 - val_loss: 4744.1029 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      " - 355s - loss: 0.7355 - accuracy: 0.7757 - top_k_categorical_accuracy: 0.9411 - val_loss: 4613.5166 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      " - 356s - loss: 0.7323 - accuracy: 0.7767 - top_k_categorical_accuracy: 0.9416 - val_loss: 4950.2895 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      " - 356s - loss: 0.7296 - accuracy: 0.7773 - top_k_categorical_accuracy: 0.9423 - val_loss: 5153.0793 - val_accuracy: 0.0250 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      " - 350s - loss: 0.7265 - accuracy: 0.7781 - top_k_categorical_accuracy: 0.9428 - val_loss: 4994.8735 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      " - 347s - loss: 0.7241 - accuracy: 0.7787 - top_k_categorical_accuracy: 0.9432 - val_loss: 5401.7531 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      " - 346s - loss: 0.7216 - accuracy: 0.7795 - top_k_categorical_accuracy: 0.9436 - val_loss: 5623.9155 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      " - 349s - loss: 0.7192 - accuracy: 0.7801 - top_k_categorical_accuracy: 0.9440 - val_loss: 4829.2990 - val_accuracy: 0.0250 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      " - 347s - loss: 0.7170 - accuracy: 0.7805 - top_k_categorical_accuracy: 0.9444 - val_loss: 4965.6879 - val_accuracy: 0.0256 - val_top_k_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "####TEST DNN\n",
    "print('------------Building DNN model--------------')\n",
    "ShuffleInTraining=True\n",
    "N_EPOCHS=30\n",
    "N_HN_1=512\n",
    "N_HN=256\n",
    "N_LAYERS=3\n",
    "N_BATCH=512\n",
    "lookback=1024\n",
    "Rate_Val=0.005\n",
    "N_Val_OverSampler=int(np.around(N_AllTrain_OverSampler*Rate_Val))\n",
    "N_Train_OverSampler=int(N_AllTrain_OverSampler-N_Val_OverSampler)\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresArray.shape[1]\n",
    "output_dim=N_CLASS\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HN_1,input_dim=input_dim))\n",
    "model.add(BatchNormalization())\n",
    "model.add(PReLU())\n",
    "# model.add(Dropout(dp))\n",
    "for i in range(N_LAYERS):\n",
    "    model.add(Dense(N_HN))\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(PReLU())\n",
    "#   model.add(Dropout(dp))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(output_dim))\n",
    "model.add(Activation('softmax'))\n",
    "# model = multi_gpu_model(model, 2)gfyht76\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(featuresArray,labelsArray,test_size=N_Val_OverSampler,train_size=N_Train_OverSampler, shuffle=True)\n",
    "# x_train=featuresArray[0:N_Train,:]\n",
    "# y_train=labelsArray[0:N_Train]\n",
    "y_train = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_train)), num_classes=N_CLASS)\n",
    "# x_val=featuresArray[N_Train:N_AllTrain,:] \n",
    "# y_val=labelsArray[N_Train:N_AllTrain]\n",
    "y_val = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_val)), num_classes=N_CLASS)\n",
    "print('------------DNN Training Go! Go! Go!!!!-----------')\n",
    "# fitting=model.fit(x_train, y_train, epochs=N_EPOCHS, batch_size=N_BATCH,verbose=2,validation_data=(x_val,y_val),shuffle=True)\n",
    "fitting=model.fit(x_train, y_train, epochs=N_EPOCHS, batch_size=N_BATCH,verbose=2,validation_data=(featuresArray_test,labelsArray_test),shuffle=True)\n",
    "\n",
    "# acc_test, test_score,fitting, model = build_and_fit_model(features_train.values,labels_train,x_val=features_test.values,y_test=labels_test,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)\n",
    "model.save('jjs_model_0124V3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------DNN Evaluate-------------------\n",
      "162505/162505 [==============================] - 3s 18us/step\n",
      "[2528.0585275140575, 0.027734531089663506, 1.0]\n",
      "1344603/1344603 [==============================] - 23s 17us/step\n",
      "[4965.687923595205, 0.025641025975346565, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('-----------DNN Evaluate-------------------')\n",
    "acc_test = model.evaluate(x_test,y_test, batch_size=N_BATCH)\n",
    "print(acc_test)\n",
    "acc_test_overSampler = model.evaluate(featuresArray_test,labelsArray_test, batch_size=N_BATCH)\n",
    "print(acc_test_overSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = fitting.history['loss']\n",
    "val_loss = fitting.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------DNN Evaluate-------------------\n",
      "87804/87804 [==============================] - 10s 110us/step\n",
      "[918.3527435946424, 0.19818003475666046, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('-----------DNN Evaluate-------------------')\n",
    "acc_test = model.evaluate(x_test,y_test, batch_size=N_BATCH)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('jjs_model_0124V2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Sort feature and label for LSTM------------------------------------\n",
      "--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------Sort feature and label for LSTM------------------------------------')\n",
    "featuresLSTM=features.values\n",
    "labelsLSTM = labels.values\n",
    "ShuffleInTraining=True\n",
    "N_EPOCHS=3\n",
    "N_HN=128\n",
    "N_LAYERS=1\n",
    "N_BATCH=128\n",
    "lookback=1024\n",
    "Rate_Val=0.2\n",
    "N_Val=np.around(N_AllTrain*Rate_Val)\n",
    "N_Train=N_AllTrain-N_Val\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresLSTM.shape[1]\n",
    "output_dim=N_CLASS\n",
    "\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "time_temp=featuresLSTM[:,2]+np.dot(featuresLSTM[:,3],100)+np.dot(featuresLSTM[:,4],10000)+np.dot(featuresLSTM[:,5],1000000)\n",
    "features_label_time=np.column_stack((featuresLSTM,labelsLSTM))\n",
    "features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "featuresLSTM=features_label_time[:,0:featuresLSTM.shape[1]]\n",
    "labelsLSTM=features_label_time[:,-2]\n",
    "labelsLSTM = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsLSTM)), num_classes=N_CLASS)\n",
    "del features_label_time\n",
    "\n",
    "print('--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------')\n",
    "train_generator=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=N_Train, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_generator=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=N_Train+1, max_index=None, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "AllTrain_generator=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "AllTest_generator=generator(x_test, y_test, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_steps = (N_Val-lookback) // N_BATCH\n",
    "test_steps =(N_AllTest - lookback) // N_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = Sequential()\n",
    "LSTMmodel.add(layers.Flatten(input_shape=(lookback, input_dim)))\n",
    "LSTMmodel.add(layers.Dense(N_HN, activation='relu'))\n",
    "LSTMmodel.add(layers.Dense(output_dim))\n",
    "model.add(Activation('softmax'))\n",
    "LSTMmodel.compile(optimizer=RMSprop(), loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "# LSTMmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------LSTM GO GO GO!!!!---------------------------------------------\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 797s 16s/step - loss: 8.1904 - accuracy: 0.0864 - top_k_categorical_accuracy: 0.3411 - val_loss: 7.9591 - val_accuracy: 0.1394 - val_top_k_categorical_accuracy: 0.4280\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 784s 16s/step - loss: 8.0796 - accuracy: 0.1109 - top_k_categorical_accuracy: 0.3505 - val_loss: 7.2991 - val_accuracy: 0.0774 - val_top_k_categorical_accuracy: 0.3846\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 788s 16s/step - loss: 8.1813 - accuracy: 0.1255 - top_k_categorical_accuracy: 0.3256 - val_loss: 8.9437 - val_accuracy: 0.1139 - val_top_k_categorical_accuracy: 0.3852\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "history = LSTMmodel.fit_generator(train_generator,steps_per_epoch=50,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------LSTM ReTraining On AllTrainSet (include trainSet and valSet) !!!!---------------------------------\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 820s 16s/step - loss: 8.1710 - accuracy: 0.1575 - top_k_categorical_accuracy: 0.3841 - val_loss: 7.1834 - val_accuracy: 0.1535 - val_top_k_categorical_accuracy: 0.4441\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------LSTM ReTraining On AllTrainSet (include trainSet and valSet) !!!!---------------------------------')\n",
    "historyAll = LSTMmodel.fit_generator(AllTrain_generator,steps_per_epoch=50, epochs=1,verbose=1,validation_data=val_generator,validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9226/10000 [==========================>...] - ETA: 2:14"
     ]
    }
   ],
   "source": [
    "acc_test = LSTMmodel.evaluate_generator(AllTest_generator, steps=10000,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------LSTM Evaluate on AllTestSet-------------------\n",
      "87804/87804 [==============================] - 19971s 227ms/step\n",
      "[9.870048522949219, 0.00019201147370040417, 0.28379303216934204]\n"
     ]
    }
   ],
   "source": [
    "print('-----------LSTM Evaluate on AllTestSet-------------------')\n",
    "####\n",
    "#需要将train_X_ALL和test_X拼接在一起，先计算一下train_X_ALL的行数，然后，根据lookback来确定test_X从哪一行开始\n",
    "####\n",
    "#evaluate_generator(generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "acc_test = LSTMmodel.evaluate_generator(AllTest_generator, steps=N_AllTest,  verbose=1)\n",
    "# acc_test = LSTMmodel.evaluate(test_X,test_Y, batch_size=N_BATCH)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Begin LSTM--------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7acc29103aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelsLSTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfeatures_label_time\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfeaturesLSTM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeaturesLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabelsLSTM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "OnlyLSTM=True#False\n",
    "if OnlyLSTM:\n",
    "    print('------------Begin LSTM--------------')\n",
    "    featuresLSTM=features.values\n",
    "    labelsLSTM = labels.values\n",
    "        #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    time_temp=featuresLSTM[:,2]+np.dot(featuresLSTM[:,3],100)+np.dot(featuresLSTM[:,4],10000)+np.dot(featuresLSTM[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresLSTM,labelsLSTM))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    featuresLSTM=features_label_time[:,0:featuresLSTM.shape[1]]\n",
    "    labelsLSTM=features_label_time[:,-2]\n",
    "    labelsLSTM = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsLSTM)), num_classes=N_CLASS)\n",
    "    del features_label_time\n",
    "\n",
    "    N_EPOCHS=40\n",
    "    N_HN=128\n",
    "    N_LAYERS=1\n",
    "    N_BATCH=64\n",
    "    lookback=4056\n",
    "    TestRate=0.2\n",
    "    size_Train=trainDF.shape[0]*TestRate\n",
    "    input_dim=featuresLSTM.shape[1]\n",
    "    output_dim=N_CLASS\n",
    "    \n",
    "    print('--------------------------generator Train_set and Val_set for LSTM---------------------------------')\n",
    "    train_X, train_Y=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=size_Train, shuffle=True, batch_size=N_BATCH, step=1)\n",
    "    val_X, val_Y=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=size_Train+1, max_index=None, shuffle=True, batch_size=N_BATCH, step=1)\n",
    " \n",
    "    LSTMmodel = Sequential()\n",
    "    LSTMmodel.add(layers.Flatten(input_shape=(lookback, input_dim)))\n",
    "    LSTMmodel.add(layers.Dense(N_HN, activation='relu'))\n",
    "    LSTMmodel.add(layers.Dense(output_dim))\n",
    "    LSTMmodel.compile(optimizer=RMSprop(), loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "    # LSTMmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "    print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "    history = LSTMmodel.fit(train_X,train_Y, epochs=N_EPOCHS,verbose=1,validation_data=(val_X, val_Y))\n",
    "\n",
    "    print('--------------------------LSTM ReTraining On trainSet and valSet!!!!---------------------------------')\n",
    "    train_X_ALL, train_Y_ALL=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=True, batch_size=N_BATCH, step=1)\n",
    "    historyAll = LSTMmodel.fit(train_X_ALL, train_Y_ALL, epochs=N_EPOCHS,verbose=1,validation_data=(val_X, val_Y))\n",
    "\n",
    "    print('-----------LSTM Evaluate ALL-------------------')\n",
    "    ####\n",
    "\n",
    "    #需要将train_X_ALL和test_X拼接在一起，先计算一下train_X_ALL的行数，然后，根据lookback来确定test_X从哪一行开始\n",
    "\n",
    "    ####\n",
    "    test_X, test_Y=generator(x_test, y_test, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=True, batch_size=N_BATCH, step=1)\n",
    "    acc_test = LSTMmodel.evaluate(test_X,test_Y, batch_size=N_BATCH)\n",
    "    print(acc_test)\n",
    "else:   \n",
    "    N_EPOCHS=21\n",
    "    N_HN=256\n",
    "    N_HN_1=512\n",
    "    N_LAYERS=2\n",
    "    N_BATCH=64\n",
    "    DP=0.5\n",
    "    SORTbyTime=False #是否需要根据时间顺序，留出后Test_size个样本用于测试\n",
    "    TestRate=0.2 #当SORTbyTime=False 时，该值才起作用\n",
    "    Test_size=200000#当SORTbyTime=True 时，该值才起作用\n",
    "    split_count=1#当SORTbyTime=True 时，该值才起作用\n",
    "    split_size=int(Test_size/split_count)#当SORTbyTime=True 时，该值才起作用\n",
    "    N_hight=featuresArray.shape[0]\n",
    "    print('------------train_val_split--------------')\n",
    "    for t_i in range(split_count):\n",
    "        if SORTbyTime:\n",
    "            # t_i=t0_i+1\n",
    "            print('--------NNN_spllit_NNN_spllit_NNN_spllit_NNN_spllit_---------')\n",
    "            print(t_i)\n",
    "            x_train=featuresArray[0:N_hight-Test_size+t_i*split_size,:]\n",
    "            y_train=labelsArray[0:N_hight-Test_size+t_i*split_size]\n",
    "\n",
    "            x_val=featuresArray[N_hight-Test_size+t_i*split_size:N_hight-Test_size+(t_i+1)*split_size,:]\n",
    "            y_val=labelsArray[N_hight-Test_size+t_i*split_size:N_hight-Test_size+(t_i+1)*split_size]\n",
    "        else:\n",
    "            print('------------train_val_split_Shuffle--------------')\n",
    "            x_train,x_val,y_train,y_val = train_test_split(featuresArray,labelsArray,test_size=TestRate,shuffle=True)\n",
    "        print('------------to_categorical--------------')\n",
    "        y_train = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_train)), num_classes=N_CLASS)\n",
    "        y_val = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_val)), num_classes=N_CLASS)\n",
    "\n",
    "\n",
    "        ##########################################################################\n",
    "        print('------------Building model--------------')\n",
    "        input_dim=x_train.shape[1]\n",
    "        output_dim=N_CLASS\n",
    "        model = Sequential()\n",
    "        model.add(Dense(N_HN_1,input_dim=input_dim,init='glorot_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(PReLU())\n",
    "        # model.add(Dropout(dp))\n",
    "        for i in range(N_LAYERS):\n",
    "            model.add(Dense(N_HN, init='glorot_uniform'))\n",
    "            model.add(BatchNormalization())    \n",
    "            model.add(PReLU())    \n",
    "        #   model.add(Dropout(dp))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(output_dim, init='glorot_uniform'))\n",
    "        model.add(Activation('softmax'))\n",
    "        # model = multi_gpu_model(model, 2)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "        if OnlyLSTM:\n",
    "            print('------------Go! Go! Go!!!!-----------')\n",
    "            fitting=model.fit(x_train, y_train, epochs=N_EPOCHS, batch_size=N_BATCH,verbose=1,validation_data=(x_val,y_val))\n",
    "            # acc_test, test_score,fitting, model = build_and_fit_model(features_train.values,labels_train,x_val=features_test.values,y_test=labels_test,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)\n",
    "            # model.save('jjs_model_0112.h5')\n",
    "            print('-----------Evaluate-------------------')\n",
    "            acc_test = model.evaluate(x_test,y_test, batch_size=N_BATCH)\n",
    "            print(acc_test)\n",
    "            if SORTbyTime:\n",
    "                del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    " \n",
    "K.clear_session()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
