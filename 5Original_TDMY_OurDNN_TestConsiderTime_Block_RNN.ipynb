{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验R1:引入LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras import layers,metrics\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU, ELU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.utils import shuffle as reset\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "# import \n",
    "from matplotlib.pylab import plt\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler #https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.RandomOverSampler.html?highlight=randomoversampler\n",
    "from frplayer import FilterResponseNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_DataFrame(data, test_size=0.2, considerTime=True, random_state=None):\n",
    "    # ConsiderTime-------trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "    if considerTime:\n",
    "        data=data.sort_values(by=\"Dates\", ascending=True)\n",
    "    else:\n",
    "        data=reset(data, random_state=random_state)\n",
    "    train=data[int(len(data)*test_size):].reset_index(drop=True)\n",
    "    test=data[:int(len(data)*test_size)].reset_index(drop=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj    \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "def Dates2TDMY(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj  \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    #T_D_M_Y=str(time)+str(day)+str(month)+str(year)\n",
    "    T_D_M_Y=str(time)+str(day)+str(month)\n",
    "    return T_D_M_Y\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field2Vec(trainDF,testDF,fieldStr):\n",
    "    fields=sorted(trainDF[fieldStr].unique())\n",
    "    categories=sorted(trainDF[\"Category\"].unique())\n",
    "    C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "    F_C_counts=trainDF.groupby([fieldStr,\"Category\"]).size()\n",
    "    F_counts=trainDF.groupby([fieldStr]).size()\n",
    "    logodds={}\n",
    "    logoddsPF={}\n",
    "    MIN_CAT_COUNTS=2\n",
    "    default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "    for f in fields:\n",
    "        PA=F_counts[f]/float(len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "        logodds[f]=deepcopy(default_logodds)\n",
    "        for cat in F_C_counts[f].keys():\n",
    "            if (F_C_counts[f][cat]>MIN_CAT_COUNTS) and F_C_counts[f][cat]<F_counts[f]:\n",
    "                PA=F_C_counts[f][cat]/float(F_counts[f])\n",
    "                logodds[f][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "        logodds[f]=pd.Series(logodds[f])\n",
    "        logodds[f].index=range(len(categories))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #fieldsTest=sorted(testDF[fieldStr].unique())\n",
    "    #N_count=0\n",
    "    #for f in fieldsTest:\n",
    "        #if f not in fields:\n",
    "            #logoddsPF[f]=-50.0  #np.log(0.)-np.log(1.)=-inf,便于计算，改为-99999.0\n",
    "            #logodds[f]=deepcopy(default_logodds)\n",
    "            #pa=1.0/float(len(categories))\n",
    "            #logodds[f][range(len(categories))]=np.log(pa)-np.log(1.0-pa)\n",
    "            #logodds[f]=pd.Series(logodds[f])\n",
    "            #logodds[f].index=range(len(categories))\n",
    "            #N_count=N_count+1\n",
    "    #print(fieldStr+' N_count: '+str(N_count))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #引进代码原作者的新思想\n",
    "    if testDF.shape[0]>0: #如果testDF里有样本,......\n",
    "        print('There are some new:'+fieldStr)\n",
    "        new_fields=sorted(testDF[fieldStr].unique())\n",
    "        new_F_counts=testDF.groupby(fieldStr).size()\n",
    "        only_new=set(new_fields+fields)-set(fields)\n",
    "        only_old=set(new_fields+fields)-set(new_fields)\n",
    "        in_both=set(new_fields).intersection(fields)\n",
    "        print('# only_new_fieldds:'+str(len(only_new)))\n",
    "        for f in only_new:\n",
    "            PA=new_F_counts[f]/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "            logodds[f]=deepcopy(default_logodds)\n",
    "            logodds[f].index=range(len(categories))\n",
    "        for f in in_both:\n",
    "            PA=(F_counts[f]+new_F_counts[f])/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)    \n",
    "    return logodds,logoddsPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(df,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y=False):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print(\"Creating address features\")###Creating address features###\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds_A[x])\n",
    "    address_features.columns=[\"logodds_A\"+str(x) for x in range(len(address_features.columns))]\n",
    "    if needT_D_M_Y:\n",
    "        print(\"Creating time T_D_M_Y features\")###Creating time T_D_M_Y features###\n",
    "        T_D_M_Y_features=cleanData[\"T_D_M_Y\"].apply(lambda xx: logodds_T[xx])\n",
    "        T_D_M_Y_features.columns=[\"logodds_T\"+str(xx) for xx in range(len(T_D_M_Y_features.columns))]\n",
    "\n",
    "    print(\"Parsing dates\")            ###Creating address features###\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    #     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    #     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print(\"Creating one-hot variables\")\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPF_A\"]=cleanData[\"Address\"].apply(lambda x: logoddsPF_A[x])\n",
    "    if needT_D_M_Y:\n",
    "        cleanData[\"logoddsPF_T\"]=cleanData[\"T_D_M_Y\"].apply(lambda x: logoddsPF_T[x])\n",
    "    print(\"droping processed columns\")\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)    \n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    if needT_D_M_Y:\n",
    "        cleanData=cleanData.drop(\"T_D_M_Y\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print(\"joining one-hot features\")\n",
    "    if needT_D_M_Y:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:]).join(T_D_M_Y_features.iloc[:,:])\n",
    "    else:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:])\n",
    "    print(\"creating new features\")\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(keep='last')).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, Y, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(X) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)#数值在[low, high)区间。\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, X.shape[-1]))\n",
    "        targets = np.zeros((len(rows),Y.shape[1]))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = X[indices]\n",
    "            targets[j] = Y[rows[j]+delay]\n",
    "#         print('# row of Val: '+str(targets.shape[0]))###Tian\n",
    "        yield samples, targets\n",
    "    #Now here is the data generator that we will use. It yields a tuple (samples, targets) where samples is one batch of input data and targets is the corresponding array of target temperatures. It takes the following arguments:\n",
    "        # •data: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "        # •lookback: How many timesteps back should our input data go.\n",
    "        # •delay: How many timesteps in the future should our target be.\n",
    "        # •min_index and max_index: Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another one for testing.\n",
    "        # •shuffle: Whether to shuffle our samples or draw them in chronological order.\n",
    "        # •batch_size: The number of samples per batch.\n",
    "        # •step: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of OrginalAllDF: (878049, 9)\n",
      "The shape of AllDF after del wrong X and Y values: (877982, 9)\n",
      "The shape of AllDF after drop_duplicates: (812529, 9)\n",
      "(689038, 2)\n",
      "Address_counts_allDF_trainDF_testDF: 23191_23191_0\n",
      "The # of AllDF, AllTrain, AllTest, is: 812529,812529,0\n",
      "-----------LOGOODS: Address-------------\n",
      "-----------LOGOODS: T_D_M_Y-------------\n",
      "-----------LOGOODS: parse_data of Alltrain  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPF_A', 'logoddsPF_T', 'PD_BAYVIEW', 'PD_CENTRAL', 'PD_INGLESIDE', 'PD_MISSION', 'PD_NORTHERN', 'PD_PARK', 'PD_RICHMOND', 'PD_SOUTHERN', 'PD_TARAVAL', 'PD_TENDERLOIN', 'DAY_Friday', 'DAY_Monday', 'DAY_Saturday', 'DAY_Sunday', 'DAY_Thursday', 'DAY_Tuesday', 'DAY_Wednesday', 'logodds_A0', 'logodds_A1', 'logodds_A2', 'logodds_A3', 'logodds_A4', 'logodds_A5', 'logodds_A6', 'logodds_A7', 'logodds_A8', 'logodds_A9', 'logodds_A10', 'logodds_A11', 'logodds_A12', 'logodds_A13', 'logodds_A14', 'logodds_A15', 'logodds_A16', 'logodds_A17', 'logodds_A18', 'logodds_A19', 'logodds_A20', 'logodds_A21', 'logodds_A22', 'logodds_A23', 'logodds_A24', 'logodds_A25', 'logodds_A26', 'logodds_A27', 'logodds_A28', 'logodds_A29', 'logodds_A30', 'logodds_A31', 'logodds_A32', 'logodds_A33', 'logodds_A34', 'logodds_A35', 'logodds_A36', 'logodds_A37', 'logodds_A38', 'logodds_T0', 'logodds_T1', 'logodds_T2', 'logodds_T3', 'logodds_T4', 'logodds_T5', 'logodds_T6', 'logodds_T7', 'logodds_T8', 'logodds_T9', 'logodds_T10', 'logodds_T11', 'logodds_T12', 'logodds_T13', 'logodds_T14', 'logodds_T15', 'logodds_T16', 'logodds_T17', 'logodds_T18', 'logodds_T19', 'logodds_T20', 'logodds_T21', 'logodds_T22', 'logodds_T23', 'logodds_T24', 'logodds_T25', 'logodds_T26', 'logodds_T27', 'logodds_T28', 'logodds_T29', 'logodds_T30', 'logodds_T31', 'logodds_T32', 'logodds_T33', 'logodds_T34', 'logodds_T35', 'logodds_T36', 'logodds_T37', 'logodds_T38', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n",
      "110\n",
      "------------Attention: we do not RandomOverSampler---------------\n",
      "------------ConsiderTime:  Sorting--------------\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "ConsiderTime=True#False# True##trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "Rate_ALL=0.0 #0.0即不保留测试机\n",
    "needOverSampler=False\n",
    "needT_D_M_Y=True #False  使用_T_D_M_Y和周几\n",
    "allDF=pd.read_csv(\"./train_addrCorrect.csv\")\n",
    "print('The shape of OrginalAllDF: '+str(allDF.shape))\n",
    "\n",
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(allDF[[\"X\",\"Y\"]])\n",
    "allDF[[\"X\",\"Y\"]]=xy_scaler.transform(allDF[[\"X\",\"Y\"]])\n",
    "allDF=allDF[abs(allDF[\"Y\"])<100]\n",
    "allDF.index=range(len(allDF))\n",
    "print('The shape of AllDF after del wrong X and Y values: '+str(allDF.shape))\n",
    "\n",
    "def listCat(x):\n",
    "    return list(x)\n",
    "allDF.drop_duplicates(inplace=True,subset=['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Category'])\n",
    "Train_duplicated=pd.pivot_table(allDF,index=['Dates','DayOfWeek','PdDistrict', 'Address', 'X', 'Y'], values='Category',aggfunc=[len,listCat])\n",
    "print('The shape of AllDF after drop_duplicates: '+str(allDF.shape))\n",
    "print(Train_duplicated.shape)\n",
    "\n",
    "trainDF,testDF=train_test_split_DataFrame(allDF, test_size=Rate_ALL, considerTime=ConsiderTime, random_state=None)\n",
    "print('Address_counts_allDF_trainDF_testDF: ' + str(len(allDF[\"Address\"].unique())) + '_'+ str(len(trainDF[\"Address\"].unique())) + '_' + str(len(testDF[\"Address\"].unique())))\n",
    "\n",
    "N_AllSample=allDF.shape[0]\n",
    "N_AllTrain=trainDF.shape[0]\n",
    "N_AllTest=testDF.shape[0]\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "print('The # of AllDF, AllTrain, AllTest, is: '+str(N_AllSample)+','+str(N_AllTrain)+','+str(N_AllTest))\n",
    "#################Now proceed as before#################\n",
    "print('-----------LOGOODS: Address-------------')\n",
    "logodds_A,logoddsPF_A=field2Vec(trainDF,testDF,\"Address\")\n",
    "if needT_D_M_Y:\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"Dates\"].apply(Dates2TDMY)\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"T_D_M_Y\"]+trainDF[\"DayOfWeek\"]\n",
    "    if Rate_ALL>0:\n",
    "        testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"Dates\"].apply(Dates2TDMY)\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"T_D_M_Y\"]+testDF[\"DayOfWeek\"]\n",
    "    print('-----------LOGOODS: T_D_M_Y-------------')\n",
    "    logodds_T,logoddsPF_T=field2Vec(trainDF,testDF,\"T_D_M_Y\")    \n",
    "else:\n",
    "    logodds_T=None\n",
    "    logoddsPF_T=None\n",
    "    \n",
    "print('-----------LOGOODS: parse_data of Alltrain  -------------')\n",
    "features, labels=parse_data(trainDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y) \n",
    "if Rate_ALL>0:\n",
    "    print('-----------LOGOODS: parse_data of Alltest  -------------')\n",
    "    features_test, labels_test=parse_data(testDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y)###########和训练集使用同样的时间和地点Logoodds值#####\n",
    "    x_test=features_test.values\n",
    "    y_test=labels_test.values\n",
    "    y_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_test)), num_classes=N_CLASS)\n",
    "\n",
    "print(features.columns.tolist())\n",
    "print(len(features.columns))\n",
    "\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)\n",
    "if Rate_ALL>0:\n",
    "    features_test[collist]=scaler.transform(features_test)###########和训练集使用同样的scaler值#####\n",
    "######################################################\n",
    "#############################先进行过采样，然后再根据时间来排序##################################\n",
    "if needOverSampler:\n",
    "    print('------------RandomOverSampler--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArrayOverSampler, labelsArrayOverSampler = ros.fit_resample(features.values,labels.values)#####过采样#####\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('Shape of OverSampler of AllTrain: '+str(featuresArrayOverSampler.shape))\n",
    "else:\n",
    "    featuresArrayOverSampler=features.values\n",
    "    labelsArrayOverSampler=labels.values\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('------------Attention: we do not RandomOverSampler---------------')\n",
    "if ConsiderTime:\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    print('------------ConsiderTime:  Sorting--------------')\n",
    "    time_temp=featuresArrayOverSampler[:,2]+np.dot(featuresArrayOverSampler[:,3],100)+np.dot(featuresArrayOverSampler[:,4],10000)+np.dot(featuresArrayOverSampler[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresArrayOverSampler,labelsArrayOverSampler))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    labelsArrayOverSampler=features_label_time[:,-2]\n",
    "    featuresArrayOverSampler=features_label_time[:,0:featuresArrayOverSampler.shape[1]]\n",
    "    del features_label_time\n",
    "    #############################先进行过采样，然后再根据时间来排序----结束############################\n",
    "if Rate_ALL>0:\n",
    "    print('------------RandomOverSampler for AllTest--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArray_test, labelsArray_test = ros.fit_resample(features_test.values,labels_test.values)#####过采样#####\n",
    "    N_AllTest_OverSampler=int(featuresArray_test.shape[0])\n",
    "    labelsArray_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArray_test)), num_classes=N_CLASS)\n",
    "    print('Shape of OverSampler of AllTest: '+str(featuresArray_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Building DNN model--------------\n",
      "N_Train_OverSampler= 162506\n",
      "BlockSize is: 1300\n",
      "-----------------E!!---------------------\n",
      "-----------------F!!---------------------\n",
      "-----------------G!!---------------------\n"
     ]
    }
   ],
   "source": [
    "####TEST DNN\n",
    "print('------------Building LSTM model--------------')\n",
    "ShuffleInTraining=True\n",
    "N_EPOCHS_0=2\n",
    "N_EPOCHS=1\n",
    "N_HN_1=128\n",
    "N_HN=64\n",
    "N_BATCH=64\n",
    "\n",
    "Rate_Val=0.8\n",
    "\n",
    "\n",
    "N_Val_OverSampler=int(np.around(N_AllTrain_OverSampler*Rate_Val))\n",
    "N_Train_OverSampler=int(N_AllTrain_OverSampler-N_Val_OverSampler)\n",
    "print('N_Train_OverSampler= '+str(N_Train_OverSampler))\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresArrayOverSampler.shape[1]\n",
    "output_dim=N_CLASS\n",
    "\n",
    "N_Split=500\n",
    "BlockSize=int(np.floor(N_Val_OverSampler/N_Split))\n",
    "print('BlockSize is: '+str(BlockSize)) \n",
    "lookback=BlockSize\n",
    "delay=-1\n",
    "\n",
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(LSTM(N_HN_1,return_sequences=True,input_shape=(None,input_dim)))\n",
    "RNNmodel.add(LSTM(N_HN))\n",
    "RNNmodel.add(Dense(output_dim))\n",
    "RNNmodel.add(Activation('softmax'))\n",
    "RNNmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(),metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "\n",
    "labelsArrayOverSampler_1hot=keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArrayOverSampler)), num_classes=N_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------\n",
      "--------------------------generator AllTrain_set, Train_set  for LSTM---------------------------------\n",
      "------------generator finished--------------------\n",
      "---------------------------------------LSTM GO GO GO!!!!---------------------------------------------\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/2\n",
      "2518/2518 [==============================] - 6027s 2s/step - loss: 2.2824 - accuracy: 0.3107 - top_k_categorical_accuracy: 0.7268 - val_loss: 2.5244 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "2518/2518 [==============================] - 5165s 2s/step - loss: 2.1676 - accuracy: 0.3364 - top_k_categorical_accuracy: 0.7583 - val_loss: 2.5910 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "------------LSTM train finished--------------------\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------')\n",
    "train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=0, max_index=N_Train_OverSampler, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler-lookback, max_index=N_Train_OverSampler+1, shuffle=False, batch_size=N_BATCH, step=1)\n",
    "#数值在[min_index, max_index)区间。当delay=1时，就是用[min_index, max_index)区间的样本预测，第max_index个样本。当delay=2时，就是预测第max_index+1个\n",
    "train_steps= (N_Train_OverSampler-lookback) // N_BATCH\n",
    "val_steps =  1 #(N_Val-lookback) // N_BATCH\n",
    "# test_steps =(N_AllTest - lookback) // N_BATCH\n",
    "print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "# history = RNNmodel.fit_generator(train_generator,steps_per_epoch=10,epochs=N_EPOCHS_0,verbose=1)\n",
    "history = RNNmodel.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=N_EPOCHS_0,verbose=1,validation_data=val_generator,validation_steps=val_steps)\n",
    "print('------------LSTM train finished--------------------')\n",
    "RNNmodel.save('jjs_model_0201LSTMV1.h5')\n",
    "# RNNmodel.evaluate_generator(val_generator,steps=1, callbacks=None,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Start the loop training!!---------------------\n",
      "i_s=0 in 500;  max_index=163807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0022 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6603 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0, 0, 1.0]\n",
      "[0, 0, 0.0]\n",
      "[0, 0, 1.0]\n",
      "i_s=1 in 500;  max_index=165107\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.0158 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5941 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=2 in 500;  max_index=166407\n",
      "Epoch 1/1\n",
      " - 35s - loss: 1.5387 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 6.1046 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=3 in 500;  max_index=167707\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.2867 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0646 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=4 in 500;  max_index=169007\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.4483 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.0677 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=5 in 500;  max_index=170307\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1463 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9823 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=6 in 500;  max_index=171607\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0382 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1379 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=7 in 500;  max_index=172907\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.6600 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5630 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=8 in 500;  max_index=174207\n",
      "Epoch 1/1\n",
      " - 36s - loss: 1.7171 - accuracy: 0.7647 - top_k_categorical_accuracy: 0.7647 - val_loss: 5.1180 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=9 in 500;  max_index=175507\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0517 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9848 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=10 in 500;  max_index=176807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.3078 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5692 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=11 in 500;  max_index=178107\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0055 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5236 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=12 in 500;  max_index=179407\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2194 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2418 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=13 in 500;  max_index=180707\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0725 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8207 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=14 in 500;  max_index=182007\n",
      "Epoch 1/1\n",
      " - 41s - loss: 1.1325 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 4.2071 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=15 in 500;  max_index=183307\n",
      "Epoch 1/1\n",
      " - 38s - loss: 1.0295 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 4.4237 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=16 in 500;  max_index=184607\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.2377 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.2254 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=17 in 500;  max_index=185907\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.5082 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.2656 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=18 in 500;  max_index=187207\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0389 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.5713 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=19 in 500;  max_index=188507\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3512 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.7556 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=20 in 500;  max_index=189807\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3695 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0278 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=21 in 500;  max_index=191107\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.2189 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.5174 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=22 in 500;  max_index=192407\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2820 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5634 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=23 in 500;  max_index=193707\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.5153 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.0245 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=24 in 500;  max_index=195007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0413 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6551 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=25 in 500;  max_index=196307\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.2538 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5722 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=26 in 500;  max_index=197607\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0091 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8273 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=27 in 500;  max_index=198907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.8077 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.8824 - val_loss: 4.4549 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=28 in 500;  max_index=200207\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1313 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.1780 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=29 in 500;  max_index=201507\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0034 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1069 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=30 in 500;  max_index=202807\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1858 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6355 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=31 in 500;  max_index=204107\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3655 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.1720 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=32 in 500;  max_index=205407\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0666 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8637 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=33 in 500;  max_index=206707\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.0646 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.0065 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=34 in 500;  max_index=208007\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.2203 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8827 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=35 in 500;  max_index=209307\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.1465 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2717 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=36 in 500;  max_index=210607\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.1837 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4351 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=37 in 500;  max_index=211907\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0478 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.2322 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=38 in 500;  max_index=213207\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2992 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.7289 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=39 in 500;  max_index=214507\n",
      "Epoch 1/1\n",
      " - 34s - loss: 1.1221 - accuracy: 0.7647 - top_k_categorical_accuracy: 0.8824 - val_loss: 3.9547 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=40 in 500;  max_index=215807\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0066 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.3819 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=41 in 500;  max_index=217107\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0519 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=42 in 500;  max_index=218407\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0791 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8701 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=43 in 500;  max_index=219707\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.9141 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 5.7822 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=44 in 500;  max_index=221007\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0084 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7682 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=45 in 500;  max_index=222307\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0226 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2231 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=46 in 500;  max_index=223607\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.2029 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2763 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=47 in 500;  max_index=224907\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0241 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0080 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=48 in 500;  max_index=226207\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.4590 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5110 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=49 in 500;  max_index=227507\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2404 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5090 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0]\n",
      "i_s=50 in 500;  max_index=228807\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.1067 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.5582 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=51 in 500;  max_index=230107\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0027 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4935 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=52 in 500;  max_index=231407\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3823 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.4274 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=53 in 500;  max_index=232707\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.3339 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.3833 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=54 in 500;  max_index=234007\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1031 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9662 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=55 in 500;  max_index=235307\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.3323 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.4130 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=56 in 500;  max_index=236607\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.1543 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2741 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=57 in 500;  max_index=237907\n",
      "Epoch 1/1\n",
      " - 30s - loss: 1.5069 - accuracy: 0.7647 - top_k_categorical_accuracy: 0.8235 - val_loss: 5.2598 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=58 in 500;  max_index=239207\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.3111 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0895 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=59 in 500;  max_index=240507\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1137 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.7253 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=60 in 500;  max_index=241807\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0528 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3149 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=61 in 500;  max_index=243107\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1604 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0661 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=62 in 500;  max_index=244407\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.8108 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.4119 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=63 in 500;  max_index=245707\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.1676 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.2058 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=64 in 500;  max_index=247007\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0755 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8322 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=65 in 500;  max_index=248307\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.2376 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.0843 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=66 in 500;  max_index=249607\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0957 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0454 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=67 in 500;  max_index=250907\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.3697 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.8744 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=68 in 500;  max_index=252207\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0062 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1832 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=69 in 500;  max_index=253507\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0315 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9088 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=70 in 500;  max_index=254807\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.5530 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 0.7639 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=71 in 500;  max_index=256107\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0710 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.1311 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=72 in 500;  max_index=257407\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.3004 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1005 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=73 in 500;  max_index=258707\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0063 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=74 in 500;  max_index=260007\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.2572 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3583 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=75 in 500;  max_index=261307\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.3513 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7513 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=76 in 500;  max_index=262607\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.3167 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.2483 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=77 in 500;  max_index=263907\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1109 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4742 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=78 in 500;  max_index=265207\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0321 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8076 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=79 in 500;  max_index=266507\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.4356 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.8957 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=80 in 500;  max_index=267807\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0782 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7238 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=81 in 500;  max_index=269107\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.4390 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6754 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=82 in 500;  max_index=270407\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.3095 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.4560 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=83 in 500;  max_index=271707\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.3847 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.9412 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=84 in 500;  max_index=273007\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0791 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9316 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=85 in 500;  max_index=274307\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.2780 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.6187 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=86 in 500;  max_index=275607\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.3158 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.1670 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=87 in 500;  max_index=276907\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1626 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.5632 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=88 in 500;  max_index=278207\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0417 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2835 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=89 in 500;  max_index=279507\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.3452 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.2650 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=90 in 500;  max_index=280807\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0178 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0174 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=91 in 500;  max_index=282107\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.6087 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.8824 - val_loss: 2.8024 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=92 in 500;  max_index=283407\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.5440 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 0.9938 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=93 in 500;  max_index=284707\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.7437 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.8824 - val_loss: 4.1037 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=94 in 500;  max_index=286007\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.2033 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.1734 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=95 in 500;  max_index=287307\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.2343 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2188 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=96 in 500;  max_index=288607\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2140 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6381 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=97 in 500;  max_index=289907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3823 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.9128 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=98 in 500;  max_index=291207\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0141 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0873 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0]\n",
      "i_s=99 in 500;  max_index=292507\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.1584 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0008 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=100 in 500;  max_index=293807\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0567 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6246 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=101 in 500;  max_index=295107\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1357 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=102 in 500;  max_index=296407\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.2448 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1719 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=103 in 500;  max_index=297707\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.9475 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.3760 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=104 in 500;  max_index=299007\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.2255 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.9384 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=105 in 500;  max_index=300307\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0631 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3313 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=106 in 500;  max_index=301607\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2254 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4316 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=107 in 500;  max_index=302907\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0394 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1922 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=108 in 500;  max_index=304207\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0058 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0252 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=109 in 500;  max_index=305507\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0766 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6586 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=110 in 500;  max_index=306807\n",
      "Epoch 1/1\n",
      " - 38s - loss: 1.2495 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8235 - val_loss: 5.1265 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=111 in 500;  max_index=308107\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.2249 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4660 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=112 in 500;  max_index=309407\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0909 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9565 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=113 in 500;  max_index=310707\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.1373 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=114 in 500;  max_index=312007\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0214 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6968 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=115 in 500;  max_index=313307\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.1040 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.9602 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=116 in 500;  max_index=314607\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0890 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6243 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=117 in 500;  max_index=315907\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0861 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5594 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=118 in 500;  max_index=317207\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.8970 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.8824 - val_loss: 4.4394 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=119 in 500;  max_index=318507\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0570 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7353 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=120 in 500;  max_index=319807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.5705 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.1530 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=121 in 500;  max_index=321107\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.4355 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.9595 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=122 in 500;  max_index=322407\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.3137 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4351 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=123 in 500;  max_index=323707\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.5119 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.8338 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=124 in 500;  max_index=325007\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0926 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8425 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=125 in 500;  max_index=326307\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0031 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0627 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=126 in 500;  max_index=327607\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.3522 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6138 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=127 in 500;  max_index=328907\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0106 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8313 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=128 in 500;  max_index=330207\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0241 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2026 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=129 in 500;  max_index=331507\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0114 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0096 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=130 in 500;  max_index=332807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 1.4320e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=131 in 500;  max_index=334107\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0380 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6742 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=132 in 500;  max_index=335407\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0225 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=133 in 500;  max_index=336707\n",
      "Epoch 1/1\n",
      " - 37s - loss: 7.6534e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=134 in 500;  max_index=338007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0013 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=135 in 500;  max_index=339307\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.5158 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5622 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=136 in 500;  max_index=340607\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2817 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0781 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=137 in 500;  max_index=341907\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.5964 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.9498 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=138 in 500;  max_index=343207\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0399 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7620 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=139 in 500;  max_index=344507\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1404 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=140 in 500;  max_index=345807\n",
      "Epoch 1/1\n",
      " - 35s - loss: 1.2370 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 6.8438 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=141 in 500;  max_index=347107\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0851 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4321 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=142 in 500;  max_index=348407\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.8010 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 9.2941 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=143 in 500;  max_index=349707\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1872 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8089 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=144 in 500;  max_index=351007\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.1416 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7312 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=145 in 500;  max_index=352307\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0661 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9734 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=146 in 500;  max_index=353607\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0500 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6738 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=147 in 500;  max_index=354907\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.2676 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6938 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "i_s=148 in 500;  max_index=356207\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.9295 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.5189 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=149 in 500;  max_index=357507\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1710 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2903 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=150 in 500;  max_index=358807\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.7488 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 5.1714 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=151 in 500;  max_index=360107\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0233 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8965 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=152 in 500;  max_index=361407\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0964 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3275 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=153 in 500;  max_index=362707\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0110 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0944 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=154 in 500;  max_index=364007\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0067 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2333 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=155 in 500;  max_index=365307\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.3846 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.5762 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=156 in 500;  max_index=366607\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0045 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5599 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=157 in 500;  max_index=367907\n",
      "Epoch 1/1\n",
      " - 36s - loss: 1.7232 - accuracy: 0.6471 - top_k_categorical_accuracy: 0.7647 - val_loss: 3.8372 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=158 in 500;  max_index=369207\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2940 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.0046 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=159 in 500;  max_index=370507\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.1508 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6204 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=160 in 500;  max_index=371807\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0105 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3236 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=161 in 500;  max_index=373107\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.3691 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.1705 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=162 in 500;  max_index=374407\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.1917 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.7326 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=163 in 500;  max_index=375707\n",
      "Epoch 1/1\n",
      " - 32s - loss: 1.0896 - accuracy: 0.7647 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.2984 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=164 in 500;  max_index=377007\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1006 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2525 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=165 in 500;  max_index=378307\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3580 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.8905 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=166 in 500;  max_index=379607\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0224 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.6203 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=167 in 500;  max_index=380907\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.6092 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.8824 - val_loss: 3.1680 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=168 in 500;  max_index=382207\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.1520 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8917 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=169 in 500;  max_index=383507\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1953 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.7588 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=170 in 500;  max_index=384807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0797 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6886 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=171 in 500;  max_index=386107\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.1771 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9751 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=172 in 500;  max_index=387407\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0948 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3649 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=173 in 500;  max_index=388707\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1352 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8205 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=174 in 500;  max_index=390007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.4739 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.2171 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=175 in 500;  max_index=391307\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1274 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.6618 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=176 in 500;  max_index=392607\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1768 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5993 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=177 in 500;  max_index=393907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.1567 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4377 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=178 in 500;  max_index=395207\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.4896 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.2314 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=179 in 500;  max_index=396507\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.1472 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5637 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=180 in 500;  max_index=397807\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0137 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5082 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=181 in 500;  max_index=399107\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0619 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1337 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=182 in 500;  max_index=400407\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.3169 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8078 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=183 in 500;  max_index=401707\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.5651 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.9233 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=184 in 500;  max_index=403007\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0075 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7961 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=185 in 500;  max_index=404307\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2838 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.7846 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=186 in 500;  max_index=405607\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0341 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4560 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=187 in 500;  max_index=406907\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0177 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=188 in 500;  max_index=408207\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.7701 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.5299 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=189 in 500;  max_index=409507\n",
      "Epoch 1/1\n",
      " - 35s - loss: 1.1407 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 5.1525 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=190 in 500;  max_index=410807\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.4460 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.5993 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=191 in 500;  max_index=412107\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0134 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4324 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=192 in 500;  max_index=413407\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1060 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5397 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=193 in 500;  max_index=414707\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0602 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0526 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=194 in 500;  max_index=416007\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0023 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9400 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=195 in 500;  max_index=417307\n",
      "Epoch 1/1\n",
      " - 31s - loss: 1.8188 - accuracy: 0.7647 - top_k_categorical_accuracy: 0.8235 - val_loss: 6.6884 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=196 in 500;  max_index=418607\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.6220 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.8398 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.8235294, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.64705884, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 0.88235295, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.7647059, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647059, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.8235294, 0.9411765]\n",
      "i_s=197 in 500;  max_index=419907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0705 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.0150 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=198 in 500;  max_index=421207\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.3514 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.3154 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=199 in 500;  max_index=422507\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2377 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1769 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=200 in 500;  max_index=423807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.5152 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5529 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=201 in 500;  max_index=425107\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0033 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2946 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=202 in 500;  max_index=426407\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2090 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.2821 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=203 in 500;  max_index=427707\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0055 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8937 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=204 in 500;  max_index=429007\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.5512 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.5843 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=205 in 500;  max_index=430307\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.1656 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6610 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=206 in 500;  max_index=431607\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.2265 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.1336 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=207 in 500;  max_index=432907\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0953 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8880 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=208 in 500;  max_index=434207\n",
      "Epoch 1/1\n",
      " - 30s - loss: 1.3474 - accuracy: 0.7647 - top_k_categorical_accuracy: 0.8235 - val_loss: 5.9809 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=209 in 500;  max_index=435507\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0297 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=210 in 500;  max_index=436807\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0255 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7793 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=211 in 500;  max_index=438107\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.4747 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.3856 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=212 in 500;  max_index=439407\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2565 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5693 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=213 in 500;  max_index=440707\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.3446 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.8852 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=214 in 500;  max_index=442007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.3863 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.0369 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=215 in 500;  max_index=443307\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2638 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.9185 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=216 in 500;  max_index=444607\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.3626 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.7157 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=217 in 500;  max_index=445907\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1950 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8621 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=218 in 500;  max_index=447207\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2778 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.1352 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=219 in 500;  max_index=448507\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0763 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4723 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=220 in 500;  max_index=449807\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0769 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8189 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=221 in 500;  max_index=451107\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0019 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7794 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=222 in 500;  max_index=452407\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.2215 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5289 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=223 in 500;  max_index=453707\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0203 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2730 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=224 in 500;  max_index=455007\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.2409 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4143 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=225 in 500;  max_index=456307\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0015 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=226 in 500;  max_index=457607\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1503 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9410 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=227 in 500;  max_index=458907\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.3205 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=228 in 500;  max_index=460207\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2043 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7542 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=229 in 500;  max_index=461507\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.4980 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.4513 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=230 in 500;  max_index=462807\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0722 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.1128 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=231 in 500;  max_index=464107\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.2562 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.8476 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=232 in 500;  max_index=465407\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0206 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3492 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=233 in 500;  max_index=466707\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.1232 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1922 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=234 in 500;  max_index=468007\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.4111 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.7115 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=235 in 500;  max_index=469307\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0079 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3106 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=236 in 500;  max_index=470607\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.2224 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4617 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=237 in 500;  max_index=471907\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.3864 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.3560 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=238 in 500;  max_index=473207\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.2516 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4613 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=239 in 500;  max_index=474507\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.1213 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0604 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=240 in 500;  max_index=475807\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.1582 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9525 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=241 in 500;  max_index=477107\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0015 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=242 in 500;  max_index=478407\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.0819 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4393 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=243 in 500;  max_index=479707\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0480 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9911 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=244 in 500;  max_index=481007\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.1687 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9189 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=245 in 500;  max_index=482307\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.2969 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.4234 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.8235294, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.64705884, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 0.88235295, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.7647059, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647059, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "i_s=246 in 500;  max_index=483607\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.2326 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.1825 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=247 in 500;  max_index=484907\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.1541 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8217 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=248 in 500;  max_index=486207\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1684 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5969 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=249 in 500;  max_index=487507\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0674 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1521 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=250 in 500;  max_index=488807\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0363 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4505 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=251 in 500;  max_index=490107\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0135 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=252 in 500;  max_index=491407\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.1489 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8517 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=253 in 500;  max_index=492707\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3210 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8091 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=254 in 500;  max_index=494007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2819 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 0.6718 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=255 in 500;  max_index=495307\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0141 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=256 in 500;  max_index=496607\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.2054 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1104 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=257 in 500;  max_index=497907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.2825 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5540 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=258 in 500;  max_index=499207\n",
      "Epoch 1/1\n",
      " - 31s - loss: 7.0999e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=259 in 500;  max_index=500507\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0924 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3266 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=260 in 500;  max_index=501807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0966 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.0948 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=261 in 500;  max_index=503107\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.1404 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4800 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=262 in 500;  max_index=504407\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0024 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8810 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=263 in 500;  max_index=505707\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0179 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=264 in 500;  max_index=507007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.2139 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6603 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=265 in 500;  max_index=508307\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.1012 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6211 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=266 in 500;  max_index=509607\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.7990 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.0914 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=267 in 500;  max_index=510907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.2872 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=268 in 500;  max_index=512207\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.2646 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6100 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=269 in 500;  max_index=513507\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.4970 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.7015 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=270 in 500;  max_index=514807\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.5017 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.7650 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=271 in 500;  max_index=516107\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.2417 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=272 in 500;  max_index=517407\n",
      "Epoch 1/1\n",
      " - 47s - loss: 0.0044 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6932 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=273 in 500;  max_index=518707\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.2783 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.4794 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=274 in 500;  max_index=520007\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.2455 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.3395 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=275 in 500;  max_index=521307\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1227 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=276 in 500;  max_index=522607\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0456 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=277 in 500;  max_index=523907\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0263 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1575 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=278 in 500;  max_index=525207\n",
      "Epoch 1/1\n",
      " - 47s - loss: 0.4189 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.9796 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=279 in 500;  max_index=526507\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.1256 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.7662 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=280 in 500;  max_index=527807\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.0085 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.5548 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=281 in 500;  max_index=529107\n",
      "Epoch 1/1\n",
      " - 44s - loss: 3.4098e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7292 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=282 in 500;  max_index=530407\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0381 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0384 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=283 in 500;  max_index=531707\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0013 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0792 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=284 in 500;  max_index=533007\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0482 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=285 in 500;  max_index=534307\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.2561 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.7297 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=286 in 500;  max_index=535607\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.1474 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.5655 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=287 in 500;  max_index=536907\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.1204 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.8445 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=288 in 500;  max_index=538207\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.4344 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7513 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=289 in 500;  max_index=539507\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.3814 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.3444 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=290 in 500;  max_index=540807\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.5234 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.6901 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=291 in 500;  max_index=542107\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0703 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=292 in 500;  max_index=543407\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1867 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8573 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=293 in 500;  max_index=544707\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.1951 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6483 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=294 in 500;  max_index=546007\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0984 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6641 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.8235294, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.64705884, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 0.88235295, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.7647059, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647059, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0]\n",
      "i_s=295 in 500;  max_index=547307\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0110 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6409 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=296 in 500;  max_index=548607\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1597 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=297 in 500;  max_index=549907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3380 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9390 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=298 in 500;  max_index=551207\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1959 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.3552 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=299 in 500;  max_index=552507\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.2590 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5189 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=300 in 500;  max_index=553807\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0947 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3207 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=301 in 500;  max_index=555107\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.2339 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=302 in 500;  max_index=556407\n",
      "Epoch 1/1\n",
      " - 29s - loss: 0.0930 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.0623 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=303 in 500;  max_index=557707\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0070 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=304 in 500;  max_index=559007\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.1273 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=305 in 500;  max_index=560307\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.0244 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6510 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=306 in 500;  max_index=561607\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.4256 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.1984 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=307 in 500;  max_index=562907\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.1241 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3341 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=308 in 500;  max_index=564207\n",
      "Epoch 1/1\n",
      " - 30s - loss: 0.0097 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4814 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=309 in 500;  max_index=565507\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.1127 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2334 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=310 in 500;  max_index=566807\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0042 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5120 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=311 in 500;  max_index=568107\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0863 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3343 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=312 in 500;  max_index=569407\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.9076 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.9412 - val_loss: 7.3170 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=313 in 500;  max_index=570707\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0041 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=314 in 500;  max_index=572007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.0293 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=315 in 500;  max_index=573307\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.2483 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 7.3370 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=316 in 500;  max_index=574607\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0105 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6175 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=317 in 500;  max_index=575907\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.1919 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=318 in 500;  max_index=577207\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0032 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2676 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=319 in 500;  max_index=578507\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.3836 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.3372 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=320 in 500;  max_index=579807\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0095 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0774 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=321 in 500;  max_index=581107\n",
      "Epoch 1/1\n",
      " - 48s - loss: 0.0436 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1168 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=322 in 500;  max_index=582407\n",
      "Epoch 1/1\n",
      " - 32s - loss: 4.1793e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6999 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=323 in 500;  max_index=583707\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1188 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2524 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=324 in 500;  max_index=585007\n",
      "Epoch 1/1\n",
      " - 31s - loss: 0.1510 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.2088 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=325 in 500;  max_index=586307\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.3904 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=326 in 500;  max_index=587607\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0290 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9267 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=327 in 500;  max_index=588907\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.6156 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.6350 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=328 in 500;  max_index=590207\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2228 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1006 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=329 in 500;  max_index=591507\n",
      "Epoch 1/1\n",
      " - 50s - loss: 0.0727 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7020 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=330 in 500;  max_index=592807\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.3762 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.9475 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=331 in 500;  max_index=594107\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.3788 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6668 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=332 in 500;  max_index=595407\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.2372 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6877 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=333 in 500;  max_index=596707\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0558 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2677 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=334 in 500;  max_index=598007\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.0695 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=335 in 500;  max_index=599307\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.0588 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8567 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=336 in 500;  max_index=600607\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.5097 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.7779 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=337 in 500;  max_index=601907\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.4043 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0255 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=338 in 500;  max_index=603207\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.1948 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7719 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=339 in 500;  max_index=604507\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.1775 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=340 in 500;  max_index=605807\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.4829 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3910 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=341 in 500;  max_index=607107\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.1846 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0660 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=342 in 500;  max_index=608407\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.0035 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4500 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=343 in 500;  max_index=609707\n",
      "Epoch 1/1\n",
      " - 50s - loss: 0.1570 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7382 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.8235294, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.64705884, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 0.88235295, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.7647059, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647059, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "i_s=344 in 500;  max_index=611007\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.1553 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8450 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=345 in 500;  max_index=612307\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0338 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=346 in 500;  max_index=613607\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.5475 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.7151 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=347 in 500;  max_index=614907\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0021 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=348 in 500;  max_index=616207\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0576 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1282 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=349 in 500;  max_index=617507\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0127 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7236 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=350 in 500;  max_index=618807\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0293 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4025 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=351 in 500;  max_index=620107\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.2087 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3059 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=352 in 500;  max_index=621407\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.1171 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7952 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=353 in 500;  max_index=622707\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1583 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=354 in 500;  max_index=624007\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.4435 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.6980 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=355 in 500;  max_index=625307\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1066 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8827 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=356 in 500;  max_index=626607\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.8477 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 4.1171 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=357 in 500;  max_index=627907\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0046 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=358 in 500;  max_index=629207\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0014 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6557 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=359 in 500;  max_index=630507\n",
      "Epoch 1/1\n",
      " - 47s - loss: 0.4640 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4237 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=360 in 500;  max_index=631807\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0022 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4970 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=361 in 500;  max_index=633107\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.0153 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5945 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=362 in 500;  max_index=634407\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.1155 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3545 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=363 in 500;  max_index=635707\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.2052 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.2605 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=364 in 500;  max_index=637007\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0142 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0441 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=365 in 500;  max_index=638307\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0725 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4594 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=366 in 500;  max_index=639607\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.8786 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.8824 - val_loss: 4.1968 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=367 in 500;  max_index=640907\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0041 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9706 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=368 in 500;  max_index=642207\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.7271 - accuracy: 0.7647 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.5160 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=369 in 500;  max_index=643507\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0829 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2197 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=370 in 500;  max_index=644807\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.1550 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6150 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=371 in 500;  max_index=646107\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0179 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0264 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=372 in 500;  max_index=647407\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.2920 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.1603 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=373 in 500;  max_index=648707\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.4739 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.2407 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=374 in 500;  max_index=650007\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1487 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4218 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=375 in 500;  max_index=651307\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.2794 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.2514 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=376 in 500;  max_index=652607\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0888 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=377 in 500;  max_index=653907\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.5417 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 7.5931 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=378 in 500;  max_index=655207\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0065 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6436 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=379 in 500;  max_index=656507\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0119 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6707 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=380 in 500;  max_index=657807\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0026 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=381 in 500;  max_index=659107\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.4503 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.6900 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=382 in 500;  max_index=660407\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.3792 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.0765 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=383 in 500;  max_index=661707\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.1868 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2909 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=384 in 500;  max_index=663007\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0068 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8936 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=385 in 500;  max_index=664307\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0062 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7395 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=386 in 500;  max_index=665607\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.0443 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.1738 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=387 in 500;  max_index=666907\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.2018 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=388 in 500;  max_index=668207\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0601 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4712 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=389 in 500;  max_index=669507\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.7976 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.4781 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=390 in 500;  max_index=670807\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.3147 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=391 in 500;  max_index=672107\n",
      "Epoch 1/1\n",
      " - 49s - loss: 0.0279 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4444 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=392 in 500;  max_index=673407\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0656 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.9223 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.8235294, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.64705884, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 0.88235295, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.7647059, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.8235294, 1.0, 1.0, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647059, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0]\n",
      "i_s=393 in 500;  max_index=674707\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.2441 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4728 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=394 in 500;  max_index=676007\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.1246 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.9832 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=395 in 500;  max_index=677307\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.1238 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7934 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=396 in 500;  max_index=678607\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0022 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=397 in 500;  max_index=679907\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.4411 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.2489 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=398 in 500;  max_index=681207\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0081 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=399 in 500;  max_index=682507\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.4171 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 6.8988 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=400 in 500;  max_index=683807\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.0793 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6919 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=401 in 500;  max_index=685107\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2269 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7868 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=402 in 500;  max_index=686407\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2452 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.6740 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=403 in 500;  max_index=687707\n",
      "Epoch 1/1\n",
      " - 32s - loss: 0.0679 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=404 in 500;  max_index=689007\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.4895 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6385 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=405 in 500;  max_index=690307\n",
      "Epoch 1/1\n",
      " - 34s - loss: 0.3370 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0006 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=406 in 500;  max_index=691607\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1812 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6433 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=407 in 500;  max_index=692907\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.2315 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.4139 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=408 in 500;  max_index=694207\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0098 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6600 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=409 in 500;  max_index=695507\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0436 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.6785 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=410 in 500;  max_index=696807\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0074 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5515 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=411 in 500;  max_index=698107\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.1264 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7347 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=412 in 500;  max_index=699407\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.0014 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8618 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=413 in 500;  max_index=700707\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1865 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7596 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=414 in 500;  max_index=702007\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.3182 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.6580 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=415 in 500;  max_index=703307\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.3132 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.4831 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=416 in 500;  max_index=704607\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.7552 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.8001 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=417 in 500;  max_index=705907\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.4160 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 7.7059 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=418 in 500;  max_index=707207\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0122 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.0769 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=419 in 500;  max_index=708507\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.3253 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.0623 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=420 in 500;  max_index=709807\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.0612 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=421 in 500;  max_index=711107\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.3456 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4254 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=422 in 500;  max_index=712407\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.1511 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.5932 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=423 in 500;  max_index=713707\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.5224 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5628 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=424 in 500;  max_index=715007\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.1568 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.6962 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=425 in 500;  max_index=716307\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.1067 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7902 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=426 in 500;  max_index=717607\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0202 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2991 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=427 in 500;  max_index=718907\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.0537 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=428 in 500;  max_index=720207\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.2138 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2703 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=429 in 500;  max_index=721507\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.6619 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.9683 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=430 in 500;  max_index=722807\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.2797 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8875 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=431 in 500;  max_index=724107\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.4613 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.9914 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=432 in 500;  max_index=725407\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.1368 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1547 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=433 in 500;  max_index=726707\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.3807 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.3527 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=434 in 500;  max_index=728007\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.0033 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.4683 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=435 in 500;  max_index=729307\n",
      "Epoch 1/1\n",
      " - 33s - loss: 0.0030 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=436 in 500;  max_index=730607\n",
      "Epoch 1/1\n",
      " - 34s - loss: 4.9924e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0957 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=437 in 500;  max_index=731907\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0099 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7901 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=438 in 500;  max_index=733207\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0799 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.9518 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=439 in 500;  max_index=734507\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0090 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.0212 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=440 in 500;  max_index=735807\n",
      "Epoch 1/1\n",
      " - 47s - loss: 0.0212 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.0662 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=441 in 500;  max_index=737107\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.2722 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.2855 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.8235294, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.64705884, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 0.88235295, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.7647059, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.8235294, 1.0, 1.0, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647059, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "i_s=442 in 500;  max_index=738407\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.1927 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=443 in 500;  max_index=739707\n",
      "Epoch 1/1\n",
      " - 51s - loss: 0.1118 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=444 in 500;  max_index=741007\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.0311 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=445 in 500;  max_index=742307\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.1106 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.6773 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=446 in 500;  max_index=743607\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.1770 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.6072 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=447 in 500;  max_index=744907\n",
      "Epoch 1/1\n",
      " - 46s - loss: 0.0339 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2074 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=448 in 500;  max_index=746207\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0247 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.9476 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=449 in 500;  max_index=747507\n",
      "Epoch 1/1\n",
      " - 51s - loss: 0.3219 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.2649 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=450 in 500;  max_index=748807\n",
      "Epoch 1/1\n",
      " - 47s - loss: 0.0581 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=451 in 500;  max_index=750107\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.2099 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=452 in 500;  max_index=751407\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.3622 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.4127 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=453 in 500;  max_index=752707\n",
      "Epoch 1/1\n",
      " - 47s - loss: 0.1426 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.3346 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=454 in 500;  max_index=754007\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0036 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=455 in 500;  max_index=755307\n",
      "Epoch 1/1\n",
      " - 48s - loss: 1.1697 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.8824 - val_loss: 5.6286 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=456 in 500;  max_index=756607\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.3088 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.4274 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=457 in 500;  max_index=757907\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.3290 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8395 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=458 in 500;  max_index=759207\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.5209 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5074 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=459 in 500;  max_index=760507\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2192 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3253 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=460 in 500;  max_index=761807\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.2803 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.2010 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=461 in 500;  max_index=763107\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.1699 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0039 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=462 in 500;  max_index=764407\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.1787 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9210 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=463 in 500;  max_index=765707\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.0729 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3641 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=464 in 500;  max_index=767007\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.5429 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.2910 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=465 in 500;  max_index=768307\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0944 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.5526 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=466 in 500;  max_index=769607\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0844 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=467 in 500;  max_index=770907\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0123 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=468 in 500;  max_index=772207\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.1448 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=469 in 500;  max_index=773507\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2413 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.2234 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=470 in 500;  max_index=774807\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0559 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.2481 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=471 in 500;  max_index=776107\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.4942 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9426 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=472 in 500;  max_index=777407\n",
      "Epoch 1/1\n",
      " - 44s - loss: 0.1094 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7538 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=473 in 500;  max_index=778707\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.3300 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 2.6763 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=474 in 500;  max_index=780007\n",
      "Epoch 1/1\n",
      " - 42s - loss: 0.1962 - accuracy: 0.8824 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.2803 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=475 in 500;  max_index=781307\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0584 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8563 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=476 in 500;  max_index=782607\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1722 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.8472 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=477 in 500;  max_index=783907\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.1156 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.3723 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=478 in 500;  max_index=785207\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.1259 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.9050 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=479 in 500;  max_index=786507\n",
      "Epoch 1/1\n",
      " - 43s - loss: 0.0118 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=480 in 500;  max_index=787807\n",
      "Epoch 1/1\n",
      " - 43s - loss: 1.0400 - accuracy: 0.8235 - top_k_categorical_accuracy: 0.8824 - val_loss: 5.6777 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=481 in 500;  max_index=789107\n",
      "Epoch 1/1\n",
      " - 40s - loss: 0.0288 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=482 in 500;  max_index=790407\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.0282 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.6454 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=483 in 500;  max_index=791707\n",
      "Epoch 1/1\n",
      " - 45s - loss: 0.3790 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.5102 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=484 in 500;  max_index=793007\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0448 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.9530 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=485 in 500;  max_index=794307\n",
      "Epoch 1/1\n",
      " - 35s - loss: 0.2272 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 5.5887 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=486 in 500;  max_index=795607\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0776 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.9943 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=487 in 500;  max_index=796907\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.0697 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.9249 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=488 in 500;  max_index=798207\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.1073 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.7685 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=489 in 500;  max_index=799507\n",
      "Epoch 1/1\n",
      " - 37s - loss: 0.5047 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.5341 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=490 in 500;  max_index=800807\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0237 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.2493 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "[0, 0, 1.0, 1.0, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.8235294, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.7647059, 1.0, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.8235294, 0.9411765, 0.8235294, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.64705884, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.7647059, 0.9411765, 0.88235295, 1.0, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.7647059, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.7647059, 1.0, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.8235294, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.8235294, 1.0, 1.0, 0.88235295, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.88235295, 1.0, 0.7647059, 1.0, 0.9411765, 1.0, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.9411765, 0.88235295, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 0.88235295, 1.0]\n",
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0, 0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.7647059, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.88235295, 0.88235295, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7647059, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.88235295, 0.9411765, 1.0, 1.0, 1.0, 1.0, 0.8235294, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 0.8235294, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.88235295, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 0.9411765, 0.9411765, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.9411765, 1.0, 1.0, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.88235295, 1.0, 1.0, 0.9411765, 1.0, 0.9411765, 1.0, 1.0, 1.0, 0.9411765, 1.0]\n",
      "i_s=491 in 500;  max_index=802107\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.5073 - accuracy: 0.8824 - top_k_categorical_accuracy: 0.9412 - val_loss: 3.9959 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=492 in 500;  max_index=803407\n",
      "Epoch 1/1\n",
      " - 38s - loss: 0.0401 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.7722 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=493 in 500;  max_index=804707\n",
      "Epoch 1/1\n",
      " - 50s - loss: 0.0705 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7439 - val_accuracy: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=494 in 500;  max_index=806007\n",
      "Epoch 1/1\n",
      " - 50s - loss: 0.3849 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 1.6868 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=495 in 500;  max_index=807307\n",
      "Epoch 1/1\n",
      " - 39s - loss: 0.0035 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.4251 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=496 in 500;  max_index=808607\n",
      "Epoch 1/1\n",
      " - 49s - loss: 0.2530 - accuracy: 0.9412 - top_k_categorical_accuracy: 0.9412 - val_loss: 4.2094 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0000e+00\n",
      "i_s=497 in 500;  max_index=809907\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.2972 - accuracy: 0.9412 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.9013 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=498 in 500;  max_index=811207\n",
      "Epoch 1/1\n",
      " - 41s - loss: 0.0568 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.3077 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n",
      "i_s=499 in 500;  max_index=812507\n",
      "Epoch 1/1\n",
      " - 36s - loss: 0.0355 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0774 - val_accuracy: 0.0000e+00 - val_top_k_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print('-----------------Start the loop training!!---------------------')\n",
    "# Scores_all=np.zeros([N_Split,4])\n",
    "ACC=[0.0,0.0]\n",
    "val_ACC=[0.0,0.0]\n",
    "val_TopACC=[0.0,0.0]\n",
    "for i_s in range(N_Split):\n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    print('i_s='+str(i_s)+ ' in '+ str(N_Split) +';  max_index='+str(N_Train_OverSampler+(i_s+1)*BlockSize+1))\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    #history = RNNmodel.fit_generator(train_generator,steps_per_epoch=1,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=(N_Val_OverSampler - lookback) // N_BATCH)\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=17,epochs=1,verbose=2,validation_data=val_generator,validation_steps=1)\n",
    "\n",
    "    ACC.extend(history.history['accuracy'])\n",
    "    val_ACC.extend(history.history['val_accuracy'])\n",
    "    val_TopACC.extend(history.history['top_k_categorical_accuracy'])\n",
    "    if i_s%49==0:\n",
    "        print(ACC)\n",
    "        print(val_ACC)\n",
    "        print(val_TopACC)\n",
    "        \n",
    "print(val_ACC)\n",
    "NP_val_ACC=np.array(val_ACC)\n",
    "print(np.sum(NP_val_ACC)/500)\n",
    "NP_val_ACCTop5=np.array(val_TopACC)\n",
    "print(np.sum(NP_val_ACCTop5)/500)\n",
    "#     loss_i, acc_i, top5acc_i=RNNmodel.evaluate(x=x_val_i, y=y_val_i, batch_size=None, verbose=0, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "\n",
    "# print('i_s='+str(i_s)+' , '+str(np.array([[loss_i, acc_i, top5acc_i]])))\n",
    "#     Scores_all[i_s,:]=np.array([[loss_i, acc_i, top5acc_i]])\n",
    "    \n",
    "# np.mean(Scores_all, axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.9478823560476303\n",
      "0.184\n",
      "0.9808235305547714\n"
     ]
    }
   ],
   "source": [
    "print(val_ACC)\n",
    "\n",
    "NP_ACC=np.array(ACC)\n",
    "print(np.sum(NP_ACC)/500)\n",
    "\n",
    "NP_val_ACC=np.array(val_ACC)\n",
    "print(np.sum(NP_val_ACC)/500)\n",
    "\n",
    "NP_val_ACCTop5=np.array(val_TopACC)\n",
    "print(np.sum(NP_val_ACCTop5)/500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (1300, 110)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6c3023c0b540>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mssssss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesArrayOverSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             warnings.warn('Network returning invalid probability values. '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (1300, 110)"
     ]
    }
   ],
   "source": [
    "ssssss=RNNmodel.predict_proba(featuresArrayOverSampler[0:1300,:],batch_size=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------Start the loop training!!---------------------')\n",
    "# Scores_all=np.zeros([N_Split,4])\n",
    "ACC=[0.0,0.0]\n",
    "val_ACC=[0.0,0.0]\n",
    "val_TopACC=[0.0,0.0]\n",
    "for i_s in range(N_Split):\n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    print('i_s='+str(i_s)+ ' in '+ str(N_Split) +';  max_index='+str(N_Train_OverSampler+(i_s+1)*BlockSize+1))\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    #history = RNNmodel.fit_generator(train_generator,steps_per_epoch=1,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=(N_Val_OverSampler - lookback) // N_BATCH)\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=17,epochs=1,verbose=2,validation_data=val_generator,validation_steps=1)\n",
    "    RNNmodel.predict_proba(val_generator)\n",
    "    ACC.extend(history.history['accuracy'])\n",
    "    val_ACC.extend(history.history['val_accuracy'])\n",
    "    val_TopACC.extend(history.history['top_k_categorical_accuracy'])\n",
    "    if i_s%49==0:\n",
    "        print(ACC)\n",
    "        print(val_ACC)\n",
    "        print(val_TopACC)\n",
    "        \n",
    "print(val_ACC)\n",
    "NP_val_ACC=np.array(val_ACC)\n",
    "print(np.sum(NP_val_ACC)/500)\n",
    "NP_val_ACCTop5=np.array(val_TopACC)\n",
    "print(np.sum(NP_val_ACCTop5)/500)\n",
    "#     loss_i, acc_i, top5acc_i=RNNmodel.evaluate(x=x_val_i, y=y_val_i, batch_size=None, verbose=0, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------2222  Start the loop training!!---------------------\n",
      "i_s=0 in 500;  max_index=163807\n",
      "[0, 0, 1.0]\n",
      "[0, 0, 0.0]\n",
      "[0, 0, 1.0]\n",
      "i_s=1 in 500;  max_index=165107\n",
      "i_s=2 in 500;  max_index=166407\n",
      "i_s=3 in 500;  max_index=167707\n",
      "i_s=4 in 500;  max_index=169007\n",
      "i_s=5 in 500;  max_index=170307\n",
      "i_s=6 in 500;  max_index=171607\n",
      "i_s=7 in 500;  max_index=172907\n",
      "i_s=8 in 500;  max_index=174207\n",
      "i_s=9 in 500;  max_index=175507\n",
      "i_s=10 in 500;  max_index=176807\n",
      "i_s=11 in 500;  max_index=178107\n",
      "i_s=12 in 500;  max_index=179407\n",
      "i_s=13 in 500;  max_index=180707\n",
      "i_s=14 in 500;  max_index=182007\n",
      "i_s=15 in 500;  max_index=183307\n",
      "i_s=16 in 500;  max_index=184607\n",
      "i_s=17 in 500;  max_index=185907\n",
      "i_s=18 in 500;  max_index=187207\n",
      "i_s=19 in 500;  max_index=188507\n",
      "i_s=20 in 500;  max_index=189807\n",
      "i_s=21 in 500;  max_index=191107\n",
      "i_s=22 in 500;  max_index=192407\n",
      "i_s=23 in 500;  max_index=193707\n",
      "i_s=24 in 500;  max_index=195007\n",
      "i_s=25 in 500;  max_index=196307\n",
      "i_s=26 in 500;  max_index=197607\n",
      "i_s=27 in 500;  max_index=198907\n"
     ]
    }
   ],
   "source": [
    "print('-----------------2222  Start the loop training!!---------------------')\n",
    "# Scores_all=np.zeros([N_Split,4])\n",
    "ACC2=[0,0]\n",
    "val_ACC2=[0,0]\n",
    "val_TopACC2=[0,0]\n",
    "for i_s in range(N_Split):\n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+i_s*BlockSize, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    print('i_s='+str(i_s)+ ' in '+ str(N_Split) +';  max_index='+str(N_Train_OverSampler+(i_s+1)*BlockSize+1))\n",
    "    val_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler+(i_s+1)*BlockSize-lookback, max_index=N_Train_OverSampler+(i_s+1)*BlockSize+1,shuffle=False, batch_size=1, step=BlockSize)\n",
    "    #history = RNNmodel.fit_generator(train_generator,steps_per_epoch=1,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=(N_Val_OverSampler - lookback) // N_BATCH)\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=50,epochs=1,verbose=0,validation_data=val_generator,validation_steps=1)\n",
    "\n",
    "    ACC2.extend(history.history['accuracy'])\n",
    "    val_ACC2.extend(history.history['val_accuracy'])\n",
    "    val_TopACC2.extend(history.history['top_k_categorical_accuracy'])\n",
    "    if i_s%99==0:\n",
    "        print(ACC2)\n",
    "        print(val_ACC2)\n",
    "        print(val_TopACC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=5.0\n",
    "b=3.0\n",
    "div = a // b \n",
    "div\n",
    "i_s=10000\n",
    "i_s % 500==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0., 444.,   0.,   0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1, 2, 3]])\n",
    "print(a[0,1])\n",
    "n=np.zeros([1,4])\n",
    "n[0,1]=444\n",
    "n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
