{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras import layers,metrics\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU, ELU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.utils import shuffle as reset\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "# import \n",
    "from matplotlib.pylab import plt\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler #https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.RandomOverSampler.html?highlight=randomoversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_DataFrame(data, test_size=0.2, considerTime=True, random_state=None):\n",
    "    # ConsiderTime-------trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "    if considerTime:\n",
    "        data=data.sort_values(by=\"Dates\", ascending=True)\n",
    "    else:\n",
    "        data=reset(data, random_state=random_state)\n",
    "    train=data[int(len(data)*test_size):].reset_index(drop=True)\n",
    "    test=data[:int(len(data)*test_size)].reset_index(drop=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj    \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "def Dates2TDMY(x):\n",
    "    if '-' in x:\n",
    "        DD=datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\")#jjs\n",
    "    else:\n",
    "        DD=datetime.strptime(x,\"%Y/%m/%d %H:%M\")#zj  \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    #T_D_M_Y=str(time)+str(day)+str(month)+str(year)\n",
    "    T_D_M_Y=str(time)+str(day)+str(month)\n",
    "    return T_D_M_Y\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field2Vec(trainDF,testDF,fieldStr):\n",
    "    fields=sorted(trainDF[fieldStr].unique())\n",
    "    categories=sorted(trainDF[\"Category\"].unique())\n",
    "    C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "    F_C_counts=trainDF.groupby([fieldStr,\"Category\"]).size()\n",
    "    F_counts=trainDF.groupby([fieldStr]).size()\n",
    "    logodds={}\n",
    "    logoddsPF={}\n",
    "    MIN_CAT_COUNTS=2\n",
    "    default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "    for f in fields:\n",
    "        PA=F_counts[f]/float(len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "        logodds[f]=deepcopy(default_logodds)\n",
    "        for cat in F_C_counts[f].keys():\n",
    "            if (F_C_counts[f][cat]>MIN_CAT_COUNTS) and F_C_counts[f][cat]<F_counts[f]:\n",
    "                PA=F_C_counts[f][cat]/float(F_counts[f])\n",
    "                logodds[f][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "        logodds[f]=pd.Series(logodds[f])\n",
    "        logodds[f].index=range(len(categories))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    fieldsTest=sorted(testDF[fieldStr].unique())\n",
    "    N_count=0\n",
    "    for f in fieldsTest:\n",
    "        if f not in fields:\n",
    "            logoddsPF[f]=-50.0  #np.log(0.)-np.log(1.)=-inf,便于计算，改为-99999.0\n",
    "            logodds[f]=deepcopy(default_logodds)\n",
    "            pa=1.0/float(len(categories))\n",
    "            logodds[f][range(len(categories))]=np.log(pa)-np.log(1.0-pa)\n",
    "            logodds[f]=pd.Series(logodds[f])\n",
    "            logodds[f].index=range(len(categories))\n",
    "            N_count=N_count+1\n",
    "    print(fieldStr+' N_count: '+str(N_count))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    return logodds,logoddsPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(df,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print(\"Creating address features\")###Creating address features###\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds_A[x])\n",
    "    address_features.columns=[\"logodds_A\"+str(x) for x in range(len(address_features.columns))]\n",
    "    print(\"Creating time T_D_M_Y features\")###Creating time T_D_M_Y features###\n",
    "    T_D_M_Y_features=cleanData[\"T_D_M_Y\"].apply(lambda xx: logodds_T[xx])\n",
    "    T_D_M_Y_features.columns=[\"logodds_T\"+str(xx) for xx in range(len(T_D_M_Y_features.columns))]\n",
    "\n",
    "    print(\"Parsing dates\")            ###Creating address features###\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    #     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    #     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print(\"Creating one-hot variables\")\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPF_A\"]=cleanData[\"Address\"].apply(lambda x: logoddsPF_A[x])\n",
    "    cleanData[\"logoddsPF_T\"]=cleanData[\"T_D_M_Y\"].apply(lambda x: logoddsPF_T[x])\n",
    "    print(\"droping processed columns\")\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)\n",
    "    cleanData=cleanData.drop(\"T_D_M_Y\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print(\"joining one-hot features\")\n",
    "    features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:]).join(T_D_M_Y_features.iloc[:,:])\n",
    "    print(\"creating new features\")\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(keep='last')).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, Y, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(X) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, X.shape[-1]))\n",
    "        targets = np.zeros((len(rows),Y.shape[1]))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = X[indices]\n",
    "            targets[j] = Y[rows[j]+delay]\n",
    "        yield samples, targets\n",
    "    #Now here is the data generator that we will use. It yields a tuple (samples, targets) where samples is one batch of input data and targets is the corresponding array of target temperatures. It takes the following arguments:\n",
    "        # •data: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "        # •lookback: How many timesteps back should our input data go.\n",
    "        # •delay: How many timesteps in the future should our target be.\n",
    "        # •min_index and max_index: Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another one for testing.\n",
    "        # •shuffle: Whether to shuffle our samples or draw them in chronological order.\n",
    "        # •batch_size: The number of samples per batch.\n",
    "        # •step: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 9)\n",
      "(790245, 9)\n",
      "(87804, 9)\n",
      "Address_counts_allDF_trainDF_testDF: 23228_22978_14945\n",
      "-----------LOGOODS: T_D_M_Y-------------\n",
      "T_D_M_Y N_count: 35\n",
      "-----------LOGOODS: Address-------------\n",
      "Address N_count: 250\n",
      "-----------LOGOODS: parse_data of Alltrain  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "-----------LOGOODS: parse_data of Alltest  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n",
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPF_A', 'logoddsPF_T', 'PD_BAYVIEW', 'PD_CENTRAL', 'PD_INGLESIDE', 'PD_MISSION', 'PD_NORTHERN', 'PD_PARK', 'PD_RICHMOND', 'PD_SOUTHERN', 'PD_TARAVAL', 'PD_TENDERLOIN', 'DAY_Friday', 'DAY_Monday', 'DAY_Saturday', 'DAY_Sunday', 'DAY_Thursday', 'DAY_Tuesday', 'DAY_Wednesday', 'logodds_A0', 'logodds_A1', 'logodds_A2', 'logodds_A3', 'logodds_A4', 'logodds_A5', 'logodds_A6', 'logodds_A7', 'logodds_A8', 'logodds_A9', 'logodds_A10', 'logodds_A11', 'logodds_A12', 'logodds_A13', 'logodds_A14', 'logodds_A15', 'logodds_A16', 'logodds_A17', 'logodds_A18', 'logodds_A19', 'logodds_A20', 'logodds_A21', 'logodds_A22', 'logodds_A23', 'logodds_A24', 'logodds_A25', 'logodds_A26', 'logodds_A27', 'logodds_A28', 'logodds_A29', 'logodds_A30', 'logodds_A31', 'logodds_A32', 'logodds_A33', 'logodds_A34', 'logodds_A35', 'logodds_A36', 'logodds_A37', 'logodds_A38', 'logodds_T0', 'logodds_T1', 'logodds_T2', 'logodds_T3', 'logodds_T4', 'logodds_T5', 'logodds_T6', 'logodds_T7', 'logodds_T8', 'logodds_T9', 'logodds_T10', 'logodds_T11', 'logodds_T12', 'logodds_T13', 'logodds_T14', 'logodds_T15', 'logodds_T16', 'logodds_T17', 'logodds_T18', 'logodds_T19', 'logodds_T20', 'logodds_T21', 'logodds_T22', 'logodds_T23', 'logodds_T24', 'logodds_T25', 'logodds_T26', 'logodds_T27', 'logodds_T28', 'logodds_T29', 'logodds_T30', 'logodds_T31', 'logodds_T32', 'logodds_T33', 'logodds_T34', 'logodds_T35', 'logodds_T36', 'logodds_T37', 'logodds_T38', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n",
      "110\n",
      "------------RandomOverSampler--------------\n",
      "Shape of OverSampler of AllTrain: (6136494, 110)\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "ConsiderTime=False# True##trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "Rate_ALL=0.1\n",
    "allDF=pd.read_csv(\"./train.csv\")\n",
    "print(allDF.shape)\n",
    "trainDF,testDF=train_test_split_DataFrame(allDF, test_size=Rate_ALL, considerTime=ConsiderTime, random_state=None)\n",
    "print(trainDF.shape)\n",
    "print(testDF.shape)\n",
    "print('Address_counts_allDF_trainDF_testDF: ' + str(len(allDF[\"Address\"].unique())) + '_'+ str(len(trainDF[\"Address\"].unique())) + '_' + str(len(testDF[\"Address\"].unique())))\n",
    "\n",
    "N_AllSample=allDF.shape[0]\n",
    "N_AllTrain=trainDF.shape[0]\n",
    "N_AllTest=testDF.shape[0]\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "#################Now proceed as before#################\n",
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(trainDF[[\"X\",\"Y\"]])\n",
    "trainDF[[\"X\",\"Y\"]]=xy_scaler.transform(trainDF[[\"X\",\"Y\"]])\n",
    "\n",
    "trainDF[\"T_D_M_Y\"]=trainDF[\"Dates\"].apply(Dates2TDMY)\n",
    "trainDF[\"T_D_M_Y\"]=trainDF[\"T_D_M_Y\"]+trainDF[\"DayOfWeek\"]\n",
    "\n",
    "testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "testDF[\"T_D_M_Y\"]=testDF[\"Dates\"].apply(Dates2TDMY)\n",
    "testDF[\"T_D_M_Y\"]=testDF[\"T_D_M_Y\"]+testDF[\"DayOfWeek\"]\n",
    "\n",
    "print('-----------LOGOODS: T_D_M_Y-------------')\n",
    "logodds_T,logoddsPF_T=field2Vec(trainDF,testDF,\"T_D_M_Y\")\n",
    "print('-----------LOGOODS: Address-------------')\n",
    "logodds_A,logoddsPF_A=field2Vec(trainDF,testDF,\"Address\")\n",
    "print('-----------LOGOODS: parse_data of Alltrain  -------------')\n",
    "features, labels=parse_data(trainDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T) \n",
    "print('-----------LOGOODS: parse_data of Alltest  -------------')\n",
    "features_test, labels_test=parse_data(testDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T)###########和训练集使用同样的时间和地点Logoodds值#####\n",
    "x_test=features_test.values\n",
    "y_test=labels_test.values\n",
    "y_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_test)), num_classes=N_CLASS)\n",
    "\n",
    "print(features.columns.tolist())\n",
    "print(len(features.columns))\n",
    "\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)\n",
    "features_test[collist]=scaler.transform(features_test)###########和训练集使用同样的scaler值#####\n",
    "######################################################\n",
    "#############################先进行过采样，然后再根据时间来排序##################################\n",
    "print('------------RandomOverSampler--------------')\n",
    "ros = RandomOverSampler()\n",
    "featuresArray, labelsArray = ros.fit_resample(features.values,labels.values)#####过采样#####\n",
    "N_AllTrain_OverSampler=int(featuresArray.shape[0])\n",
    "print('Shape of OverSampler of AllTrain: '+str(featuresArray.shape))\n",
    "if ConsiderTime:\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    print('------------Sort--------------')\n",
    "    time_temp=featuresArray[:,2]+np.dot(featuresArray[:,3],100)+np.dot(featuresArray[:,4],10000)+np.dot(featuresArray[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresArray,labelsArray))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    labelsArray=features_label_time[:,-2]\n",
    "    featuresArray=features_label_time[:,0:featuresArray.shape[1]]\n",
    "    del features_label_time\n",
    "    #############################先进行过采样，然后再根据时间来排序----结束############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------RandomOverSampler--------------\n",
      "Shape of OverSampler of AllTest: (667052, 110)\n"
     ]
    }
   ],
   "source": [
    "print('------------RandomOverSampler--------------')\n",
    "ros = RandomOverSampler()\n",
    "featuresArray_test, labelsArray_test = ros.fit_resample(features_test.values,labels_test.values)#####过采样#####\n",
    "N_AllTest_OverSampler=int(featuresArray_test.shape[0])\n",
    "labelsArray_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArray_test)), num_classes=N_CLASS)\n",
    "print('Shape of OverSampler of AllTest: '+str(featuresArray_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Building DNN model--------------\n",
      "------------DNN Training Go! Go! Go!!!!-----------\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6105812 samples, validate on 87804 samples\n",
      "Epoch 1/100\n",
      " - 304s - loss: 1.4029 - accuracy: 0.6070 - top_k_categorical_accuracy: 0.8219 - val_loss: 2711.0574 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      " - 299s - loss: 1.0726 - accuracy: 0.6904 - top_k_categorical_accuracy: 0.8833 - val_loss: 3143.1225 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      " - 300s - loss: 0.9878 - accuracy: 0.7121 - top_k_categorical_accuracy: 0.8980 - val_loss: 3720.8004 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      " - 302s - loss: 0.9402 - accuracy: 0.7243 - top_k_categorical_accuracy: 0.9062 - val_loss: 2843.5162 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      " - 304s - loss: 0.9089 - accuracy: 0.7321 - top_k_categorical_accuracy: 0.9117 - val_loss: 2043.9137 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      " - 309s - loss: 0.8857 - accuracy: 0.7381 - top_k_categorical_accuracy: 0.9158 - val_loss: 3528.0607 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      " - 309s - loss: 0.8673 - accuracy: 0.7427 - top_k_categorical_accuracy: 0.9191 - val_loss: 1595.7076 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      " - 305s - loss: 0.8524 - accuracy: 0.7464 - top_k_categorical_accuracy: 0.9217 - val_loss: 1319.0156 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      " - 308s - loss: 0.8400 - accuracy: 0.7495 - top_k_categorical_accuracy: 0.9241 - val_loss: 1256.9933 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      " - 305s - loss: 0.8295 - accuracy: 0.7521 - top_k_categorical_accuracy: 0.9260 - val_loss: 1317.9352 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      " - 304s - loss: 0.8200 - accuracy: 0.7547 - top_k_categorical_accuracy: 0.9277 - val_loss: 1291.7453 - val_accuracy: 0.1062 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      " - 303s - loss: 0.8118 - accuracy: 0.7566 - top_k_categorical_accuracy: 0.9293 - val_loss: 1718.3239 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      " - 307s - loss: 0.8047 - accuracy: 0.7585 - top_k_categorical_accuracy: 0.9306 - val_loss: 1951.2551 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      " - 309s - loss: 0.7983 - accuracy: 0.7603 - top_k_categorical_accuracy: 0.9317 - val_loss: 3057.1450 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      " - 309s - loss: 0.7924 - accuracy: 0.7617 - top_k_categorical_accuracy: 0.9326 - val_loss: 2865.1300 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      " - 312s - loss: 0.7872 - accuracy: 0.7630 - top_k_categorical_accuracy: 0.9338 - val_loss: 2227.6618 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      " - 309s - loss: 0.7824 - accuracy: 0.7643 - top_k_categorical_accuracy: 0.9345 - val_loss: 3371.5403 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      " - 308s - loss: 0.7777 - accuracy: 0.7654 - top_k_categorical_accuracy: 0.9354 - val_loss: 2464.0289 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      " - 309s - loss: 0.7741 - accuracy: 0.7665 - top_k_categorical_accuracy: 0.9361 - val_loss: 2780.5755 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      " - 311s - loss: 0.7699 - accuracy: 0.7675 - top_k_categorical_accuracy: 0.9368 - val_loss: 1547.8569 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      " - 309s - loss: 0.7664 - accuracy: 0.7684 - top_k_categorical_accuracy: 0.9373 - val_loss: 1397.6833 - val_accuracy: 0.1110 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      " - 305s - loss: 0.7633 - accuracy: 0.7692 - top_k_categorical_accuracy: 0.9380 - val_loss: 1535.4569 - val_accuracy: 0.1997 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      " - 307s - loss: 0.7601 - accuracy: 0.7701 - top_k_categorical_accuracy: 0.9386 - val_loss: 1938.0178 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      " - 304s - loss: 0.7570 - accuracy: 0.7709 - top_k_categorical_accuracy: 0.9391 - val_loss: 1781.0182 - val_accuracy: 5.4667e-04 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      " - 306s - loss: 0.7543 - accuracy: 0.7715 - top_k_categorical_accuracy: 0.9396 - val_loss: 1545.2095 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      " - 304s - loss: 0.7518 - accuracy: 0.7721 - top_k_categorical_accuracy: 0.9399 - val_loss: 1663.8330 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      " - 304s - loss: 0.7491 - accuracy: 0.7729 - top_k_categorical_accuracy: 0.9404 - val_loss: 1670.8349 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      " - 302s - loss: 0.7471 - accuracy: 0.7734 - top_k_categorical_accuracy: 0.9408 - val_loss: 1673.6322 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      " - 303s - loss: 0.7447 - accuracy: 0.7739 - top_k_categorical_accuracy: 0.9413 - val_loss: 1768.9700 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      " - 307s - loss: 0.7426 - accuracy: 0.7746 - top_k_categorical_accuracy: 0.9417 - val_loss: 1763.3050 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      " - 304s - loss: 0.7406 - accuracy: 0.7751 - top_k_categorical_accuracy: 0.9420 - val_loss: 1787.5282 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      " - 306s - loss: 0.7387 - accuracy: 0.7757 - top_k_categorical_accuracy: 0.9423 - val_loss: 1612.4108 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      " - 303s - loss: 0.7369 - accuracy: 0.7761 - top_k_categorical_accuracy: 0.9426 - val_loss: 1667.1128 - val_accuracy: 0.1999 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      " - 305s - loss: 0.7352 - accuracy: 0.7764 - top_k_categorical_accuracy: 0.9430 - val_loss: 2001.1507 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      " - 307s - loss: 0.7334 - accuracy: 0.7769 - top_k_categorical_accuracy: 0.9433 - val_loss: 1704.8043 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      " - 306s - loss: 0.7322 - accuracy: 0.7772 - top_k_categorical_accuracy: 0.9435 - val_loss: 1737.7291 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      " - 305s - loss: 0.7303 - accuracy: 0.7779 - top_k_categorical_accuracy: 0.9437 - val_loss: 1795.7407 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      " - 304s - loss: 0.7292 - accuracy: 0.7782 - top_k_categorical_accuracy: 0.9440 - val_loss: 1811.7687 - val_accuracy: 0.0796 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      " - 303s - loss: 0.7277 - accuracy: 0.7785 - top_k_categorical_accuracy: 0.9442 - val_loss: 1880.2241 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      " - 304s - loss: 0.7262 - accuracy: 0.7790 - top_k_categorical_accuracy: 0.9445 - val_loss: 1808.5844 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      " - 303s - loss: 0.7250 - accuracy: 0.7792 - top_k_categorical_accuracy: 0.9447 - val_loss: 1886.8492 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      " - 304s - loss: 0.7238 - accuracy: 0.7796 - top_k_categorical_accuracy: 0.9448 - val_loss: 1829.0976 - val_accuracy: 0.0772 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      " - 303s - loss: 0.7225 - accuracy: 0.7799 - top_k_categorical_accuracy: 0.9451 - val_loss: 1708.6376 - val_accuracy: 0.1999 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      " - 303s - loss: 0.7211 - accuracy: 0.7801 - top_k_categorical_accuracy: 0.9453 - val_loss: 1842.1892 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      " - 300s - loss: 0.7202 - accuracy: 0.7804 - top_k_categorical_accuracy: 0.9454 - val_loss: 1702.1561 - val_accuracy: 0.1997 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      " - 302s - loss: 0.7191 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9457 - val_loss: 1844.9995 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      " - 301s - loss: 0.7180 - accuracy: 0.7811 - top_k_categorical_accuracy: 0.9459 - val_loss: 1849.7917 - val_accuracy: 0.1999 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      " - 303s - loss: 0.7167 - accuracy: 0.7813 - top_k_categorical_accuracy: 0.9461 - val_loss: 1964.0097 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      " - 302s - loss: 0.7161 - accuracy: 0.7816 - top_k_categorical_accuracy: 0.9463 - val_loss: 1914.3533 - val_accuracy: 0.1999 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      " - 300s - loss: 0.7150 - accuracy: 0.7817 - top_k_categorical_accuracy: 0.9464 - val_loss: 1865.4593 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      " - 304s - loss: 0.7138 - accuracy: 0.7820 - top_k_categorical_accuracy: 0.9466 - val_loss: 1877.4760 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      " - 304s - loss: 0.7129 - accuracy: 0.7823 - top_k_categorical_accuracy: 0.9467 - val_loss: 1878.1328 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      " - 307s - loss: 0.7122 - accuracy: 0.7825 - top_k_categorical_accuracy: 0.9469 - val_loss: 1931.9719 - val_accuracy: 0.0479 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      " - 340s - loss: 0.7111 - accuracy: 0.7827 - top_k_categorical_accuracy: 0.9469 - val_loss: 1942.1705 - val_accuracy: 0.0479 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      " - 487s - loss: 0.7104 - accuracy: 0.7828 - top_k_categorical_accuracy: 0.9471 - val_loss: 1894.6611 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      " - 313s - loss: 0.7095 - accuracy: 0.7831 - top_k_categorical_accuracy: 0.9473 - val_loss: 1784.6412 - val_accuracy: 0.1046 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      " - 315s - loss: 0.7085 - accuracy: 0.7834 - top_k_categorical_accuracy: 0.9474 - val_loss: 1977.5012 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      " - 313s - loss: 0.7078 - accuracy: 0.7836 - top_k_categorical_accuracy: 0.9476 - val_loss: 1918.2041 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      " - 314s - loss: 0.7071 - accuracy: 0.7840 - top_k_categorical_accuracy: 0.9477 - val_loss: 2036.4246 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      " - 312s - loss: 0.7061 - accuracy: 0.7842 - top_k_categorical_accuracy: 0.9479 - val_loss: 2009.4850 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      " - 426s - loss: 0.7055 - accuracy: 0.7843 - top_k_categorical_accuracy: 0.9480 - val_loss: 2118.8283 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      " - 428s - loss: 0.7050 - accuracy: 0.7843 - top_k_categorical_accuracy: 0.9481 - val_loss: 2096.6660 - val_accuracy: 0.1999 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      " - 319s - loss: 0.7041 - accuracy: 0.7845 - top_k_categorical_accuracy: 0.9482 - val_loss: 2022.9330 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      " - 321s - loss: 0.7033 - accuracy: 0.7849 - top_k_categorical_accuracy: 0.9484 - val_loss: 2060.1008 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      " - 328s - loss: 0.7026 - accuracy: 0.7850 - top_k_categorical_accuracy: 0.9485 - val_loss: 2160.0538 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      " - 405s - loss: 0.7020 - accuracy: 0.7851 - top_k_categorical_accuracy: 0.9486 - val_loss: 2180.7460 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      " - 452s - loss: 0.7014 - accuracy: 0.7854 - top_k_categorical_accuracy: 0.9486 - val_loss: 2309.4203 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      " - 319s - loss: 0.7008 - accuracy: 0.7854 - top_k_categorical_accuracy: 0.9488 - val_loss: 2075.9264 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      " - 321s - loss: 0.7003 - accuracy: 0.7856 - top_k_categorical_accuracy: 0.9490 - val_loss: 2048.8501 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      " - 325s - loss: 0.6994 - accuracy: 0.7859 - top_k_categorical_accuracy: 0.9490 - val_loss: 2087.5965 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      " - 322s - loss: 0.6991 - accuracy: 0.7858 - top_k_categorical_accuracy: 0.9491 - val_loss: 1968.5388 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      " - 321s - loss: 0.6985 - accuracy: 0.7861 - top_k_categorical_accuracy: 0.9492 - val_loss: 2053.5397 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      " - 318s - loss: 0.6980 - accuracy: 0.7861 - top_k_categorical_accuracy: 0.9493 - val_loss: 2019.4698 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      " - 327s - loss: 0.6974 - accuracy: 0.7864 - top_k_categorical_accuracy: 0.9494 - val_loss: 2069.3340 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      " - 433s - loss: 0.6966 - accuracy: 0.7865 - top_k_categorical_accuracy: 0.9495 - val_loss: 2050.4167 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      " - 422s - loss: 0.6960 - accuracy: 0.7867 - top_k_categorical_accuracy: 0.9496 - val_loss: 2104.6949 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      " - 319s - loss: 0.6956 - accuracy: 0.7867 - top_k_categorical_accuracy: 0.9497 - val_loss: 2019.2489 - val_accuracy: 0.0478 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      " - 319s - loss: 0.6951 - accuracy: 0.7869 - top_k_categorical_accuracy: 0.9498 - val_loss: 2055.2856 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      " - 442s - loss: 0.6945 - accuracy: 0.7870 - top_k_categorical_accuracy: 0.9498 - val_loss: 2064.6671 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      " - 513s - loss: 0.6943 - accuracy: 0.7872 - top_k_categorical_accuracy: 0.9499 - val_loss: 2106.6690 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      " - 527s - loss: 0.6938 - accuracy: 0.7873 - top_k_categorical_accuracy: 0.9500 - val_loss: 2077.0669 - val_accuracy: 0.1048 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      " - 383s - loss: 0.6933 - accuracy: 0.7874 - top_k_categorical_accuracy: 0.9501 - val_loss: 2019.6971 - val_accuracy: 0.0511 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      " - 320s - loss: 0.6928 - accuracy: 0.7874 - top_k_categorical_accuracy: 0.9501 - val_loss: 1971.6562 - val_accuracy: 0.0493 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a5191cecde26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_CLASS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------DNN Training Go! Go! Go!!!!-----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mfitting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_BATCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# acc_test, test_score,fitting, model = build_and_fit_model(features_train.values,labels_train,x_val=features_test.values,y_test=labels_test,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jjs_model_0124V3.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####TEST DNN\n",
    "print('------------Building DNN model--------------')\n",
    "ShuffleInTraining=True\n",
    "N_EPOCHS=100\n",
    "N_HN_1=512\n",
    "N_HN=256\n",
    "N_LAYERS=3\n",
    "N_BATCH=512\n",
    "lookback=1024\n",
    "Rate_Val=0.005\n",
    "N_Val_OverSampler=int(np.around(N_AllTrain_OverSampler*Rate_Val))\n",
    "N_Train_OverSampler=int(N_AllTrain_OverSampler-N_Val_OverSampler)\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresArray.shape[1]\n",
    "output_dim=N_CLASS\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HN_1,input_dim=input_dim))\n",
    "model.add(BatchNormalization())\n",
    "model.add(PReLU())\n",
    "# model.add(Dropout(dp))\n",
    "for i in range(N_LAYERS):\n",
    "    model.add(Dense(N_HN))\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(PReLU())\n",
    "#   model.add(Dropout(dp))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(output_dim))\n",
    "model.add(Activation('softmax'))\n",
    "# model = multi_gpu_model(model, 2)gfyht76\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "\n",
    "x_train,x_val,y_train,y_val = train_test_split(featuresArray,labelsArray,test_size=N_Val_OverSampler,train_size=N_Train_OverSampler, shuffle=True)\n",
    "# x_train=featuresArray[0:N_Train,:]\n",
    "# y_train=labelsArray[0:N_Train]\n",
    "y_train = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_train)), num_classes=N_CLASS)\n",
    "# x_val=featuresArray[N_Train:N_AllTrain,:] \n",
    "# y_val=labelsArray[N_Train:N_AllTrain]\n",
    "y_val = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_val)), num_classes=N_CLASS)\n",
    "print('------------DNN Training Go! Go! Go!!!!-----------')\n",
    "fitting=model.fit(x_train, y_train, epochs=N_EPOCHS, batch_size=N_BATCH,verbose=2,validation_data=(x_test,y_test),shuffle=True)\n",
    "# acc_test, test_score,fitting, model = build_and_fit_model(features_train.values,labels_train,x_val=features_test.values,y_test=labels_test,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)\n",
    "model.save('jjs_model_0124V3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------DNN Evaluate-------------------\n",
      "87804/87804 [==============================] - 1s 16us/step\n",
      "[1428.1827215625942, 0.10521160811185837, 1.0]\n",
      "671814/671814 [==============================] - 12s 18us/step\n",
      "[100641286229.69618, 0.11470883339643478, 0.27296990156173706]\n"
     ]
    }
   ],
   "source": [
    "print('-----------DNN Evaluate-------------------')\n",
    "acc_test = model.evaluate(x_test,y_test, batch_size=N_BATCH)\n",
    "print(acc_test)\n",
    "acc_test_overSampler = model.evaluate(featuresArray_test,labelsArray_test, batch_size=N_BATCH)\n",
    "print(acc_test_overSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = fitting.history['loss']\n",
    "val_loss = fitting.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------DNN Evaluate-------------------\n",
      "87804/87804 [==============================] - 10s 110us/step\n",
      "[918.3527435946424, 0.19818003475666046, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('-----------DNN Evaluate-------------------')\n",
    "acc_test = model.evaluate(x_test,y_test, batch_size=N_BATCH)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('jjs_model_0124V2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Sort feature and label for LSTM------------------------------------\n",
      "--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------Sort feature and label for LSTM------------------------------------')\n",
    "featuresLSTM=features.values\n",
    "labelsLSTM = labels.values\n",
    "ShuffleInTraining=True\n",
    "N_EPOCHS=3\n",
    "N_HN=128\n",
    "N_LAYERS=1\n",
    "N_BATCH=128\n",
    "lookback=1024\n",
    "Rate_Val=0.2\n",
    "N_Val=np.around(N_AllTrain*Rate_Val)\n",
    "N_Train=N_AllTrain-N_Val\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresLSTM.shape[1]\n",
    "output_dim=N_CLASS\n",
    "\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "time_temp=featuresLSTM[:,2]+np.dot(featuresLSTM[:,3],100)+np.dot(featuresLSTM[:,4],10000)+np.dot(featuresLSTM[:,5],1000000)\n",
    "features_label_time=np.column_stack((featuresLSTM,labelsLSTM))\n",
    "features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "featuresLSTM=features_label_time[:,0:featuresLSTM.shape[1]]\n",
    "labelsLSTM=features_label_time[:,-2]\n",
    "labelsLSTM = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsLSTM)), num_classes=N_CLASS)\n",
    "del features_label_time\n",
    "\n",
    "print('--------------------------generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------')\n",
    "train_generator=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=N_Train, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_generator=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=N_Train+1, max_index=None, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "AllTrain_generator=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "AllTest_generator=generator(x_test, y_test, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_steps = (N_Val-lookback) // N_BATCH\n",
    "test_steps =(N_AllTest - lookback) // N_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = Sequential()\n",
    "LSTMmodel.add(layers.Flatten(input_shape=(lookback, input_dim)))\n",
    "LSTMmodel.add(layers.Dense(N_HN, activation='relu'))\n",
    "LSTMmodel.add(layers.Dense(output_dim))\n",
    "model.add(Activation('softmax'))\n",
    "LSTMmodel.compile(optimizer=RMSprop(), loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "# LSTMmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------LSTM GO GO GO!!!!---------------------------------------------\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 797s 16s/step - loss: 8.1904 - accuracy: 0.0864 - top_k_categorical_accuracy: 0.3411 - val_loss: 7.9591 - val_accuracy: 0.1394 - val_top_k_categorical_accuracy: 0.4280\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 784s 16s/step - loss: 8.0796 - accuracy: 0.1109 - top_k_categorical_accuracy: 0.3505 - val_loss: 7.2991 - val_accuracy: 0.0774 - val_top_k_categorical_accuracy: 0.3846\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 788s 16s/step - loss: 8.1813 - accuracy: 0.1255 - top_k_categorical_accuracy: 0.3256 - val_loss: 8.9437 - val_accuracy: 0.1139 - val_top_k_categorical_accuracy: 0.3852\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "history = LSTMmodel.fit_generator(train_generator,steps_per_epoch=50,epochs=N_EPOCHS,verbose=1,validation_data=val_generator,validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------LSTM ReTraining On AllTrainSet (include trainSet and valSet) !!!!---------------------------------\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 820s 16s/step - loss: 8.1710 - accuracy: 0.1575 - top_k_categorical_accuracy: 0.3841 - val_loss: 7.1834 - val_accuracy: 0.1535 - val_top_k_categorical_accuracy: 0.4441\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------LSTM ReTraining On AllTrainSet (include trainSet and valSet) !!!!---------------------------------')\n",
    "historyAll = LSTMmodel.fit_generator(AllTrain_generator,steps_per_epoch=50, epochs=1,verbose=1,validation_data=val_generator,validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9226/10000 [==========================>...] - ETA: 2:14"
     ]
    }
   ],
   "source": [
    "acc_test = LSTMmodel.evaluate_generator(AllTest_generator, steps=10000,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------LSTM Evaluate on AllTestSet-------------------\n",
      "87804/87804 [==============================] - 19971s 227ms/step\n",
      "[9.870048522949219, 0.00019201147370040417, 0.28379303216934204]\n"
     ]
    }
   ],
   "source": [
    "print('-----------LSTM Evaluate on AllTestSet-------------------')\n",
    "####\n",
    "#需要将train_X_ALL和test_X拼接在一起，先计算一下train_X_ALL的行数，然后，根据lookback来确定test_X从哪一行开始\n",
    "####\n",
    "#evaluate_generator(generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "acc_test = LSTMmodel.evaluate_generator(AllTest_generator, steps=N_AllTest,  verbose=1)\n",
    "# acc_test = LSTMmodel.evaluate(test_X,test_Y, batch_size=N_BATCH)\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Begin LSTM--------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7acc29103aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesLSTM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelsLSTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfeatures_label_time\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mfeaturesLSTM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeaturesLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabelsLSTM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures_label_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "OnlyLSTM=True#False\n",
    "if OnlyLSTM:\n",
    "    print('------------Begin LSTM--------------')\n",
    "    featuresLSTM=features.values\n",
    "    labelsLSTM = labels.values\n",
    "        #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    time_temp=featuresLSTM[:,2]+np.dot(featuresLSTM[:,3],100)+np.dot(featuresLSTM[:,4],10000)+np.dot(featuresLSTM[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresLSTM,labelsLSTM))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    featuresLSTM=features_label_time[:,0:featuresLSTM.shape[1]]\n",
    "    labelsLSTM=features_label_time[:,-2]\n",
    "    labelsLSTM = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsLSTM)), num_classes=N_CLASS)\n",
    "    del features_label_time\n",
    "\n",
    "    N_EPOCHS=40\n",
    "    N_HN=128\n",
    "    N_LAYERS=1\n",
    "    N_BATCH=64\n",
    "    lookback=4056\n",
    "    TestRate=0.2\n",
    "    size_Train=trainDF.shape[0]*TestRate\n",
    "    input_dim=featuresLSTM.shape[1]\n",
    "    output_dim=N_CLASS\n",
    "    \n",
    "    print('--------------------------generator Train_set and Val_set for LSTM---------------------------------')\n",
    "    train_X, train_Y=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=size_Train, shuffle=True, batch_size=N_BATCH, step=1)\n",
    "    val_X, val_Y=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=size_Train+1, max_index=None, shuffle=True, batch_size=N_BATCH, step=1)\n",
    " \n",
    "    LSTMmodel = Sequential()\n",
    "    LSTMmodel.add(layers.Flatten(input_shape=(lookback, input_dim)))\n",
    "    LSTMmodel.add(layers.Dense(N_HN, activation='relu'))\n",
    "    LSTMmodel.add(layers.Dense(output_dim))\n",
    "    LSTMmodel.compile(optimizer=RMSprop(), loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "    # LSTMmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "    print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "    history = LSTMmodel.fit(train_X,train_Y, epochs=N_EPOCHS,verbose=1,validation_data=(val_X, val_Y))\n",
    "\n",
    "    print('--------------------------LSTM ReTraining On trainSet and valSet!!!!---------------------------------')\n",
    "    train_X_ALL, train_Y_ALL=generator(featuresLSTM, labelsLSTM, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=True, batch_size=N_BATCH, step=1)\n",
    "    historyAll = LSTMmodel.fit(train_X_ALL, train_Y_ALL, epochs=N_EPOCHS,verbose=1,validation_data=(val_X, val_Y))\n",
    "\n",
    "    print('-----------LSTM Evaluate ALL-------------------')\n",
    "    ####\n",
    "\n",
    "    #需要将train_X_ALL和test_X拼接在一起，先计算一下train_X_ALL的行数，然后，根据lookback来确定test_X从哪一行开始\n",
    "\n",
    "    ####\n",
    "    test_X, test_Y=generator(x_test, y_test, lookback=lookback, delay=1, min_index=0, max_index=None, shuffle=True, batch_size=N_BATCH, step=1)\n",
    "    acc_test = LSTMmodel.evaluate(test_X,test_Y, batch_size=N_BATCH)\n",
    "    print(acc_test)\n",
    "else:   \n",
    "    N_EPOCHS=21\n",
    "    N_HN=256\n",
    "    N_HN_1=512\n",
    "    N_LAYERS=2\n",
    "    N_BATCH=64\n",
    "    DP=0.5\n",
    "    SORTbyTime=False #是否需要根据时间顺序，留出后Test_size个样本用于测试\n",
    "    TestRate=0.2 #当SORTbyTime=False 时，该值才起作用\n",
    "    Test_size=200000#当SORTbyTime=True 时，该值才起作用\n",
    "    split_count=1#当SORTbyTime=True 时，该值才起作用\n",
    "    split_size=int(Test_size/split_count)#当SORTbyTime=True 时，该值才起作用\n",
    "    N_hight=featuresArray.shape[0]\n",
    "    print('------------train_val_split--------------')\n",
    "    for t_i in range(split_count):\n",
    "        if SORTbyTime:\n",
    "            # t_i=t0_i+1\n",
    "            print('--------NNN_spllit_NNN_spllit_NNN_spllit_NNN_spllit_---------')\n",
    "            print(t_i)\n",
    "            x_train=featuresArray[0:N_hight-Test_size+t_i*split_size,:]\n",
    "            y_train=labelsArray[0:N_hight-Test_size+t_i*split_size]\n",
    "\n",
    "            x_val=featuresArray[N_hight-Test_size+t_i*split_size:N_hight-Test_size+(t_i+1)*split_size,:]\n",
    "            y_val=labelsArray[N_hight-Test_size+t_i*split_size:N_hight-Test_size+(t_i+1)*split_size]\n",
    "        else:\n",
    "            print('------------train_val_split_Shuffle--------------')\n",
    "            x_train,x_val,y_train,y_val = train_test_split(featuresArray,labelsArray,test_size=TestRate,shuffle=True)\n",
    "        print('------------to_categorical--------------')\n",
    "        y_train = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_train)), num_classes=N_CLASS)\n",
    "        y_val = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_val)), num_classes=N_CLASS)\n",
    "\n",
    "\n",
    "        ##########################################################################\n",
    "        print('------------Building model--------------')\n",
    "        input_dim=x_train.shape[1]\n",
    "        output_dim=N_CLASS\n",
    "        model = Sequential()\n",
    "        model.add(Dense(N_HN_1,input_dim=input_dim,init='glorot_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(PReLU())\n",
    "        # model.add(Dropout(dp))\n",
    "        for i in range(N_LAYERS):\n",
    "            model.add(Dense(N_HN, init='glorot_uniform'))\n",
    "            model.add(BatchNormalization())    \n",
    "            model.add(PReLU())    \n",
    "        #   model.add(Dropout(dp))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(output_dim, init='glorot_uniform'))\n",
    "        model.add(Activation('softmax'))\n",
    "        # model = multi_gpu_model(model, 2)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "        if OnlyLSTM:\n",
    "            print('------------Go! Go! Go!!!!-----------')\n",
    "            fitting=model.fit(x_train, y_train, epochs=N_EPOCHS, batch_size=N_BATCH,verbose=1,validation_data=(x_val,y_val))\n",
    "            # acc_test, test_score,fitting, model = build_and_fit_model(features_train.values,labels_train,x_val=features_test.values,y_test=labels_test,hn=N_HN,layers=N_LAYERS,epochs=N_EPOCHS,verbose=2,dp=DP)\n",
    "            # model.save('jjs_model_0112.h5')\n",
    "            print('-----------Evaluate-------------------')\n",
    "            acc_test = model.evaluate(x_test,y_test, batch_size=N_BATCH)\n",
    "            print(acc_test)\n",
    "            if SORTbyTime:\n",
    "                del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    " \n",
    "K.clear_session()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
